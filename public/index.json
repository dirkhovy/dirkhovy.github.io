[{"authors":["hovy_dirk"],"categories":null,"content":"Welcome!\nI am a Professor in the Computing Sciences Department of Bocconi University in Milan, where I lead the MilaNLP lab together with Debora Nozza. I am also the scientific director of the Data and Marketing Insights research unit. Previously, I was CS faculty at the University of Copenhagen, got a PhD from USC\u0026rsquo;s Information Sciences Institute, and a master\u0026rsquo;s degree in linguistics from Marburg University, Germany.\nI am interested in the interaction between language, society, and machine learning, or what computers can tell us about language and what language can tell us about society. I am also interested in ethical questions of bias and algorithmic fairness in machine learning.\nI have authored over 150 articles on these topics, including 3 best and one outstanding paper awards, and have published two textbooks on text processing in Python for social scientists.\nI co-founded and organized several workshops (on computational social science, and ethics in NLP), and I was a local organizer for the EMNLP 2017 conference. I was awarded an ERC Starting Grant project 2020 for research on demographic bias in NLP.\nOutside of work, I enjoy cooking, leather-crafting, and picking up heavy things to put them back down.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2162c73950c747d1a2acd1061edae370","permalink":"https://dirkhovy.com/authors/1_dirk_hovy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/1_dirk_hovy/","section":"authors","summary":"Welcome!\nI am a Professor in the Computing Sciences Department of Bocconi University in Milan, where I lead the MilaNLP lab together with Debora Nozza. I am also the scientific director of the Data and Marketing Insights research unit.","tags":null,"title":"Dirk Hovy","type":"authors"},{"authors":["Dirk Hovy"],"categories":null,"content":"After publishing \u0026ldquo; How to professor\u0026rdquo;, several people said they found it helpful, and asked whether I had a similar post on writing. Luckily, we have held an annual writing workshop in the lab for the last few years, so there already was a presentation. This article is the text version of that presentation. As with the previous post, everything here is based on my own experience as an academic writer, with some grounding in prior work, so take it with a grain of salt. However, if it can help you improve your writing and avoid some of my mistakes, go ahead.\nBefore we start, though, let\u0026rsquo;s address the elephant in the room. Some people have asked whether we still need to know how to write in the age of LLMs. My answer is an unambiguous \u0026ldquo;yes.\u0026rdquo; You should, of course, use all the tools at your disposal, e.g., ChatGPT to turn your notes into a continuous text, Quillbot to make your text more fluent, or Grammarly to improve the grammaticality. However, all of those tools are ML applications, and the old adage of \u0026ldquo;crap in, crap out\u0026rdquo; holds here as well. Starting out with a well-written piece will yield better results than leaving it to the tools to fix some sloppy copy. Besides, some LLM tools have their own flawed writing tendencies, such as overusing superlatives and empty phrases (\u0026ldquo;let\u0026rsquo;s delve into this fascinating topic\u0026rdquo;). They also tend not to be as good at structural aspects as human editors. Knowing how to write well will help you spot inconsistencies in LLM suggestions. More importantly, though, they do not reflect your voice, and that can leave the writing feel generic and anodyne. They do, however, make decent critics for early drafts to help you spot what is missing.\nScientific Writing The Importance of Good Writing \u0026ldquo;Good writing is like a window pane.\u0026rdquo;\n\u0026mdash;George Orwell\nScientific writing is a fundamental skill for researchers and academics. Whether you are authoring a research paper or drafting a grant proposal, writing is crucial for clear and effective communication. No scientific paper is just the results: A surprising amount of academic writing is also storytelling. You need to frame the results and make the reader care about them (anecdotally, I have seen rejected papers get accepted after improving just the writing).\nGood writing differentiates successful communication from misunderstandings. Even small things, like misplaced words or punctuation errors, can dramatically alter meaning. For example, consider the headline: \u0026ldquo;Rachael Ray finds inspiration in cooking her family and her dog.\u0026rdquo; Poor dog\u0026hellip; Adding prepositions like \u0026ldquo;with\u0026rdquo; and \u0026ldquo;for,\u0026rdquo; or simply using commas, can prevent such unfortunate interpretations. Clear writing helps avoid confusion.\nMany review forms specifically ask how readable a submission is. That might seem like a formality, but getting a low score here will likely obfuscate any strengths of your work in other areas.\nKnow Your Audience Scientific writing should be clear to any well-prepared reader. First impressions matter: You win or lose the reader on the first page, most likely already in the abstract. Within the first few lines, you either capture their attention and make them want to read on \u0026ndash; or you lose their interest (and potentially the paper acceptance). Engrossed reviewers will be much more inclined to rate your paper highly. They may even forgive minor details that are off later on. If you start out on the back foot instead, reviewers may feel you are wasting their time and will be much more critical of any minor detail.\nWith that in mind, we should tailor our writing to fit our audience: a scientific paper and a blog post have different audiences, and your writing should take that into account. Independent of the topic, any audience falls somewhere on the \u0026ldquo;What-So What\u0026rdquo; curve, i.e., how much they care about the technical details (What) vs. the reasons and implications of the work (So What). Your co-authors will care much more about the What than the So What (they know why you did it). For most other audiences, the importance of the So What increases. The depth and complexity of information you\u0026rsquo;ll include differ greatly from what you\u0026rsquo;d present to a class of high-schoolers, a peer group, or grant reviewers (which might not be professional peers). Understanding your audience helps you decide how much background information to provide, how much jargon is acceptable, and how much you need to invest to make them care about the problem. People in your field are intrinsically motivated (otherwise, they would not be in that field). Grant reviewers might not. Depending on the type of grant, these might not be people in your field, or even academics at all.\nFor any audience, though, make sure to reduce their cognitive load: Suspense is great in fiction, but in academic writing, spoilers are completely okay. Do not leave readers guessing what the paper is about; tell them upfront. Keeping track of 5 different scenarios that a research paper could evolve into is taxing even for experts. Save them the trouble and let them focus on the content.\nI have often heard the advice not to make your audience feel dumb. Most people, myself included, understand that to mean not to oversimplify matters. However, that is probably not correct. I have never seen an audience dislike a paper just becasue it explained a complex matter simply: Nobody feels dumb if they understand what\u0026rsquo;s going on in a paper. What does make people feel dumb is if they don\u0026rsquo;t get what the paper is about. In a few cases, that might be due to their limited knowledge. In the overwhelming majority of cases, though, it\u0026rsquo;s due to bad writing.\n\u0026ldquo;\u0026lsquo;All you have to do is write one true sentence. Write the truest sentence that you know.\u0026rsquo; So finally I would write one true sentence, and then go on from there. It was easy then because there was always one true sentence that I knew or had seen or had heard someone say.\u0026rdquo;\n\u0026mdash;Ernest Hemmingway\nWe often think of writing as an artistic expression that requires some sort of innate talent. And while great fiction writers certainly bring their own style to the table, even they will readily admit that good writing is mainly one thing: practice. (Case in point: despite his adventurous lifestyle, Hemingway slavishly followed a daily writing routine and rewrote often.) The good news is that means nobody is automagically good at it. It also means anyone can learn it. Even if English is not your native language, you can craft good scientific texts by following some simple rules of thumb and practicing them until they become second nature. They might not win a Pulitzer Prize, but they will get your message across and keep your readers engaged. All it takes is some simple rules, repeated improvements, and lots of practice.\nI have been writing almost daily for about 25 years. I have published over 150 articles, two textbooks, and have a forthcoming trade book. I like writing. And yet, the first draft I write is still gonna be dogwater. I have accepted that and now try to get it out of the way as soon as possible. It\u0026rsquo;s better to have a mediocre first draft you can improve than wait forever for the perfect inspiration. And with a few basic guidelines in mind, you can make that first draft at least a good starting point.\nRules of Thumb Short Sentences are more effective and easier to understand. If a sentence extends beyond two lines, split it into smaller ones. Subject Placement: Introduce the subject early in the sentence to clarify who\u0026rsquo;s doing what, and put it close to the verb. Full Verbs: Use full verbs rather than nominal constructions. Active Voice helps with all of the above. Instead of saying, \u0026ldquo;Measurements were taken,\u0026rdquo; use \u0026ldquo;We measured.\u0026rdquo; Many of us were taught to use the passive voice in formal writing because it is considered more \u0026ldquo;objective.\u0026rdquo; In practice, it hides who did the work and also offloads responsibility. Be bold: you put all this effort into your work, stand for it! Information Structure: Introduce new concepts at the end of the sentence and elaborate on them immediately after. (It\u0026rsquo;s okay to break the active voice rule above to help with this aspect.) Clear Referents: avoid dangling pronouns/starting sentences with a pronoun: \u0026ldquo;This enables us\u0026rdquo; ⟶ \u0026ldquo;This method enables us.\u0026rdquo; Avoiding Fluff Eliminate unnecessary words or phrases to make your text clearer. Here is an incomplete list for easy find-and-replace:\nat that point in time ⟶ then at this point in time ⟶ now in the event that ⟶ if until such time as ⟶ until on account of ⟶ because in the majority of cases ⟶ mostly has the capability of ⟶ can in spite of the fact that ⟶ despite in the final analysis ⟶ finally, ultimately a large percentage of ⟶ most owing to the fact that ⟶ because need to be established ⟶ requires give consideration to ⟶ consider with the exception of ⟶ except it would thus appear that ⟶ apparently in order to ⟶ to we aim to do X ⟶ we do X Illustrative Examples Consider this before-and-after example:\nBefore: \u0026ldquo;By investigating the characteristics of bidirectional embeddings, it is desired that new future roles for this approach will be determined.\u0026rdquo; After: \u0026ldquo;Our investigation of bidirectional embeddings will reveal new roles for this approach.\u0026rdquo; The revised sentence is direct and easy to understand. It\nhas a subject-first sentence structure making clear who did what, uses full verbs, avoids the semantically empty passive construction, is shorter and more decisive in its language removes unnecessary fluff. Writing Abstracts and Introductions Given that you win over or lose the review early on, a compelling abstract is vital for your paper. It should entice reviewers to read on and engage with your work. A good abstract clearly outlines the area, purpose, results, and significance of your research, and tells the reader what to expect (remember: spoilers are good).\nSince abstracts are your calling card, an effective abstract should succinctly describe:\nThe general area The predominant current approach What is missing, or common problems with that approach (the \u0026ldquo;pain\u0026rdquo;) What do you do instead (the \u0026ldquo;gain\u0026rdquo;)? How do you do it? Your results What that means for the future As a practical algorithm, start by writing one sentence for each of those points. It will not be the most beautiful abstract, but it will get your point across. Personally, I am a fan of writing abstracts early, even if you have not yet started the work (advice I got from a PhD committee member). It helps you clarify your thoughts, gives you a marching plan, and lets you gauge interest in the topic by sharing it with colleagues. Any research will reach a point where you need to decide which direction to take it in. Having a written statement of what you thought you would do in the form of an abstract helps you decide which path to go down.\nThat said, the abstract is the part of a paper that needs the most work, and that changes the most. It needs to accurately reflect the state of the work (which might have changed over time).\nAs an example of how to overhaul an abstract, take the following one from an old review (slightly altered for anonymity):\nThe available statistical methods for sequential tagging, especially in maximal NP (noun phrase) chunking, perform well. However, existing tools cannot combine methods freely. All the freely available tools consist of tightly coupled modules. Combining well-known methods (HMM, Maximum Entropy model, TnT, first and second order transition model, beam search, CRFs, smoothing techniques) in a general-purpose sequential tagger would help to find the best combination for each task. This paper introduces an updated, modular, universal sequential tagger which was used for maximal NP chunking. The tool was rewritten from an existing project and its Maximum Entropy based HMM (MEMM) framework was completed with other common methods: TnT-like trigram transition model and the ability of drop-in replacement unigram model from any classifier from the Scikit-learn library or compatible API. The new tool is open source under the LGPL licence. Several kinds of method combinations were tested for English and Amharic. A trigram based solution resulted in the best ever F-score of 93.56% for Amharic NP chunking (+3% improvement). The key of the improvement is based on more accurate POS categories with fine-tuned trigram search.\nIt has all the information needed, but dives right in, jumps around between parts, and buries some of the information. Using the 7-sentence structure and some of the basic rules we have seen, we can rearrange and rewrite it like this:\nNoun phrase (NP) chunking is a core method in linguistic analysis. The best NP chunking tools use statistical methods for sequential tagging. However, existing tools cannot combine methods freely to find the best combination for each task. We show how to combine well-known methods (different learners, models, and smoothing techniques) in a general-purpose sequential tagger. We introduce a modular, universal NP chunker, based on Maximum Entropy Markov Models, which includes other common methods, like drop-in. We test several combinations for English and Amharic and achieve the best reported F-score of 93.56% for Amharic NP chunking (+3% improvement). The improvement is based on more accurate POS categories with fine-tuned trigram search. A nice bonus of the 7-sentence abstract is that it also serves as a scaffold for your introduction section. Simply copy the abstract, expand each sentence into a paragraph by adding examples and references, and you have the outline of that section as well. Spend some time crafting a succinct example that encapsulates what you are working on. Make clear why it matters. Bonus points if you can reuse the example throughout the paper.\nGrant Writing Essentials At some point, you will find yourself in a position where you have to write a grant. Maybe it\u0026rsquo;s your choice, but it might also be a requirement to get tenure or a promotion. Either way, grantwriting has a couple of benefits independent of whether you end up getting the money. It sharpens your research ideas, forces you to think long-term, and helps you practice outreach to non-academics (many grant reviewers are not academics).\nThe mistake I made when writing my first grant (which, from what I\u0026rsquo;ve heard over the years, is common) was treating it as just a longer research paper. However, they are patently not. Writing grant proposals differs from writing academic papers in several ways. The What–So-What tradeoff is very different from a paper. It\u0026rsquo;s probably better to think of grants as more like blog posts: they should be understandable to a broad, self-selected audience, make a succinct point, and be somewhat exciting.\nPapers Grants Audience Researcher with scholarly passion Sponsor-centered: Service attitude Focus Past work you have done Future work you wish to do Function Exposition: Explaining to reader Persuasive: “Sell” the reader Style Impersonal, objective, dispassionate Personal: Convey excitement Organization Individualistic: present your idea Team-oriented: Feedback needed Specificity Specialized terminology ok Accessible general language Themes Theses, theories, and ideas Goals, activities, and outcomes Grant Questions Pick a problem you believe in and ask:\nWhy is it important? How is existing knowledge or practice inadequate? Why is your idea better? How is it new, unique, different? What will it contribute and who will benefit from it? Also identify whether it\u0026rsquo;s an individual or consortium grant, and whether it\u0026rsquo;s top-down (they provide the topics) or bottom-up (you come up with an idea). Those aspects will matter in whether you start writing right away or find some collaborators first, and how you frame the idea, respectively.\nPitch Perfect Make a compelling case for your idea\u0026rsquo;s impact and benefits. Ideally, the grant topic is:\nan important need or issue that should be addressed a gap between where we are now and where we could be a limitation of current knowledge or way of doing things holding us back All this is similar to the \u0026ldquo;pain\u0026rdquo; we have seen in Abstract writing. I have heard this called the \u0026ldquo;unrejectionable \u0026ldquo;: what major issue do the funders allow to continue by not funding your proposal?\nIn contrast, your grant project is an opportunity to:\nadvance our understanding or address a societal need improve efficiency or lower costs of goods and/or services reshape our thinking or way of doing things And yes, that is the \u0026ldquo;gain\u0026rdquo; we have seen earlier.\nWith all that in mind, set the stage to engage and excite the reviewers. Remember: You win or lose on the first page!\nIdentify the need/importance: Who cares? Describe your project\u0026rsquo;s fundamental purpose Create a vision (\u0026ldquo;So What?\u0026rdquo;) Summarize the state of the art Show how your work will advance the field State your solution clearly Describe technical challenges to solving the problem Describe the concept and establish credibility Outline potential benefits Envision the world with the problem solved Keywords and Key Words Clearly state the project\u0026rsquo;s goal and how it aligns with the grant\u0026rsquo;s objectives. They will give you specific keywords, sometimes explicitly: Pay attention to them and what they mean. Make sure you use those words (and maybe even boldface them) in your proposal.\nSome other \u0026ldquo;grant\u0026rdquo; words:\nObjectives: The big goals to solve. State them explicitly and refer back to them. Work packages: Steps in your pipeline (e.g., data collection, model development, literature review). Milestones: Achievements. Release of a model, data set, etc. These are often the results of work packages. Deliverables: Overall outcomes of the project: e.g., a website, publications, models, data sets, workshops, etc. Stakeholders: Society, academia, industry, and grant funders. Ideally, they all benefit from your findings in some way. Money, Money, Money Your grant officer should help you with the details, but you need to have the basics:\npersonnel (postdocs, PhDs, RAs, annotators) teaching buyout/time costs travel costs (flight, hotel, registration) publication costs equipment (GPU servers, eye trackers, etc.) data or annotation services (student annotators, MTurk, surveys, etc.) Account for all expenses, and make them make sense in the narrative. I.e., do not ask for something that is not justified by the project.\nUniversities will also take a fixed percentage of Overhead Costs: think of this as a fee for using their facilities and support. It varies by university, from 30% to over 60%. Some grants explicitly include it, others do not. Be sure to check!\nCommon Mistakes Frequent (preventable) reasons for rejection include:\nProposal did not match program/keywords Applicant did not follow directions Problem statement is too global Problem has no relationship to reality, or no potential solution Problem has been studied to death already Unclear problem, central theme, methods, or goals Overly dramatic imagined consequences Jargon and lack of clear writing Beyond that, it\u0026rsquo;s of course up to the reviewers and funders whether they like your grant, but it\u0026rsquo;s better to avoid getting sorted out at an early stage already.\nConclusion Both scientific papers and grant proposals should be clearly written to effectively communicate their potential impact and win over reviewers. The tools and strategies outlined here give you a scientific writing foundation to achieve that. Beyond that, aim for clarity, structure, and persuasiveness. Use concise language and tailor your message to your audience for the best results. But most of all: start early, keep iterating on the draft, get lots of feedback, and have fun with it. Happy writing!\nFurther Reading When I wrote my thesis, I discovered A Manual for Writers of Research Papers, Theses, and Dissertations: Chicago Style for Students and Researchers by Kate Turabian. I wish I had known about it earlier. It helped me a lot. Some parts can be safely ignored if you use modern typesetting and word processors (e.g., how to make tables or insert images), but the stylistic advice still stands. Beyond that, I find any well-crafted written piece, like articles in The New Yorker, helpful to see how to draft better. Find a writer you like and see what they do to achieve their goals. It will help you get more comfortable and make your writing more compelling.\n","date":1764028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1764028800,"objectID":"756de5f8b17e3e8ea5e2d6a65af32563","permalink":"https://dirkhovy.com/post/2025_11_25/","publishdate":"2025-11-25T00:00:00Z","relpermalink":"/post/2025_11_25/","section":"post","summary":"After publishing \u0026ldquo; How to professor\u0026rdquo;, several people said they found it helpful, and asked whether I had a similar post on writing. Luckily, we have held an annual writing workshop in the lab for the last few years, so there already was a presentation.","tags":null,"title":"How to Write Gooder","type":"post"},{"authors":["Gavin Abercrombie","Tanvi Dinkar","Amanda Cercas Curry","Verena Rieser","Dirk Hovy"],"categories":[],"content":"","date":1762646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1762646400,"objectID":"9913f6d4efe79e0895ec94bbb8036d72","permalink":"https://dirkhovy.com/publication/2025-consistency-key-disentangling-label-variation-nlp-intra-annotator-agreement/","publishdate":"2025-11-01T00:00:00+01:00","relpermalink":"/publication/2025-consistency-key-disentangling-label-variation-nlp-intra-annotator-agreement/","section":"publication","summary":"We commonly use agreement measures to assess the utility of judgements made by human annotators in Natural Language Processing (NLP) tasks. While inter-annotator agreement is frequently used as an indication of label reliability by measuring consistency between annotators, we argue for the additional use of intra-annotator agreement to measure label stability (and annotator consistency) over time. However, in a systematic review, we find that the latter is rarely reported in this field. Calculating these measures can act as important quality control and could provide insights into why annotators disagree. We conduct exploratory annotation experiments to investigate the relationships between these measures and perceptions of subjectivity and ambiguity in text items, finding that annotators provide inconsistent responses around 25% of the time across four different NLP tasks.","tags":["nlp","annotation"],"title":"Consistency is Key: Disentangling Label Variation in Natural Language Processing with Intra-Annotator Agreement","type":"publication"},{"authors":["Flor Miriam Plaza-Del-Arco","Paul Röttger","Nino Scherrer","Emanuele Borgonovo","Elmar Plischke","Dirk Hovy"],"categories":[],"content":"","date":1762646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1762646400,"objectID":"043653ab1dc5606c97b40b9c98a4d6b8","permalink":"https://dirkhovy.com/publication/2025-no-for-some-yes-for-others-persona-prompts-and-other-sources-of-false-refusal-in-language-models/","publishdate":"2025-11-01T00:00:00+01:00","relpermalink":"/publication/2025-no-for-some-yes-for-others-persona-prompts-and-other-sources-of-false-refusal-in-language-models/","section":"publication","summary":"Large language models (LLMs) are increasingly integrated into our daily lives and personalized. However, LLM personalization might also increase unintended side effects. Recent work suggests that persona prompting can lead models to falsely refuse user requests. However, no work has fully quantified the extent of this issue. To address this gap, we measure the impact of 15 sociodemographic personas (based on gender, race, religion, and disability) on false refusal. To control for other factors, we also test 16 different models, 3 tasks (Natural Language Inference, politeness, and offensiveness classification), and nine prompt paraphrases. We propose a Monte Carlo-based method to quantify this issue in a sample-efficient manner. Our results show that as models become more capable, personas impact the refusal rate less. However, we find that the choice of model significantly influence false refusals, especially in sensitive content tasks. The impact of certain sociodemographic personas further increases the false refusal effect in some models, which suggests that there are underlying biases in the alignment strategies or safety mechanisms.","tags":["nlp","llms","refusal","persona"],"title":"No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models","type":"publication"},{"authors":["Pedro Henrique Luz de Araujo","Paul Röttger","Dirk Hovy","Benjamin Roth"],"categories":[],"content":"","date":1762646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1762646400,"objectID":"6c2d2447c1b90b8c03e8f759821e4f3a","permalink":"https://dirkhovy.com/publication/2025-principled_personas/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2025-principled_personas/","section":"publication","summary":"Expert persona prompting—assigning roles such as expert in math to language models—is widely used for task improvement. However, prior work shows mixed results on its effectiveness, and does not consider when and why personas should improve performance. We analyze the literature on persona prompting for task improvement and distill three desiderata: 1) performance advantage of expert personas, 2) robustness to irrelevant persona attributes, and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs across 27 tasks with respect to these desiderata. We find that expert personas usually lead to positive or non-significant performance changes. Surprisingly, models are highly sensitive to irrelevant persona details, with performance drops of almost 30 percentage points. In terms of fidelity, we find that while higher education, specialization, and domain-relatedness can boost performance, their effects are often inconsistent or negligible across tasks. We propose mitigation strategies to improve robustness—but find they only work for the largest, most capable models. Our findings underscore the need for more careful persona design and for evaluation schemes that reflect the intended effects of persona usage.","tags":["Large Language Models","Persona Prompting","Evaluation"],"title":"Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance","type":"publication"},{"authors":["Chenfei Xiong","Jingwei Ni","Yu Fan","Vilém Zouhar","Donya Rooein","Lorena Calvo-Bartolomé","Alexander Hoyle","Zhijing Jin"," Mrinmaya Sachan","Markus Leippold","Dirk Hovy","Mennatallah El-Assady","Elliott Ash"],"categories":[],"content":"","date":1757635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1757635200,"objectID":"64da59498cfd1280830e26f76d7d7b6d","permalink":"https://dirkhovy.com/publication/2025-co-detect/","publishdate":"2025-09-12T17:19:53+01:00","relpermalink":"/publication/2025-co-detect/","section":"publication","summary":"We introduce Co-DETECT (Collaborative Discovery of Edge cases in TExt ClassificaTion), a novel mixed-initiative annotation framework that integrates human expertise with automatic annotation guided by large language models (LLMs). Co-DETECT starts with an initial, sketch-level codebook and dataset provided by a domain expert, then leverages the LLM to annotate the data and identify edge cases that are not well described by the initial codebook. Specifically, Co-DETECT flags challenging examples, induces high-level, generalizable descriptions of edge cases, and assists user in incorporating edge case handling rules to improve the codebook. This iterative process enables more effective handling of nuanced phenomena through compact, generalizable annotation rules. Extensive user study, qualitative and quantitative analyses prove the effectiveness of Co-DETECT.","tags":["Co-detect","LLMs","edge cases","text classification"],"title":"Co-DETECT: Collaborative Discovery of Edge Cases in Text Classification?","type":"publication"},{"authors":["Donya Rooein","Vilém Zouhar","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1757376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1757376000,"objectID":"d4cf0c88aa16ae18d864531651955c58","permalink":"https://dirkhovy.com/publication/2025-biased-tales/","publishdate":"2025-09-09T17:19:53+01:00","relpermalink":"/publication/2025-biased-tales/","section":"publication","summary":"Stories play a pivotal role in human communication, shaping beliefs and morals, particularly in children. As parents increasingly rely on large language models (LLMs) to craft bedtime stories, the presence of cultural and gender stereotypes in these narratives raises significant concerns. To address this issue, we present Biased Tales, a comprehensive dataset designed to analyze how biases influence protagonists' attributes and story elements in LLM-generated stories. Our analysis uncovers striking disparities. When the protagonist is described as a girl (as compared to a boy), appearance-related attributes increase by 55.26%. Stories featuring non-Western children disproportionately emphasize cultural heritage, tradition, and family themes far more than those for Western children. Our findings highlight the role of sociocultural bias in making creative AI use more equitable and diverse.","tags":["Cultural Bias","LLMs","Story generation","Children"],"title":"Biased Tales: Cultural and Topic Bias in Generating Children’s Stories?","type":"publication"},{"authors":["Paul Röttger","Musashi Hinck","Valentin Hofmann","Kobi Hackenburg","Valentina Pyatkin","Faeze Brahman","Dirk Hovy"],"categories":[],"content":"","date":1756684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756684800,"objectID":"126a730c6e97a09d75e9bbde320a8c01","permalink":"https://dirkhovy.com/publication/2025-issuebench/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2025-issuebench/","section":"publication","summary":"Large language models (LLMs) are helping millions of users write texts about diverse issues, and in doing so expose users to different ideas and perspectives. This creates concerns about issue bias, where an LLM tends to present just one perspective on a given issue, which in turn may influence how users think about this issue. So far, it has not been possible to measure which issue biases LLMs manifest in real user interactions, making it difficult to address the risks from biased LLMs. Therefore, we create IssueBench: a set of 2.49m realistic English-language prompts to measure issue bias in LLM writing assistance, which we construct based on 3.9k templates (e.g. 'write a blog about') and 212 political issues (e.g. 'AI regulation') from real user interactions. Using IssueBench, we show that issue biases are common and persistent in 10 state-of-the-art LLMs. We also show that biases are very similar across models, and that all models align more with US Democrat than Republican voter opinion on a subset of issues. IssueBench can easily be adapted to include other issues, templates, or tasks. By enabling robust and realistic measurement, we hope that IssueBench can bring a new quality of evidence to ongoing discussions about LLM biases and how to address them.","tags":["Large Language Models","AI Alignment","NLP"],"title":"IssueBench: Millions of Realistic Prompts for Measuring Issue Bias in LLM Writing Assistance","type":"publication"},{"authors":["Elisa Bassignana*","Amanda Cercas Curry*","Dirk Hovy"],"categories":[],"content":"","date":1753315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1753315200,"objectID":"f0111883e85a61cd942724f92e4e2991","permalink":"https://dirkhovy.com/publication/2025-ses-survey/","publishdate":"2025-07-24T14:48:20+01:00","relpermalink":"/publication/2025-ses-survey/","section":"publication","summary":"Socioeconomic status (SES) fundamentally influences how people interact with each other and, more recently, with digital technologies like large language models (LLMs). While previous research has highlighted the interaction between SES and language technology, it was limited by reliance on proxy metrics and synthetic data. We survey 1,000 individuals from ‘diverse socioeconomic backgrounds’ about their use of language technologies and generative AI, and collect 6,482 prompts from their previous interactions with LLMs. We find systematic differences across SES groups in language technology usage (i.e., frequency, performed tasks), interaction styles, and topics. Higher SES entail a higher level of abstraction, convey requests more concisely, and topics like ‘inclusivity’ and ‘travel’. Lower SES correlates with higher anthropomorphization of LLMs (using ”hello” and ”thank you”) and more concrete language. Our findings suggest that while generative language technologies are becoming more accessible to everyone, socioeconomic linguistic differences still stratify their use to create a digital divide. These differences underscore the importance of considering SES in developing language technologies to accommodate varying linguistic needs rooted in socioeconomic factors and limit the AI Gap across SES groups.","tags":["socioeconomic status","survey","ses"],"title":"The AI Gap: How Socioeconomic Status Affects Language Technology Interactions","type":"publication"},{"authors":["Matthias Orlikowski","Jiaxin Pei","Paul Röttger","Philipp Cimiano","David Jurgens","Dirk Hovy"],"categories":[],"content":"","date":1751324400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751324400,"objectID":"69eaa52cdc12704420cfb65f9438b352","permalink":"https://dirkhovy.com/publication/2025-beyond-demographics-fine-tuning-large-language-models-predict-individuals-subjective-text-perceptions/","publishdate":"2025-07-01T00:00:00+01:00","relpermalink":"/publication/2025-beyond-demographics-fine-tuning-large-language-models-predict-individuals-subjective-text-perceptions/","section":"publication","summary":"People naturally vary in their annotations for subjective questions and some of this variation is thought to be due to the person's sociodemographic characteristics. LLMs have also been used to label data, but recent work has shown that models perform poorly when prompted with sociodemographic attributes, suggesting limited inherent sociodemographic knowledge. Here, we ask whether LLMs can be trained to be accurate sociodemographic models of annotator variation. Using a curated dataset of five tasks with standardized sociodemographics, we show that models do improve in sociodemographic prompting when trained but that this performance gain is largely due to models learning annotator-specific behaviour rather than sociodemographic behaviours. Across all tasks, our results suggest that models learn little meaningful connection between sociodemographics and annotation, raising doubts about the current use of LLMs for simulating sociodemographic variation and behaviour.","tags":["llms","nlp","sociodemographics","annotation"],"title":"Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals' Subjective Text Perceptions","type":"publication"},{"authors":["Sankalan Pal Chowdhury","Terry Jingchen Zhang","Donya Rooein","Dirk Hovy","Tanja Käser","Mrinmaya Sachan"],"categories":[],"content":"","date":1751324400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751324400,"objectID":"e92018cf66903342c271d1f2cc3539e3","permalink":"https://dirkhovy.com/publication/2025-educators-perceptions-large-language-models-tutors-comparing-human-ai-tutors-blind-text-only-setting/","publishdate":"2025-07-01T00:00:00+01:00","relpermalink":"/publication/2025-educators-perceptions-large-language-models-tutors-comparing-human-ai-tutors-blind-text-only-setting/","section":"publication","summary":"The rapid development of Large Language Models (LLMs) opens up the possibility of using them aspersonal tutors. This has led to the development of several intelligent tutoring systems and learning assistants that use LLMs as back-ends with various degrees of engineering. In this study, we seek to compare human tutors with LLM tutorsin terms of engagement, empathy, scaffolding, and conciseness. We ask human tutors to compare the performance of an LLM tutor with that of a human tutor in teaching grade-school math word problems on these qualities. We find that annotators with teaching experience perceive LLMs as showing higher performance than human tutors in all 4 metrics. The biggest advantage is in empathy, where 80% of our annotators prefer the LLM tutor more often than the human tutors. Our study paints a positive picture of LLMs as tutors and indicates that these models can be used to reduce the load on human teachers in the future.","tags":["llms","nlp","education"],"title":"Educators' Perceptions of Large Language Models as Tutors: Comparing Human and AI Tutors in a Blind Text-only Setting","type":"publication"},{"authors":["Diyi Yang","Dirk Hovy","David Jurgens","Barbara Plank"],"categories":[],"content":"","date":1748732400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1748732400,"objectID":"76f569ff17a57a9f49b085b6622731c2","permalink":"https://dirkhovy.com/publication/2025-socially-aware-language-technologies-perspectives-practices/","publishdate":"2025-06-01T00:00:00+01:00","relpermalink":"/publication/2025-socially-aware-language-technologies-perspectives-practices/","section":"publication","summary":"Language technologies have advanced substantially, particularly with the introduction of large language models. However, these advancements can exacerbate several issues that models have traditionally faced, including bias, evaluation, and risk. In this perspective piece, we argue that many of these issues share a common core: a lack of awareness of the social factors, interactions, and implications of the social environment in which NLP operates. We call this social awareness. While NLP is improving at addressing linguistic issues, there has been relatively limited progress in incorporating social awareness into models to work in all situations for all users. Integrating social awareness into NLP will improve the naturalness, usefulness, and safety of applications while also opening up new applications. Today, we are only at the start of a new, important era in the field.","tags":["llms","nlp","sociodemographics"],"title":"Socially Aware Language Technologies: Perspectives and Practices","type":"publication"},{"authors":["Dirk Hovy"],"categories":null,"content":"It feels not long ago that I was worried about my job applications, but in reality, I have done this long enough that some of my first MSc supervisees are professors of their own now. Every few months, a lab member goes on the academic job market, and we have a conversation about how to best approach it.\nSo I decided to collect those thoughts on what to do if you plan to become a professor (or, more generally, a professional researcher) in NLP. It\u0026rsquo;s entirely based on my own experience: I\u0026rsquo;ve worked two tenure track jobs, one more research-focused in a CS dept and one with more teaching in a Business School. I fact-checked with some people, but it\u0026rsquo;s probably still not always generalizable.\nIf it helps you make up your mind, though, go ahead :)\nWhere to go The first question is where to go. Part of that is your active decision: Do you enjoy teaching or research more? Part of that is out of your hands: There might not be a position in the city, region, or even country you would like to go to. So you will have to be flexible, but it pays to have a robust set of criteria. Also, keep an open mind. There are plenty of options: traditional university jobs, business schools, think tanks, industry research labs, or government research facilities. There might be even more. They all come with pros and cons, but it is a good idea to include all applicable ones in your search. Much of what follows is outside your control, but choosing to apply (and where) is most definitely within it.\nFinding a position Give it your best go, but do not get discouraged. You do not know what a committee is looking for. They might look for people with a specific research profile, a specific demographic, or a specific skill. While this uncertainty is grating, it can also be consoling. You might not have gotten rejected because you were not good enough in the things you have control over – you might just not be the person they want. Nothing you can do about that. After being placed in the first position, I once got rejected because the hiring department decided to build a bridge to another department that required a specific subject area. One of the other candidates happened to have that specialization. I did not. They hired him. It wasn\u0026rsquo;t part of the initial call, and it wasn\u0026rsquo;t something they had planned. It happens.\nSome (though luckily not all) positions you apply for are already spoken for but have to run a public call nonetheless. You will do the whole song and dance, but you never actually had a chance to get it. Unfortunately, being rejected from a competition that was never open holds very little information. You will not know beforehand which kind of competition it is.\nExpect to apply for 20 positions or more for any match (depending on the field). Try to get practice interviews. Your first interview should not be for your dream job.\nIn general, you will be judged by these four aspects, in descending order of importance:\nResearch productivity\nFunding ability\nTeaching\nService\n1. Research productivity Different places have very different ways of measuring research productivity, from your Google Scholar index, to a list of preferred venues, to a list of your three most impactful papers. It is impossible to optimize for all. You will not know beforehand which venues a university values (they might not even know themselves), so it\u0026rsquo;s good to go for a mixed strategy. The easiest metric to track is your h-index. It is a measure of both the quality and quantity of your research. Aim for the top venues in the field, but throw in some \u0026ldquo;easy\u0026rdquo; venues with higher acceptance rates to bulk out the CV. Often, those supposedly second-tier venue publications garner more citations than top venues. Having a lot of papers and a lot of citations is a helpful signal to employers. However, even candidates with high citation count who have only second-tier publications will likely get sorted out early if there is any expert in the committee.\nDo not be shy to self-cite! I have heard the argument in a tenure case that \u0026ldquo;If even he doesn\u0026rsquo;t cite himself, how important is the work?\u0026rdquo; Ideally, you are developing a stream of research, so put in citations to your own prior work (if appropriate, of course). Before submitting a camera-ready, go over your prior work and check: would it make sense to include it here? It\u0026rsquo;s easy to overlook a paper that could add a valid point, even if it\u0026rsquo;s your own. Being able to cite your own prior work also indicates that you have a consistent research profile. Also, seeing a reference in a paper makes others more likely to re-cite it.\nResearch is a crowded business, and it is hard to keep track. People might not cite you for any number of reasons, but typically, it is simply a lack of awareness. Be active on social media and make it easy for people to find you. Maintain an updated website and tell people what you are researching (and why).\n2. Funding ability Universities care about your research. They also care about money. If you have a proven track record of getting grants, you will be much more desirable as a candidate than someone with the same CV but no grants. Grants also signal that your research is interesting to outside stakeholders, something universities value. People typically only list their successful grants, the ones they got but declined, and maybe the current ones.\nGrant writing is very different from academic writing: it is story-telling, not research. Do not expect to be good at it from the start. It takes practice, and the odds are low, but persist, and you will be rewarded. As always, grant systems are auto-correlated. If you got a grant in the past, you are more likely to get one in the future (they even ask you to list past grants to assess you). So aim for small grants first, even if they are primarily symbolic. They will pad your resume and increase your chance for future grants.\nDo write grants. Lots of them. You will not be naturally good at it; it is a weird genre. Accept that most will get rejected and that you might not know why. If you get a success rate of 30% over your lifetime, you will be outstanding. Do go back and read old grants, and think about whether you would have given yourself money. Read other people\u0026rsquo;s grants and learn to parse them into components.\nRealize that you are writing for a lay audience. The \u0026ldquo;so what\u0026rdquo; of the grant is equally or more important than the \u0026ldquo;what.\u0026rdquo; Identify the need for your work, and explain why we will be better off afterward (the \u0026ldquo;unrejectionable\u0026rdquo;): It is the funders\u0026rsquo; choice whether they want to let this problem persist…\nGrants give you freedom and independence. Freedom to explore the areas you want and independence from university politics. Grants will often allow you to reduce your teaching load to have more time for research. They will also give you a bargaining chip in salary negotiations and other decisions.\n3. Teaching If you apply for an academic position, you will be expected to teach. There are sometimes incentives for this (teaching awards as positive, student evaluations as a negative incentive), but it will be a given. You should have a teaching statement and some prepared material, but do not sweat this too much: early on, you are not expected to have a ton of teaching already. For better or worse, teaching quality rarely enters into hiring decisions (we all had that one prof). Fight hard to get a class on a topic you know well, and fight even harder to keep it. Preparing a new class is a bottomless time sink, especially in areas you do not know well. If you can use the materials of a more experienced colleague, do so. Resist the urge to make your own or to tinker too much. If you have to make your own class from scratch, make sure you will teach it for the foreseeable future. Plan ahead. Make it count. You do not have to have the perfect material in your first year. It takes about three times to get a class fine-tuned and make it your own. Don\u0026rsquo;t expect to know everything after one year. More than with anything else, perfection is the enemy of the good in teaching prep. You can spend any amount of time preparing. Don\u0026rsquo;t. Realize that students are not out to expose you: They want to learn from you. You do not have to know every obscure detail. If you do not know some obscure detail, say so, make a note, and look it up for next time. It shows you are engaged, and it is an excellent chance for you to learn.\nPrepare an outline of the class, and think about what you want students to learn from it. Gear everything towards that learning outcome. Refer back to that outline often. Do not be afraid to change it if you see it makes more sense in a different order. You will not know ahead of time. Use plenty of examples, and wrap up each class with take-home points. Worry more about the learning outcome than about grade curves or evaluations. Teaching can be gratifying and rewarding if you learn what works for you. It is worth investing in that. It can be a great complement to research, or it can be a drag. It is up to you how to approach it.\nKnow that evaluations are not objective. They measure how much students liked you as much as how well they learned. If you are female, more junior, or not white, your evaluations will likely be worse than that of white, male, more senior colleagues. Use this to discount the numerical outcomes. Do pay attention to valid concerns in the written part, but be prepared for contradictions. I have been told in one of my first classes that I was simultaneously too fast, too slow, too technical, not technical enough, too strict, and the nicest teacher all year. Discard the emotions and look for constructive feedback.\nStructure your interaction with students and be transparent but firm about it. It is usual for them to have many questions, and it is easy to send an email. But not every question needs an email. There are more of them than you, and you have limited time. Even if every student just has a single question, that still means dozens of emails for you. Collect email questions and answer them in batch in class. Many will also resolve themselves (we all ask questions and realize the answer once we say it aloud). Point to the syllabus, write everything out as clearly as possible and refuse to answer things that are on there (and tell them you do that).\nOnly meet during dedicated office hours and after appointments (I tried an open-door policy and did not get anything done). It\u0026rsquo;s also good to set a time limit for meetings: if you have an online system, use it. Otherwise, set up a Google Form with name, time, and topic, and link to it on your website. Ask students to come prepared to those meetings. It will help them focus their thoughts, and it will make it easier to answer them.\n4. Service Research is a community effort. Show that you are a good citizen. If a university wants to hire you potentially for life, they like to see that you are involved. Get engaged in organizing workshops, panels, or initiatives (either write a proposal, or ask an existing committee to let you join). Choose the ones that align with your profile. Become a regular reviewer for a good journal, or eventually an editor.\nTake some time to understand how your workplace functions: structurally, procedurally, politically. Those things are not the most natural fit for researchers and can be quite dry and boring, but knowing and understanding them can make your life easier and your work more effective.\nStructure is the number and types of department, research centers, labs, hubs, groups, etc. It’s the positions and roles that make up the governance of a place. Knowing who’s responsible for what can help you waste less time by asking the right person.\nProcedure is everything from grant management to hiring. What are the steps, which forms do you have to complete, who needs to sign off? This will make your work run more smoothly and save you unpleasant surprises.\nPolitics is everything that connects the former two, but on a personal level. Who works with whom, who wants what position, what are their goals and motivations. If a professor is known to hate AI, don’t waste time trying to convince them of your new hire or grant proposal. If two people don’t speak to each other, be careful not to get in the middle.\nAgree to help out with one committee in your university, but choose which one. Say no to all others. Especially junior female professors are often expected to do a lot of service, and it can easily take over too much time that should go to research and building your profile.\nPublicity Ideally, good work would bubble to the top. That\u0026rsquo;s not what happens, though. All things being equal, research from big schools or well-known co-authors get cited more. Research that was promoted on social media and is easy to find gets cited more. Research that made it into the news gets cited more. As a researcher, it is your job to publish and then publicize your findings. Getting it into a venue is not enough. You need a website that is easy to find and up to date. You need to post things on social media: talks you give, workshops you organize, papers you published. Make it easy for people to find your work and understand it. If two people talk about your area, they need to mention your name. It is not their job to be aware of you. It is your job to make them aware. You will have to say the same thing many times before people know it. Have a clear message and profile, and reinforce it.\nNetwork widely, go to conferences, give invited talks. Give plenty of invited talks. \u0026ldquo;Invited\u0026rdquo; does not mean they cold-called you. If you visit a city with a relevant research group, let them know and offer to give a talk. They will usually be happy to slot you in.\nWhen you go up for tenure, schools will send out requests for reference letters from people you haven\u0026rsquo;t worked with. Cultivate a network of those people early! You will be able to list some reference givers, but they might choose some more. So make sure your name is known.\nMaking it into the press is usually a matter of supplying your press office with a release and hoping they get it out or promoting it on Twitter. Newspapers rarely trawl conference proceedings. Journalists are similar to researchers in that they are looking for interesting new findings. However, they are under much more time and space constraints, which often does not leave room for subtlety. When giving an interview, prepare: What single sentence do you want them to take away from the interview? Repeat that one. Make your points clear and simple: people have no time to read up on the background knowledge. Use simple examples and images. Take notes of all the things you want to cover in the interview and make sure to tick them off as you go. Ask for written questions ahead of time. After the interview, ask for a draft or at least the quotes of you before publication. Sharing this should be standard, but sometimes it is not. Those proofs are your only chance to correct the record if you have been misunderstood (it happens, even with preparation). Remember that you can mark certain things as \u0026ldquo;off the record.\u0026rdquo;\nStaying creative and managing projects Whatever route you take, you will have to generate new research ideas. When you are in industry, you should never be irreplaceable. When you are in academia, you need to be one of a kind. Either way, you should be original and creative. It does get easier over time, but it takes work. Find out what inspires you, and seek that out. For me, it is interacting with people on visits or conferences and then distracting myself with something creative but unrelated to push it forward. Trust your instinct: if you need a day of slacking and playing video games, it might just be your brain recharging and making new connections.\nYou will have to find out how many parallel projects you can pursue to always have an iron in the fire without slowing progress on everything. It should be more than one, but the exact number depends on your multi-tasking affinity and the projects\u0026rsquo; complexity. For some, that is 2. For others, 15. Try to push yourself to find that limit, but realize when you reach it. If you feel like you are standing still, don\u0026rsquo;t be afraid to shelf a project.\nThose projects ideally fit together to advance your research profile, but do not be afraid to try something new out every once in a while. Nothing is sadder than a researcher clinging to outdated ideas.\nHow much you can choose and experiment also depends on your career stage. Earlier on, it is probably reasonable to explore more and to push many lines. As you find your niche, focus on that. At the same time, getting tenure allows you to be more experimental. Use the security to explore more far-fetched and ambitious projects, but don\u0026rsquo;t risk your collaborators\u0026rsquo; careers.\nBut do not get stuck in minor variations of the same theme either.\nRunning a lab Depending on your choices, you might have the chance to build up a lab. This is sometimes even expected. If you have a choice, consider the options. Working with a lab allows you to explore more research areas, but it will replace a large chunk of your time with managerial duties, admin, and bureaucracy. That chunk usually comes out of your active research time. Working alone means less collaboration on a day-to-day basis, but also no managerial responsibilities. Either way, fight hard to keep a day clear of all meetings and admin to do your own research. Mark it in your calendar as blocked, and do not make exceptions. Ever. If you make an exception for a good reason, you\u0026rsquo;ll soon make one for a bad reason.\nIf you do build a lab, realize that you will spend more time each day with these people than with your partner. Don\u0026rsquo;t hire assholes. Work on the group atmosphere you want: you will set the tone and the norms. Treat people with respect and trust them that they want to do good work. Do not be afraid to give up responsibility and control. Do not make them do something you would not do. Be clear about what you expect from them, and keep their desks free of unnecessary bureaucracy and admin. Listen to their ideas and concerns, and take them seriously. Say \u0026ldquo;Yes, and?\u0026rdquo; and see where it takes them. It is your job to help them succeed and solve their problems, not the other way around.\nBe flexible and don’t be afraid to change things. The meeting day does not work for most of the group? Find a different day. The format of the internal talks feels boring? Try shortening it, restrict the topics, make it an interpretative dance. You are not forced to stick to something if it does not work. Occasionally, it can be good to try something new even if nobody feels the need. You can always change it back.\nFinal thoughts Make sure to take at least one day a week completely off. That also means no email. Keep some hobbies, especially sports. You can get away with a lot of neglect in your 20s, but it will catch up, and you don’t want to lose time fixing a preventable injury. Our jobs require a lot of sitting at a computer: counteract that with whatever sports you enjoy.\nGo on vacation, and set your OOO response for one more day than you are away. You can use it to catch up on email.\nDon’t feel like you have to be perfect. Make a plan, be prepared, but know that things will blindside you, that things will not work out. And that’s ok. So will you be. I have failed many times, and usually it didn’t matter. Our jobs are not heart surgery.\nLastly, realize that you are given one of the potentially best and most self-directed jobs there are, but that it’s still a job. Don’t let it distract you from the importance of friends, family, and your health.\n(Some of the better advice in here is based on tips from Dan Jurafsky, Ed Hovy, Lyle Ungar, and Nel Dutt. Thanks!)\n“Things of great importance have to be taken lightly.” – Hagakure\n“Realize that your choices are half chance. So are everybody else\u0026rsquo;s.” – Baz Luhrman, \u0026ldquo;Everybody\u0026rsquo;s free (to wear sunscreen)\u0026rdquo;\n","date":1736812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736812800,"objectID":"904e916df517be38c7bf529b647670a9","permalink":"https://dirkhovy.com/post/2025_01_14/","publishdate":"2025-01-14T00:00:00Z","relpermalink":"/post/2025_01_14/","section":"post","summary":"It feels not long ago that I was worried about my job applications, but in reality, I have done this long enough that some of my first MSc supervisees are professors of their own now.","tags":null,"title":"How to professor","type":"post"},{"authors":["Flor Miriam Plaza-del-Arco","Amanda Cercas Curry","Susanna Paoli","Alba Curry","Dirk Hovy"],"categories":[],"content":"","date":1726963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726963200,"objectID":"8cf9a7741aced2c3989f8f303097b872","permalink":"https://dirkhovy.com/publication/2024-divine-llamas-emotion-bias/","publishdate":"2023-04-12T17:19:53+01:00","relpermalink":"/publication/2024-divine-llamas-emotion-bias/","section":"publication","summary":"Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers. Religions, therefore, cultivate certain emotions. Moreover, these rules are explicitly laid out and interpreted by religious leaders. Using emotion attribution, we explore how different religions are represented in LLMs. We find that: Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs. Eastern religions like Hinduism and Buddhism are strongly stereotyped. Judaism and Islam are stigmatized -- the models' refusal skyrocket. We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion. In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic. This finding underscores the urgent need to address and rectify these biases. Our research underscores the crucial role emotions play in our lives and how our values influence them.","tags":["Emotion attribution","Religion","Bias","Stereotypes","Large Language Models"],"title":"Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models","type":"publication"},{"authors":["Fabio Pernisi","Dirk Hovy","Paul Röttger"],"categories":[],"content":"","date":1723334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723334400,"objectID":"156b0278c4b0945d090f234ba8e4045f","permalink":"https://dirkhovy.com/publication/2024-compromesso/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2024-compromesso/","section":"publication","summary":"As diverse linguistic communities and users adopt large language models (LLMs), assessing their safety across languages becomes critical. Despite ongoing efforts to make LLMs safe, they can still be made to behave unsafely with jailbreaking, a technique in which models are prompted to act outside their operational guidelines. Research on LLM safety and jailbreaking, however, has so far mostly focused on English, limiting our understanding of LLM safety in other languages. We contribute towards closing this gap by investigating the effectiveness of many-shot jailbreaking, where models are prompted with unsafe demonstrations to induce unsafe behaviour, in Italian. To enable our analysis, we create a new dataset of unsafe Italian question-answer pairs. With this dataset, we identify clear safety vulnerabilities in four families of open-weight LLMs. We find that the models exhibit unsafe behaviors even when prompted with few unsafe demonstrations, and -- more alarmingly -- that this tendency rapidly escalates with more demonstrations.","tags":["Large Language Models","AI Safety","NLP"],"title":"Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models","type":"publication"},{"authors":["Xinpeng Wang","Bolei Ma","Chengzhi Hu","Leon Weber-Genzel","Paul Röttger","Frauke Kreuter","Dirk Hovy","Barbara Plank"],"categories":[],"content":"","date":1723334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723334400,"objectID":"7705723cc81af3d241d833404acc59a6","permalink":"https://dirkhovy.com/publication/2024-myanswerisc/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2024-myanswerisc/","section":"publication","summary":"The open-ended nature of language generation makes the evaluation of autoregressive large language models (LLMs) challenging. One common evaluation approach uses multiple-choice questions to limit the response space. The model is then evaluated by ranking the candidate answers by the log probability of the first token prediction. However, first-tokens may not consistently reflect the final response output, due to model’s diverse response styles such as starting with “Sure” or refusing to answer. Consequently, first-token evaluation is not indicative of model behaviour when interacting with users. But by how much? We evaluate how aligned first-token evaluation is with the text output along several dimensions, namely final option choice, refusal rate, choice distribution and robustness under prompt perturbation. Our results show that the two approaches are severely misaligned on all dimensions, reaching mismatch rates over 60%. Models heavily fine-tuned on conversational or safety data are especially impacted. Crucially, models remain misaligned even when we increasingly constrain prompts, i.e., force them to start with an option letter or example template. Our findings i) underscore the importance of inspecting the text output as well and ii) caution against relying solely on first-token evaluation.","tags":["Large Language Models","Evaluation","NLP"],"title":"My Answer is C: First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models","type":"publication"},{"authors":["Paul Röttger","Valentin Hofmann","Valentina Pyatkin","Musashi Hinck","Hannah Rose Kirk","Hinrich Schuetze","Dirk Hovy"],"categories":[],"content":"","date":1723334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723334400,"objectID":"aba2a2e9644c22fb67872e026df2a6f8","permalink":"https://dirkhovy.com/publication/2024-politicalcompass/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2024-politicalcompass/","section":"publication","summary":"Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are used by millions of people. Such real-world concerns, however, stand in stark contrast to the artificiality of current evaluations: real users do not typically ask LLMs survey questions. Motivated by this discrepancy, we challenge the prevailing *constrained* evaluation paradigm for values and opinions in LLMs and explore more realistic *unconstrained* evaluations. As a case study, we focus on the popular Political Compass Test (PCT). In a systematic review, we find that most prior work using the PCT *forces models to comply with the PCT’s multiple-choice format. We show that models give substantively different answers when not forced; that answers change depending on how models are forced; and that answers lack paraphrase robustness. Then, we demonstrate that models give different answers yet again in a more realistic open-ended answer setting. We distill these findings into recommendations and open challenges in evaluating values and opinions in LLMs.","tags":["Large Language Models","AI Alignment","NLP"],"title":"Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models","type":"publication"},{"authors":["Paul Röttger","Hannah Rose Kirk","Bertie Vidgen","Giuseppe Attanasio","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1721088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721088000,"objectID":"a6fed1f8412ee969bf6cd5afc26ac5e8","permalink":"https://dirkhovy.com/publication/2024-xstest/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2024-xstest/","section":"publication","summary":"Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This risk motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse to comply with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a systematic way. XSTest comprises 250 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with, and 200 unsafe prompts as contrasts that models, for most applications, should refuse. We describe XSTest’s creation and composition, and then use the test suite to highlight systematic failure modes in state-of-the-art language models as well as more general challenges in building safer language models.","tags":["Large Language Models","AI Safety","NLP"],"title":"XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models","type":"publication"},{"authors":[],"categories":null,"content":"","date":1718866832,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718866832,"objectID":"41db170e2d502d239c634aa2cbd62981","permalink":"https://dirkhovy.com/talk/worldwideviews2024/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/worldwideviews2024/","section":"talk","summary":"","tags":["podcast"],"title":"Decoding AI","type":"talk"},{"authors":[],"categories":null,"content":" ","date":1716534032,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716534032,"objectID":"df6897521e9ec070a28b0654539ec255","permalink":"https://dirkhovy.com/talk/websci2024/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/websci2024/","section":"talk","summary":"","tags":["talk"],"title":"Unhumanizing Models","type":"talk"},{"authors":["Lorenzo Lupo","Paul Bose","Mahyar Habibi","Dirk Hovy","Carlo Schwarz"],"categories":[],"content":"","date":1716163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716163200,"objectID":"e1b884510e6a32df5fabb54ecd4853bc","permalink":"https://dirkhovy.com/publication/2024-dadit/","publishdate":"2024-02-23T14:48:20+01:00","relpermalink":"/publication/2024-dadit/","section":"publication","summary":"Social scientists increasingly use demographically stratified social media data to study the attitudes, beliefs, and behavior of the general public. To facilitate such analyses, we construct, validate, and release the representative DADIT dataset of 30M tweets of 20k Italian Twitter users, along with their bios and profile pictures. We enrich the user data with high-quality labels for gender, age, and location. This new dataset enables us to compare the performance of various state-of-the-art models for the prediction of the gender and age of social media users. In particular, we investigate if tweets contain valuable information for the prediction of user characteristics, since popular classifiers like M3 don't leverage them. Our best XLM-based classifier improves upon the commonly used competitor M3 by up to 53% F1. Especially for age prediction, classifiers profit from including tweets as features. We also confirm these findings on a German test set.","tags":["Twitter data","demographic prediction","language models","multimodal classification"],"title":"DADIT: A Dataset for Demographic Classification of Italian Twitter Users and a Comparison of Prediction Methods","type":"publication"},{"authors":["Donya Rooein","Paul Rottger","Anastassia Shaitarova","Dirk Hovy"],"categories":[],"content":"","date":1715817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715817600,"objectID":"68e0ca6ce3b15d6e054e6e5e289b8963","permalink":"https://dirkhovy.com/publication/2024-difficulty-classification/","publishdate":"2024-05-15T16:22:16+01:00","relpermalink":"/publication/2024-difficulty-classification/","section":"publication","summary":"Using large language models (LLMs) for educational applications like dialogue-based teaching is a hot topic. Effective teaching, however, requires teachers to adapt the difficulty of content and explanations to the education level of their students. Even the best LLMs today struggle to do this well. If we want to improve LLMs on this adaptation task, we need to be able to measure adaptation success reliably. However, current Static metrics for text difficulty, like the Flesch-Kincaid Reading Ease score, are known to be crude and brittle. We, therefore, introduce and evaluate a new set of Prompt-based metrics for text difficulty. Based on a user study, we create Prompt-based metrics as inputs for LLMs. They leverage LLM's general language understanding capabilities to capture more abstract and complex features than Static metrics. Regression experiments show that adding our Prompt-based metrics significantly improves text difficulty classification over Static metrics alone. Our results demonstrate the promise of using LLMs to evaluate text adaptation to different education levels. ","tags":["Difficulty Classification","Education","Large Language Models"],"title":"Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts","type":"publication"},{"authors":["Paul Röttger","Fabio Pernisi","Bertie Vidgen","Dirk Hovy"],"categories":[],"content":"","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712534400,"objectID":"63bda1d9c59fa404b61557ca9db3376b","permalink":"https://dirkhovy.com/publication/2024-safetyprompts/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2024-safetyprompts/","section":"publication","summary":"The last two years have seen a rapid growth in concerns around the safety of large language models (LLMs). Researchers and practitioners have met these concerns by introducing an abundance of new datasets for evaluating and improving LLM safety. However, much of this work has happened in parallel, and with very different goals in mind, ranging from the mitigation of near-term risks around bias and toxic content generation to the assessment of longer-term catastrophic risk potential. This makes it difficult for researchers and practitioners to find the most relevant datasets for a given use case, and to identify gaps in dataset coverage that future work may fill. To remedy these issues, we conduct a first systematic review of open datasets for evaluating and improving LLM safety. We review 102 datasets, which we identified through an iterative and community-driven process over the course of several months. We highlight patterns and trends, such as a a trend towards fully synthetic datasets, as well as gaps in dataset coverage, such as a clear lack of non-English datasets. We also examine how LLM safety datasets are used in practice -- in LLM release publications and popular LLM benchmarks -- finding that current evaluation practices are highly idiosyncratic and make use of only a small fraction of available datasets. Our contributions are based on this http URL, a living catalogue of open datasets for LLM safety, which we commit to updating continuously as the field of LLM safety develops.","tags":["Large Language Models","AI Safety","NLP"],"title":"SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety ","type":"publication"},{"authors":["Flor Miriam Plaza-del-Arco","Amanda Cercas Curry","Alba Curry","Gavin Abercrombie","Dirk Hovy"],"categories":[],"content":"","date":1711584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711584000,"objectID":"72fdc8b25d816d74f056cd9b0f6f497b","permalink":"https://dirkhovy.com/publication/2024-emotion-gender-stereotypes/","publishdate":"2023-04-12T17:19:53+01:00","relpermalink":"/publication/2024-emotion-gender-stereotypes/","section":"publication","summary":"Large language models (LLMs) reflect societal norms and biases, especially about gender. While societal biases and stereotypes have been extensively researched in various NLP applications, there is a surprising gap for emotion analysis. However, emotion and gender are closely linked in societal discourse. E.g., women are often thought of as more empathetic, while men's anger is more socially accepted. To fill this gap, we present the first comprehensive study of gendered emotion attribution in five state-of-the-art LLMs (open- and closed-source). We investigate whether emotions are gendered, and whether these variations are based on societal stereotypes. We prompt the models to adopt a gendered persona and attribute emotions to an event like 'When I had a serious argument with a dear person'. We then analyze the emotions generated by the models in relation to the gender-event pairs. We find that all models consistently exhibit gendered emotions, influenced by gender stereotypes. These findings are in line with established research in psychology and gender studies. Our study sheds light on the complex societal interplay between language, gender, and emotion. The reproduction of emotion stereotypes in LLMs allows us to use those models to study the topic in detail, but raises questions about the predictive use of those same LLMs for emotion applications.","tags":["Emotion attribution","Gender Bias","Large Language Models"],"title":"Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution","type":"publication"},{"authors":["Donya Rooein","Dirk Hovy"],"categories":[],"content":"","date":1711584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711584000,"objectID":"4f5e4f0fe7cf32b88733c20420ae3e76","permalink":"https://dirkhovy.com/publication/2024-conversations-data/","publishdate":"2023-04-12T17:19:53+01:00","relpermalink":"/publication/2024-conversations-data/","section":"publication","summary":"Open conversations are one of the most engaging forms of teaching. However, creating those conversations in educational software is a complex endeavor, especially if we want to address the needs of different audiences. While language models hold great promise for educational applications, there are substantial challenges in training them to engage in meaningful and effective conversational teaching, especially when considering the diverse needs of various audiences. No official data sets exist for this task to facilitate the training of language models for conversational teaching, considering the diverse needs of various audiences. This paper presents a novel source for facilitating conversational teaching of scientific concepts at various difficulty levels (from preschooler to expert), namely dialogues taken from video transcripts. We analyse this data source in various ways to show that it offers a diverse array of examples that can be used to generate contextually appropriate and natural responses to scientific topics for specific target audiences. It is a freely available valuable resource for training and evaluating conversation models, encompassing organically occurring dialogues. While the raw data is available online, we provide additional metadata for conversational analysis of dialogues at each level in all available videos. ","tags":["Education","Conversational Data","Adaptive Learning"],"title":"Conversations as a Source for Teaching Scientific Concepts at Different Education Levels","type":"publication"},{"authors":["Flor Miriam Plaza-del-Arco","Alba Curry","Amanda Cercas Curry","Dirk Hovy"],"categories":[],"content":"","date":1711584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711584000,"objectID":"d9ced95d92a4ea8da9be921c1eb03a4d","permalink":"https://dirkhovy.com/publication/2024-emotion-analysis-survey/","publishdate":"2023-04-12T17:19:53+01:00","relpermalink":"/publication/2024-emotion-analysis-survey/","section":"publication","summary":"Emotions are a central aspect of communication. Consequently, emotion analysis (EA) is a rapidly growing field in natural language processing (NLP). However, there is no consensus on scope, direction, or methods. In this paper, we conduct a thorough review of 154 relevant NLP publications from the last decade. Based on this review, we address four different questions: (1) How are EA tasks defined in NLP? (2) What are the most prominent emotion frameworks and which emotions are modeled? (3) Is the subjectivity of emotions considered in terms of demographics and cultural factors? and (4) What are the primary NLP applications for EA? We take stock of trends in EA and tasks, emotion frameworks used, existing datasets, methods, and applications. We then discuss four lacunae: (1) the absence of demographic and cultural aspects does not account for the variation in how emotions are perceived, but instead assumes they are universally experienced in the same manner; (2) the poor fit of emotion categories from the two main emotion theories to the task; (3) the lack of standardized EA terminology hinders gap identification, comparison, and future goals; and (4) the absence of interdisciplinary research isolates EA from insights in other fields. Our work will enable more focused research into EA and a more holistic approach to modeling emotions in NLP.","tags":["Emotion analysis","Survey","Natural Language Processing"],"title":"Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions","type":"publication"},{"authors":["Amanda Cercas Curry","Giuseppe Attanasio","Zeerak Talat","Dirk Hovy"],"categories":[],"content":"","date":1709596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709596800,"objectID":"d22ae7873586110e84d9ca0f0c95c8d7","permalink":"https://dirkhovy.com/publication/2024-socialclass-experiments/","publishdate":"2024-03-05T14:48:20+01:00","relpermalink":"/publication/2024-socialclass-experiments/","section":"publication","summary":"Since the foundational work of William Labov on the social stratification of language (Labov, 1964), linguistics has made concentrated efforts to explore the links between sociodemographic characteristics and language production and perception. But while there is strong evidence for socio-demographic characteristics in language, they are infrequently used in Natural Language Processing (NLP). Age and gender are somewhat well represented, but Labov's original target, socioeconomic status, is noticeably absent. And yet it matters. We show empirically that NLP disadvantages less-privileged socioeconomic groups. We annotate a corpus of 95K utterances from movies with social class, ethnicity and geographical language variety and measure the performance of NLP systems on three tasks: language modelling, automatic speech recognition, and grammar error correction. We find significant performance disparities that can be attributed to socioeconomic status as well as ethnicity and geographical differences. With NLP technologies becoming ever more ubiquitous and quotidian, they must accommodate all language varieties to avoid disadvantaging already marginalised groups. We argue for the inclusion of socioeconomic class in future language technologies.","tags":["Large Language Models","Fairness","NLP","Demographics"],"title":"Classist Tools: Social Class Correlates with Performance in NLP","type":"publication"},{"authors":["Amanda Cercas Curry","Zeerak Talat","Dirk Hovy"],"categories":[],"content":"","date":1709596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709596800,"objectID":"d2459c7e7c738b73a9cc2ed6b169f672","permalink":"https://dirkhovy.com/publication/2024-socialclass-survey/","publishdate":"2024-03-05T14:48:20+01:00","relpermalink":"/publication/2024-socialclass-survey/","section":"publication","summary":"Since Labov's (1964) foundational work on the social stratification of language, linguistics has dedicated concerted efforts towards understanding the relationships between socio-demographic factors and language production and perception. Despite the large body of evidence identifying significant relationships between socio-demographic factors and language production, relatively few of these factors have been investigated in the context of NLP technology. While age and gender are well covered, Labov's initial target, socio-economic class, is largely absent. We survey the existing Natural Language Processing (NLP) literature and find that only around 20 papers even mention socio-economic status. However, the majority of those papers do not engage with class beyond collecting information of annotator-demographics. Given this research lacuna, we provide a definition of class that can be operationalised by NLP researchers, and argue for including socio-economic class in future language technologies.","tags":["Social class","Fairness","NLP","Demographics"],"title":"Impoverished Language Technology: The Lack of (Social) Class in NLP","type":"publication"},{"authors":[],"categories":null,"content":"","date":1697731232,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697731232,"objectID":"1f92c1cded0ae4445a511cd6d29cea0a","permalink":"https://dirkhovy.com/talk/zurich2024/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/zurich2024/","section":"talk","summary":"","tags":["talk"],"title":"Fünf ethische Herausforderungen in Sprachtechnologie, und wie wir sie adressieren können ","type":"talk"},{"authors":[],"categories":null,"content":" ","date":1697726732,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697726732,"objectID":"2f658008dbc7e5f117237bad179c8f7d","permalink":"https://dirkhovy.com/talk/vienna2023/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/vienna2023/","section":"talk","summary":"","tags":["talk"],"title":"Unhumanizing Models – Why we Need to Change how We Think about AI","type":"talk"},{"authors":["Flor Miriam Plaza-del-Arco","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1690156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690156800,"objectID":"af13235c20bbbfc9b999e446ca7c1bb9","permalink":"https://dirkhovy.com/publication/2023-label-variation-llms/","publishdate":"2023-07-24T14:48:20+01:00","relpermalink":"/publication/2023-label-variation-llms/","section":"publication","summary":"Large Language Models (LLMs) exhibit remarkable text classification capabilities, excelling in zero- and few-shot learning (ZSL and FSL) scenarios. However, since they are trained on different datasets, performance varies widely across tasks between those models. Recent studies emphasize the importance of considering human label variation in data annotation. However, how this human label variation also applies to LLMs remains unexplored. Given this likely model specialization, we ask: Do aggregate LLM labels improve over individual models (as for human annotators)? We evaluate four recent instruction-tuned LLMs as annotators on five subjective tasks across four languages. We use ZSL and FSL setups and label aggregation from human annotation. Aggregations are indeed substantially better than any individual model, benefiting from specialization in diverse tasks or languages. Surprisingly, FSL does not surpass ZSL, as it depends on the quality of the selected examples. However, there seems to be no good information-theoretical strategy to select those. We find that no LLM method rivals even simple supervised models. We also discuss the tradeoffs in accuracy, cost, and moral/ethical considerations between LLM and human annotation.","tags":["NLP","LLMs","annotation"],"title":"Wisdom of Instruction-Tuned Language Model Crowds. Exploring Model Label Variation","type":"publication"},{"authors":["Amanda Cercas Curry","Giuseppe Attanasio","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"f06c4346370b070a759172242d7d10a1","permalink":"https://dirkhovy.com/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/","section":"publication","summary":"We present the system proposed by the MilaNLP team for the Explainable Detection of Online Sexism (EDOS) shared task. We propose an ensemble modeling approach to combine different classifiers trained with domain adaptation objectives and standard fine-tuning.Our results show that the ensemble is more robust than individual models and that regularized models generate more “conservative” predictions, mitigating the effects of lexical overfitting.However, our error analysis also finds that many of the misclassified instances are debatable, raising questions about the objective annotatability of hate speech data.","tags":["Hate Speech","NLP","domain adaptation","language models"],"title":"MilaNLP at SemEval-2023 Task 10: Ensembling Domain-Adapted and Regularized Pretrained Language Models for Robust Sexism Detection","type":"publication"},{"authors":["Flor Miriam Plaza-del-Arco","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"3f2cc27a6d89ea664c434ace9993294a","permalink":"https://dirkhovy.com/publication/2023-zero-shot-prompting-hate-speech/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-zero-shot-prompting-hate-speech/","section":"publication","summary":"Hate speech detection faces two significant challenges: 1) the limited availability of labeled data and 2) the high variability of hate speech across different contexts and languages. Prompting brings a ray of hope to these challenges. It allows injecting a model with task-specific knowledge without relying on labeled data. This paper explores zero-shot learning with prompting for hate speech detection. We investigate how well zero-shot learning can detect hate speech in 3 languages with limited labeled data. We experiment with various large language models and verbalizers on 8 benchmark datasets. Our findings highlight the impact of prompt selection on the results. They also suggest that prompting, specifically with recent large language models, can achieve performance comparable to and surpass fine-tuned models, making it a promising alternative for under-resourced languages. Our findings highlight the potential of prompting for hate speech detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task.","tags":["Hate Speech","NLP","multilingual"],"title":"Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech","type":"publication"},{"authors":["Gavin Abercrombie","Dirk Hovy","Vinodkumar Prabhakaran"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"6cffcdc288e8545b5e096b0c26db8ca6","permalink":"https://dirkhovy.com/publication/2023-temporal-second-language-influence-intra-annotator-agreement-stability-hate-speech-labelling/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-temporal-second-language-influence-intra-annotator-agreement-stability-hate-speech-labelling/","section":"publication","summary":"Much work in natural language processing (NLP) relies on human annotation. The majority of this implicitly assumes that annotator’s labels are temporally stable, although the reality is that human judgements are rarely consistent over time. As a subjective annotation task, hate speech labels depend on annotator’s emotional and moral reactions to the language used to convey the message. Studies in Cognitive Science reveal a ‘foreign language effect’, whereby people take differing moral positions and perceive offensive phrases to be weaker in their second languages. Does this affect annotations as well? We conduct an experiment to investigate the impacts of (1) time and (2) different language conditions (English and German) on measurements of intra-annotator agreement in a hate speech labelling task. While we do not observe the expected lower stability in the different language condition, we find that overall agreement is significantly lower than is implicitly assumed in annotation tasks, which has important implications for dataset reproducibility in NLP.","tags":["annotation","NLP","sociodemographics"],"title":"Temporal and Second Language Influence on Intra-Annotator Agreement and Stability in Hate Speech Labelling","type":"publication"},{"authors":["Matthias Orlikowski","Paul Röttger","Philipp Cimiano","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"4abddd30922258b0fac152dcdf4b69f0","permalink":"https://dirkhovy.com/publication/2023-ecological-fallacy-annotation-modeling-human-label-variation-goes-beyond-sociodemographics/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-ecological-fallacy-annotation-modeling-human-label-variation-goes-beyond-sociodemographics/","section":"publication","summary":"Many NLP tasks exhibit human label variation, where different annotators give different labels to the same texts. This variation is known to depend, at least in part, on the sociodemographics of annotators. Recent research aims to model individual annotator behaviour rather than predicting aggregated labels, and we would expect that sociodemographic information is useful for these models. On the other hand, the ecological fallacy states that aggregate group behaviour, such as the behaviour of the average female annotator, does not necessarily explain individual behaviour. To account for sociodemographics in models of individual annotator behaviour, we introduce group-specific layers to multi-annotator models. In a series of experiments for toxic content detection, we find that explicitly accounting for sociodemographic attributes in this way does not significantly improve model performance. This result shows that individual annotation behaviour depends on much more than just sociodemographics.","tags":["annotation","NLP","sociodemographics"],"title":"The Ecological Fallacy in Annotation: Modeling Human Label Variation goes beyond Sociodemographics","type":"publication"},{"authors":["Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"1ebebe2dde0f3ca3bcb2976010570452","permalink":"https://dirkhovy.com/publication/2023-prof-profanity-obfuscation-nlp/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-prof-profanity-obfuscation-nlp/","section":"publication","summary":"Work on hate speech has made considering rude and harmful examples in scientific publications inevitable. This situation raises various problems, such as whether or not to obscure profanities. While science must accurately disclose what it does, the unwarranted spread of hate speech can harm readers and increases its internet frequency. While maintaining publications’ professional appearance, obfuscating profanities makes it challenging to evaluate the content, especially for non-native speakers. Surveying 150 ACL papers, we discovered that obfuscation is usually used for English but not other languages, and even then, quite unevenly. We discuss the problems with obfuscation and suggest a multilingual community resource called PrOf with a Python module to standardize profanity obfuscation processes. We believe PrOf can help scientific publication policies to make hate speech work accessible and comparable, irrespective of language.","tags":["Hate Speech","NLP","multilingual"],"title":"The State of Profanity Obfuscation in Natural Language Processing Scientific Publications","type":"publication"},{"authors":["Anne Lauscher","Debora Nozza","Ehm Miltersen","Archie Crowley","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"ff9d8520053fa8f944c7faa36dfc35da","permalink":"https://dirkhovy.com/publication/2023-commercial-machine-translation-fail-neopronouns/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-commercial-machine-translation-fail-neopronouns/","section":"publication","summary":"As 3rd-person pronoun usage shifts to include novel forms, e.g., neopronouns, we need more research on identity-inclusive NLP. Exclusion is particularly harmful in one of the most popular NLP applications, machine translation (MT). Wrong pronoun translations can discriminate against marginalized groups, e.g., non-binary individuals (Dev et al., 2021). In this “reality check”, we study how three commercial MT systems translate 3rd-person pronouns. Concretely, we compare the translations of gendered vs. gender-neutral pronouns from English to five other languages (Danish, Farsi, French, German, Italian), and vice versa, from Danish to English.Our error analysis shows that the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors. Similarly, gender neutrality is often not preserved. By surveying the opinions of affected native speakers from diverse languages, we provide recommendations to address the issue in future MT research.","tags":["NLP","pronouns","fairness","ethics"],"title":"What about ''em''? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns","type":"publication"},{"authors":["Anne Lauscher","Debora Nozza","Ehm Miltersen","Archie Crowley","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"fd19c1177957eaded55b19f54d5290bc","permalink":"https://dirkhovy.com/publication/2023-interpretability-for-fairer-machine-translation/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-interpretability-for-fairer-machine-translation/","section":"publication","summary":"As 3rd-person pronoun usage shifts to include novel forms, e.g., neopronouns, we need more research on identity-inclusive NLP. Exclusion is particularly harmful in one of the most popular NLP applications, machine translation (MT). Wrong pronoun translations can discriminate against marginalized groups, e.g., non-binary individuals (Dev et al., 2021). In this “reality check”, we study how three commercial MT systems translate 3rd-person pronouns. Concretely, we compare the translations of gendered vs. gender-neutral pronouns from English to five other languages (Danish, Farsi, French, German, Italian), and vice versa, from Danish to English.Our error analysis shows that the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors. Similarly, gender neutrality is often not preserved. By surveying the opinions of affected native speakers from diverse languages, we provide recommendations to address the issue in future MT research.","tags":["NLP","pronouns","fairness","ethics"],"title":"What about ''em''? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns","type":"publication"},{"authors":["Tommaso Fornaciari","Luca Luceri","Emilio Ferrara","Dirk Hovy"],"categories":[],"content":"","date":1685923200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685923200,"objectID":"d77d8b1e10205c823e23d8f2019f4585","permalink":"https://dirkhovy.com/publication/2023-leveraging-social-interactions-detect-misinformation-social-media/","publishdate":"2023-06-05T14:48:20+01:00","relpermalink":"/publication/2023-leveraging-social-interactions-detect-misinformation-social-media/","section":"publication","summary":"Detecting misinformation threads is crucial to guarantee a healthy environment on social media. We address the problem using the data set created during the COVID-19 pandemic. It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source. The models identifying unreliable threads usually rely on textual features. But reliability is not just what is said, but by whom and to whom. We additionally leverage on network information. Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not. We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework. Keeping track of thesequence of the interactions during the time, we improve over previous state-of-the-art models.","tags":["misinformation","NLP","social media","networks"],"title":"Leveraging Social Interactions to Detect Misinformation on Social Media","type":"publication"},{"authors":[],"categories":null,"content":" ","date":1684853132,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684853132,"objectID":"a95585153d2bd2562f2efc2b00e954f9","permalink":"https://dirkhovy.com/talk/padova2023/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/padova2023/","section":"talk","summary":"","tags":["talk"],"title":"Before and after chatGPT: chances, changes, and opportunities of large language models in research","type":"talk"},{"authors":["Sunipa Dev","Vinodkumar Prabhakaran","David Adelani","Dirk Hovy","Luciana Benotti"],"categories":[],"content":"","date":1683331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683331200,"objectID":"9e1fac152996630e6fb17446c2ddd42a","permalink":"https://dirkhovy.com/publication/2023-proceedings-c3nlp/","publishdate":"2023-05-06T14:48:20+01:00","relpermalink":"/publication/2023-proceedings-c3nlp/","section":"publication","summary":"Natural Language Processing has seen impressive gains in recent years. This research includes the demonstration by NLP models to have turned into useful technologies with improved capabilities, measured in terms of how well they match human behavior captured in web-scale language data or through annotations. However, human behavior is inherently shaped by the cultural contexts humans are embedded in, the values and beliefs they hold, and the social practices they follow, part of which will be reflected in the data used to train NLP models, and the behavior these NLP models exhibit. This workshop will bring together NLP researchers invested in this work, along with a community of scholars with multi-disciplinary expertise spanning linguistics, social sciences, and cultural anthropology.","tags":["computational social science","NLP","culture"],"title":"Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP)","type":"publication"},{"authors":["Chia-chien Hung","Anne Lauscher","Dirk Hovy","Simone Paolo Ponzetto","Goran Glavaš"],"categories":[],"content":"","date":1682985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682985600,"objectID":"3c029d51f2b8c8bba4e070b7cafee2cc","permalink":"https://dirkhovy.com/publication/2023-can-demographic-factors-improve-text-classification/","publishdate":"2023-05-02T14:48:20+01:00","relpermalink":"/publication/2023-can-demographic-factors-improve-text-classification/","section":"publication","summary":"Demographic factors (e.g., gender or age) shape our language. Previous work showed that incorporating demographic factors can consistently improve performance for various NLP tasks with traditional NLP models. In this work, we investigate whether these previous findings still hold with state-of-the-art pretrained Transformer-based language models (PLMs). We use three common specialization methods proven effective for incorporating external knowledge into pretrained Transformers (e.g., domain-specific or geographic knowledge). We adapt the language representations for the demographic dimensions of gender and age, using continuous language modeling and dynamic multi-task learning for adaptation, where we couple language modeling objectives with the prediction of demographic classes. Our results, when employing a multilingual PLM, show substantial gains in task performance across four languages (English, German, French, and Danish), which is consistent with the results of previous work. However, controlling for confounding factors – primarily domain and language proficiency of Transformer-based PLMs – shows that downstream performance gains from our demographic adaptation do not actually stem from demographic knowledge. Our results indicate that demographic specialization of PLMs, while holding promise for positive societal impact, still represents an unsolved problem for (modern) NLP.","tags":["NLP","language models","demographics"],"title":"Can Demographic Factors Improve Text Classification? Revisiting Demographic Adaptation in the Age of Transformers","type":"publication"},{"authors":null,"categories":["items"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"8b6a5370faffe8ef8b097fcb670e4010","permalink":"https://dirkhovy.com/item/06/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/06/","section":"item","summary":"Baby shoes I made for a colleague.","tags":["chrometan","items","shoes"],"title":"Baby Shoes","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"d06cc6fa4433a2a966fa41c55e4fddf6","permalink":"https://dirkhovy.com/item/14/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/14/","section":"item","summary":"Pair of small belt pouches I made for my godson.","tags":["vegtan","bags","boxes"],"title":"Belt Pouches","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"159de40af9dde8cf21f29460c6d9737f","permalink":"https://dirkhovy.com/item/13/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/13/","section":"item","summary":"Small clutch bag I made in the same style as the luggage bag for my son. First experiment with dye.","tags":["vegtan","bags","strap","handle","boxes"],"title":"Clutch Bag","type":"item"},{"authors":null,"categories":["items"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"9b468a0e8186973778179e2c74dd73b8","permalink":"https://dirkhovy.com/item/15/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/15/","section":"item","summary":"A dice tray I made for a friend.","tags":["chrometan","items"],"title":"Dice Tray","type":"item"},{"authors":null,"categories":["NLP","hate speech"],"content":"Hate speech is one of the most central problems of online life, with real-life consequences: various hate crimes started as online hate. 1 in 4 users have been harassed online (Pew Research), 63% of the targets are women (Cox commission). The pandemic-related increase of online activity has only intensified this problem: over 500 million messages are sent each day. To address this problem, content providers and policymakers need automated assistance in spotting and addressing hateful comments. INDOMITA will provide those methods.\nBut hate speech is complex. What is considered offensive varies by social norms and user demographics. \u0026ldquo;Yo, a**hole!\u0026rdquo; is acceptable among friends, but problematic with strangers. But current hate speech detection only uses the words in a message to determine whether it is hate speech or not. It does not consider who says those words and to whom, potentially missing subtle forms of hate speech and mislabeling harmless interactions due to overreliance on keywords. This overly simplified approach is a significant limitation. Our user-based approach will address that.\nBut \u0026ldquo;better\u0026rdquo; detection is subjective: people have very different thresholds for what they find offensive. Current evaluation metrics do not allow for such nuance. Any tool that improves the overall detection rate will be judged sufficient. But a tool that works great for most users, but fails for some other groups might achieve good performance. It still fails in the task it was designed to do. Our fairness metrics will correct this.\nBut detection alone does not solve the problem. Interventions like counterspeech or education have a lasting impact on abusive users. It can be enough to alert them to the hurtful nature of their message. At other times, they will only respond if someone they perceive as authoritative engages in a discussion. This decision requires an understanding of the abusive user\u0026rsquo;s social context. Our user-based counterspeech approach facilitates this.\nOur novel, user-centered approach will address hatespeech in three ways:\ncomprehensively modeling a complex issue to improve detection across input formats (text, images, and video), by incorporating socio-demographic context into the model. developing methods to automate counterspeech and to address abusive users effectively. developing evaluation metrics that assess fairness and performance and account for the subjective nature of hate speech. In sum, our user focus will revolutionize existing research on hate speech detection, both in Italian and other languages, to give authorities and media providers better ways to assess content for immediate countermeasures. It will allow us to bridge language differences more easily than purely text-based methods, as we capture socio-behavioral patterns that generalize across languages. It will generate revolutionary insights of the complex dynamics between online actors and the generation of online hate.\nINDOMITA is supported by a MUR FARE 2020 initiative under grant agreement Prot. R20YSMBZ8S.\n","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"5af9db37d16b9da1095a77d2e9b2ea3b","permalink":"https://dirkhovy.com/project/indomita/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/project/indomita/","section":"project","summary":"Innovative Demographically-aware Hate Speech Detection in Online Media in Italian","tags":["demographic","social media","NLP"],"title":"INDOMITA","type":"project"},{"authors":null,"categories":["items"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"f6ffbf28c9f7359c1242e30fb76a8d73","permalink":"https://dirkhovy.com/item/09/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/09/","section":"item","summary":"A leather apron I made for my brother.","tags":["chrometan","items"],"title":"Leather Apron","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"98bc7a8fa66e1811386d020fb7539e6b","permalink":"https://dirkhovy.com/item/11/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/11/","section":"item","summary":"Small bag I made for myself, inspired by old-timey doctor's bags.","tags":["chrometan","bags","strap","handle","boxes"],"title":"Little Brown Bag","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"1db67674eef0dc23805e0e437efe8bef","permalink":"https://dirkhovy.com/item/12/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/12/","section":"item","summary":"A small suitcase bag I made for my son.","tags":["vegtan","bags","handle","boxes"],"title":"Luggage","type":"item"},{"authors":null,"categories":["items"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"5ef67cc218d1c1b98032c7cf4399ddb9","permalink":"https://dirkhovy.com/item/16/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/16/","section":"item","summary":"Napkin rings with embossed names.","tags":["vegtan","items","embossed"],"title":"Napkin rings","type":"item"},{"authors":null,"categories":["items"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"4690fe12463cb3fef43f9b0c458ee4d3","permalink":"https://dirkhovy.com/item/02/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/02/","section":"item","summary":"Notebook cover with string closure.","tags":["chrometan","cover"],"title":"Notebook Cover","type":"item"},{"authors":null,"categories":["items"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"206b7283e4f3aac234396e056bf114cc","permalink":"https://dirkhovy.com/item/03/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/03/","section":"item","summary":"Notebook cover with push buttons.","tags":["chrometan","cover"],"title":"Notebook Cover","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"862e4edad1597d620e5964cd25ab4f69","permalink":"https://dirkhovy.com/item/07/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/07/","section":"item","summary":"A pencil case I made for my father.","tags":["vegtan","bags","boxes"],"title":"Pencil Case","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"6b1c448c36356b7ad128024e1f48d3e4","permalink":"https://dirkhovy.com/item/08/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/08/","section":"item","summary":"Simple bag based on a binocular case I made for a friend.","tags":["vegtan","bags","strap","boxes"],"title":"Simple Bag","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"da79b99195497184c23efa8037def20f","permalink":"https://dirkhovy.com/item/10/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/10/","section":"item","summary":"Small bag in taco shape. I made this bag for my mother.","tags":["vegtan","bags","strap","handle"],"title":"Taco Bag","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"3a16edfb54887de97c88ed2ecfa17f9e","permalink":"https://dirkhovy.com/item/01/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/01/","section":"item","summary":"The first bag I made for my wife. Comes with different colored exchangeable straps.","tags":["vegtan","totes","bags","strap","handle"],"title":"Tote Bag","type":"item"},{"authors":null,"categories":["bags"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"93188e8d817df9122fcd9af1939a3d44","permalink":"https://dirkhovy.com/item/04/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/04/","section":"item","summary":"Large tote bag with sturdy handles. The second bag I made for my wife.","tags":["chrometan","bags","handle"],"title":"Tote Bag with Handles","type":"item"},{"authors":null,"categories":["items"],"content":"","date":1681344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681344000,"objectID":"f291537e7f7e0881d016a79ae0f5e428","permalink":"https://dirkhovy.com/item/05/","publishdate":"2023-04-13T00:00:00Z","relpermalink":"/item/05/","section":"item","summary":"A viking helmet (Gjermundu style) I made for my godson.","tags":["vegtan","items","helmet","rivets"],"title":"Viking Helmet","type":"item"},{"authors":["Donya Rooein","Amanda Cercas Curry","Dirk Hovy"],"categories":[],"content":"","date":1681257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681257600,"objectID":"d47bea93b523ae78237df41065e8b24f","permalink":"https://dirkhovy.com/publication/2023-know-your-audience-education/","publishdate":"2023-04-12T17:19:53+01:00","relpermalink":"/publication/2023-know-your-audience-education/","section":"publication","summary":"Large language models (LLMs) offer a range of new possibilities, including adapting the text to different audiences and their reading needs. But how well do they adapt? We evaluate the readability of answers generated by four state-of-the-art LLMs (commercial and open-source) to science questions when prompted to target different age groups and education levels. To assess the adaptability of LLMs to diverse audiences, we compare the readability scores of the generated responses against the recommended comprehension level of each age and education group. We find large variations in the readability of the answers by different LLMs. Our results suggest LLM answers need to be better adapted to the intended audience demographics to be more comprehensible. They underline the importance of enhancing the adaptability of LLMs in education settings to cater to diverse age and education levels. Overall, current LLMs have set readability ranges and do not adapt well to different audiences, even when prompted. That limits their potential for educational purposes.","tags":["Education","NLP","LLMs"],"title":"Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?","type":"publication"},{"authors":["Rishav Hada","Amir Ebrahimi Fard","Sarah Shugars","Federico Bianchi","Patricia Rossini","Dirk Hovy","Rebekah Tromble","Nava Tintareva"],"categories":[],"content":"","date":1677456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677456000,"objectID":"0dd3066b1e69e63f2f33c17401858cd2","permalink":"https://dirkhovy.com/publication/2023-beyond-digital-echo-chambers-role-viewpoint-diversity-political-discussion/","publishdate":"2023-02-27T14:48:20+01:00","relpermalink":"/publication/2023-beyond-digital-echo-chambers-role-viewpoint-diversity-political-discussion/","section":"publication","summary":"Increasingly taking place in online spaces, modern political conversations are typically perceived to be unproductively affirming---siloed in so called 'echo chambers' of exclusively like-minded discussants. Yet, to date we lack sufficient means to measure viewpoint diversity in conversations. To this end, in this paper, we operationalize two viewpoint metrics proposed for recommender systems and adapt them to the context of social media conversations. This is the first study to apply these two metrics (Representation and Fragmentation) to real world data and to consider the implications for online conversations specifically. We apply these measures to two topics---daylight savings time (DST), which serves as a control, and the more politically polarized topic of immigration. We find that the diversity scores for both Fragmentation and Representation are lower for immigration than for DST. Further, we find that while pro-immigrant views receive consistent pushback on the platform, anti-immigrant views largely operate within echo chambers. We observe less severe yet similar patterns for DST. Taken together, Representation and Fragmentation paint a meaningful and important new picture of viewpoint diversity.","tags":["NLP","computational social science","political science","echo chambers"],"title":"Beyond Digital 'Echo Chambers': The Role of Viewpoint Diversity in Political Discussion","type":"publication"},{"authors":[],"categories":null,"content":"","date":1676703632,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676703632,"objectID":"bdd2053248e03f55fff55c6dc885ee1b","permalink":"https://dirkhovy.com/talk/bigquestions2023/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/bigquestions2023/","section":"talk","summary":"","tags":["podcast"],"title":"Conversations on Sustainable Development: ChatGPT","type":"talk"},{"authors":[],"categories":null,"content":"","date":1675926032,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675926032,"objectID":"d8f4b46196861ed2f3c4051211d3270d","permalink":"https://dirkhovy.com/talk/letschatethics2023/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/letschatethics2023/","section":"talk","summary":"","tags":["podcast"],"title":"Let's Chat ChatGPT","type":"talk"},{"authors":["Federico Bianchi","Amanda Cercas Curry","Dirk Hovy"],"categories":[],"content":"","date":1673136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673136000,"objectID":"c607865224483ec3caddadf624167af7","permalink":"https://dirkhovy.com/publication/2023-ai-normal-accidents-waiting-happen/","publishdate":"2023-01-08T14:48:20+01:00","relpermalink":"/publication/2023-ai-normal-accidents-waiting-happen/","section":"publication","summary":"Artificial Intelligence (AI) is at a crucial point in its development: stable enough to be used in production systems, and increasingly pervasive in our lives. What does that mean for its safety? In his book Normal Accidents, the sociologist Charles Perrow proposed a framework to analyze new technologies and the risks they entail. He showed that major accidents are nearly unavoidable in complex systems with tightly coupled components if they are run long enough. In this essay, we apply and extend Perrow’s framework to AI to assess its potential risks. Today’s AI systems are already highly complex, and their complexity is steadily increasing. As they become more ubiquitous, different algorithms will interact directly, leading to tightly coupled systems whose capacity to cause harm we will be unable to predict. We argue that under the current paradigm, Perrow’s normal accidents apply to AI systems and it is only a matter of time before one occurs.","tags":["AI","models","sociology"],"title":"Viewpoint: Artificial Intelligence Accidents Waiting to Happen?","type":"publication"},{"authors":["Federico Bianchi","Stefanie Hills","Patricia Rossini","Dirk Hovy","Rebekah Tromble","Nava Tintarev"],"categories":[],"content":"","date":1670803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670803200,"objectID":"281aa24403feb3bfd4b39889e2df47e3","permalink":"https://dirkhovy.com/publication/2022-not_just_hate/","publishdate":"2022-12-12T14:48:20+01:00","relpermalink":"/publication/2022-not_just_hate/","section":"publication","summary":"Well-annotated data is a prerequisite for good Natural Language Processing models. Too often, though, annotation decisions are governed by optimizing time or annotator agreement. We make a case for nuanced efforts in an interdisciplinary setting for annotating offensive online speech. Detecting offensive content is rapidly becoming one of the most important real-world NLP tasks. However, most datasets use a single binary label, e.g., for hate or incivility, even though each concept is multi-faceted. This modeling choice severely limits nuanced insights, but also performance.We show that a more fine-grained multi-label approach to predicting incivility and hateful or intolerant content addresses both conceptual and performance issues.We release a novel dataset of over 40,000 tweets about immigration from the US and UK, annotated with six labels for different aspects of incivility and intolerance.Our dataset not only allows for a more nuanced understanding of harmful speech online, models trained on it also outperform or match performance on benchmark datasets","tags":["Hate Speech","NLP","dataset"],"title":"It's Not Just Hate: A Multi-Dimensional Perspective on Detecting Harmful Speech Online","type":"publication"},{"authors":["Federico Bianchi","Vincenzo Cutrona","Dirk Hovy"],"categories":[],"content":"","date":1670803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670803200,"objectID":"3ac3335b591cf77ff6390c5bf2664375","permalink":"https://dirkhovy.com/publication/2022-twitter_demographer/","publishdate":"2022-12-12T14:48:20+01:00","relpermalink":"/publication/2022-twitter_demographer/","section":"publication","summary":"Twitter data have become essential to Natural Language Processing (NLP) and social science research, driving various scientific discoveries in recent years. However, the textual data alone are often not enough to conduct studies: especially, social scientists need more variables to perform their analysis and control for various factors. How we augment this information, such as users’ location, age, or tweet sentiment, has ramifications for anonymity and reproducibility, and requires dedicated effort. This paper describes Twitter-Demographer, a simple, flow-based tool to enrich Twitter data with additional information about tweets and users. {tool is aimed at NLP practitioners, psycho-linguists, and (computational) social scientists who want to enrich their datasets with aggregated information, facilitating reproducibility, and providing algorithmic privacy-by-design measures for pseudo-anonymity. We discuss our design choices, inspired by the flow-based programming paradigm, to use black-box components that can easily be chained together and extended. We also analyze the ethical issues related to the use of this tool, and the built-in measures to facilitate pseudo-anonymity.","tags":["Social Media","NLP","dataset","Twitter"],"title":"Twitter-Demographer: A Flow-based Tool to Enrich Twitter Data","type":"publication"},{"authors":["Marius Hessenthaler","Emma Strubell","Dirk Hovy","Anne Lauscher"],"categories":[],"content":"","date":1670630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670630400,"objectID":"c8e28f24b48da4ce4375ff8698f4155c","permalink":"https://dirkhovy.com/publication/2022-bridging_fairness_and_environmental_sustainability_in_natural_language_processing/","publishdate":"2022-12-12T14:48:20+01:00","relpermalink":"/publication/2022-bridging_fairness_and_environmental_sustainability_in_natural_language_processing/","section":"publication","summary":"Fairness and environmental impact are important research directions for the sustainable development of artificial intelligence. However, while each topic is an active research area in natural language processing (NLP), there is a surprising lack of research on the interplay between the two fields. This lacuna is highly problematic, since there is increasing evidence that an exclusive focus on fairness can actually hinder environmental sustainability, and vice versa. In this work, we shed light on this crucial intersection in NLP by (1) investigating the efficiency of current fairness approaches through surveying example methods for reducing unfair stereotypical bias from the literature, and (2) evaluating a common technique to reduce energy consumption (and thus environmental impact) of English NLP models, knowledge distillation (KD), for its impact on fairness. In this case study, we evaluate the effect of important KD factors, including layer and dimensionality reduction, with respect to: (a) performance on the distillation task (natural language inference and semantic similarity prediction), and (b) multiple measures and dimensions of stereotypical bias (e.g., gender bias measured via the Word Embedding Association Test). Our results lead us to clarify current assumptions regarding the effect of KD on unfair bias: contrary to other findings, we show that KD can actually decrease model fairness.","tags":["NLP","fairness","sustainability"],"title":"Bridging Fairness and Environmental Sustainability in Natural Language Processing","type":"publication"},{"authors":["Anne Lauscher","Federico Bianchi","Samuel R. Bowman","Dirk Hovy"],"categories":[],"content":"","date":1670630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670630400,"objectID":"d3d511c9d6fd6b178e0bf4de6bc057c3","permalink":"https://dirkhovy.com/publication/2022-socioprobe_what_when_where_language_models_learn_about_sociodemographics/","publishdate":"2022-12-10T14:48:20+01:00","relpermalink":"/publication/2022-socioprobe_what_when_where_language_models_learn_about_sociodemographics/","section":"publication","summary":"Pre-trained language models (PLMs) have outperformed other NLP models on a wide range of tasks. Opting for a more thorough understanding of their capabilities and inner workings, researchers have established the extend to which they capture lower-level knowledge like grammaticality, and mid-level semantic knowledge like factual understanding. However, there is still little understanding of their knowledge of higher-level aspects of language. In particular, despite the importance of sociodemographic aspects in shaping our language, the questions of whether, where, and how PLMs encode these aspects, e.g., gender or age, is still unexplored. We address this research gap by probing the sociodemographic knowledge of different single-GPU PLMs on multiple English data sets via traditional classifier probing and information-theoretic minimum description length probing. Our results show that PLMs do encode these sociodemographics, and that this knowledge is sometimes spread across the layers of some of the tested PLMs. We further conduct a multilingual analysis and investigate the effect of supplementary training to further explore to what extent, where, and with what amount of pre-training data the knowledge is encoded. Our overall results indicate that sociodemographic knowledge is still a major challenge for NLP. PLMs require large amounts of pre-training data to acquire the knowledge and models that excel in general language understanding do not seem to own more knowledge about these aspects.","tags":["NLP","sociodemographics","transformers","language models"],"title":"SocioProbe: What, When, and Where Language Models Learn about Sociodemographics","type":"publication"},{"authors":["Paul Röttger","Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1666224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666224000,"objectID":"a2ca0d19f38470541be45569c6948729","permalink":"https://dirkhovy.com/publication/2022-strategies-hate-speech-detection-under-resourced-languages/","publishdate":"2022-10-20T14:48:20+01:00","relpermalink":"/publication/2022-strategies-hate-speech-detection-under-resourced-languages/","section":"publication","summary":"Hate speech is a global phenomenon, but most hate speech datasets so far focus on English-language content. This hinders the development of more effective hate speech detection models in hundreds of languages spoken by billions across the world. More data is needed, but annotating hateful content is expensive, time-consuming and potentially harmful to annotators. To mitigate these issues, we explore data-efficient strategies for expanding hate speech detection into under-resourced languages. In a series of experiments with mono- and multilingual models across five non-English languages, we find that 1) a small amount of target-language fine-tuning data is needed to achieve strong performance, 2) the benefits of using more such data decrease exponentially, and 3) initial fine-tuning on readily-available English data can partially substitute target-language data and improve model generalisability. Based on these findings, we formulate actionable recommendations for hate speech detection in low-resource language settings.","tags":["Hate Speech","NLP","multilingual"],"title":"Data-Efficient Strategies for Expanding Hate Speech Detection into Under-Resourced Languages","type":"publication"},{"authors":["Giuseppe Attanasio","Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1665619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665619200,"objectID":"bcb8bb12e133a3d8b26d9091bc35a703","permalink":"https://dirkhovy.com/publication/2022-limitation-diachronic-continuous-training/","publishdate":"2022-10-13T14:48:20+01:00","relpermalink":"/publication/2022-limitation-diachronic-continuous-training/","section":"publication","summary":"Language is constantly changing and evolving, leaving language models to quickly become outdated, both factually and linguistically. Recent research proposes we continuously update our models using new data. Continuous training allows us to teach language models about new events and facts and changing norms. However, continuous training also means continuous costs. We show there is currently limited evidence for the benefits of continuous training, be it for the actual downstream performance or the environmental cost. Our results show continuous training does not significantly improve performance. While it is clear that, sooner or later, our language models need to be updated, it is unclear when this effort is worth the cost. We call for a critical reflection about when and how to use continuous training and for more benchmarks to support this research direction.","tags":["NLP","BERT"],"title":"Is It Worth the (Environmental) Cost? Limited Evidence for the Benefits of Diachronic Continuous Training","type":"publication"},{"authors":["Anne Lauscher","Archie Crowley","Dirk Hovy"],"categories":[],"content":"","date":1665532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665532800,"objectID":"a7cbc519326b6c1f4579513c619bb3ac","permalink":"https://dirkhovy.com/publication/2022-welcome_modern_world_pronouns_identity-inclusive_natural_language_processing_beyond_gender/","publishdate":"2022-10-12T14:48:20+01:00","relpermalink":"/publication/2022-welcome_modern_world_pronouns_identity-inclusive_natural_language_processing_beyond_gender/","section":"publication","summary":"The world of pronouns is changing – from a closed word class with few members to an open set of terms to reflect identities. However, Natural Language Processing (NLP) barely reflects this linguistic shift, resulting in the possible exclusion of non-binary users, even though recent work outlined the harms of gender-exclusive language technology. The current modeling of 3rd person pronouns is particularly problematic. It largely ignores various phenomena like neopronouns, i.e., novel pronoun sets that are not (yet) widely established. This omission contributes to the discrimination of marginalized and underrepresented groups, e.g., non-binary individuals. It thus prevents gender equality, one of the UN’s sustainable development goals (goal 5). Further, other identity-expressions beyond gender are ignored by current NLP technology. This paper provides an overview of 3rd person pronoun issues for NLP. Based on our observations and ethical considerations, we define a series of five desiderata for modeling pronouns in language technology, which we validate through a survey. We evaluate existing and novel modeling approaches w.r.t. these desiderata qualitatively and quantify the impact of a more discrimination-free approach on an established benchmark dataset.","tags":["NLP","pronouns","fairness","ethics"],"title":"Welcome to the Modern World of Pronouns: Identity-Inclusive Natural Language Processing beyond Gender","type":"publication"},{"authors":["A. Stevie Bergman","Gavin Abercrombie","Shannon Spruit","Dirk Hovy","Emily Dinan","Y-Lan Boureau","Verena Rieser"],"categories":[],"content":"","date":1662940800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662940800,"objectID":"3acc9d4e5de91b3e10aeb9ecb187107d","permalink":"https://dirkhovy.com/publication/2022-guiding_release_safer_e2e_conversational_ai_through_value_sensitive_design/","publishdate":"2022-09-12T14:48:20+01:00","relpermalink":"/publication/2022-guiding_release_safer_e2e_conversational_ai_through_value_sensitive_design/","section":"publication","summary":"Over the last several years, end-to-end neural conversational agents have vastly improved their ability to carry unrestricted, open-domain conversations with humans. However, these models are often trained on large datasets from the Internet and, as a result, may learn undesirable behaviours from this data, such as toxic or otherwise harmful language. Thus, researchers must wrestle with how and when to release these models. In this paper, we survey recent and related work to highlight tensions between values, potential positive impact, and potential harms. We also provide a framework to support practitioners in deciding whether and how to release these models, following the tenets of value-sensitive design.","tags":["NLP","NLG","fairness","ethics","value sensitive design","chatbots"],"title":"Guiding the Release of Safer E2E Conversational AI through Value Sensitive Design","type":"publication"},{"authors":["Tommaso Fornaciari","Alexandra Uma","Massimo Poesio","Dirk Hovy"],"categories":[],"content":"","date":1652313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652313600,"objectID":"9827bbbeabf9916ea04af9f70ca7d9ed","permalink":"https://dirkhovy.com/publication/2022-hard_soft_evaluation_nlp_models_bootstrap_sampling-boostsa/","publishdate":"2022-05-12T14:48:20+01:00","relpermalink":"/publication/2022-hard_soft_evaluation_nlp_models_bootstrap_sampling-boostsa/","section":"publication","summary":"Natural Language Processing (NLP) ‘s applied nature makes it necessary to select the most effective and robust models. Producing slightly higher performance is insufficient; we want to know whether this advantage will carry over to other data sets. Bootstrapped significance tests can indicate that ability.So while necessary, computing the significance of models’ performance differences has many levels of complexity. It can be tedious, especially when the experimental design has many conditions to compare and several runs of experiments.We present BooStSa, a tool that makes it easy to compute significance levels with the BOOtSTrap SAmpling procedure to evaluate models that predict not only standard hard labels but soft-labels (i.e., probability distributions over different classes) as well.","tags":["NLP","bootstrap sampling","stats","p-value"],"title":"Hard and Soft Evaluation of NLP models with BOOtSTrap SAmpling - BooStSa","type":"publication"},{"authors":["Federico Bianchi","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1650499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650499200,"objectID":"100083027ef95cdeecf37cf18bd6bf97","permalink":"https://dirkhovy.com/publication/2022-language-invariant-properties-nlp/","publishdate":"2022-04-12T14:48:20+01:00","relpermalink":"/publication/2022-language-invariant-properties-nlp/","section":"publication","summary":"Meaning is context-dependent, but many properties of language (should) remain the same even if we transform the context. For example, sentiment, entailment, or speaker properties should be the same in a translation and original of a text. We introduce language invariant properties: i.e., properties that should not change when we transform text, and how they can be used to quantitatively evaluate the robustness of transformation algorithms. We use translation and paraphrasing as transformation examples, but our findings apply more broadly to any transformation. Our results indicate that many NLP transformations change properties like author characteristics, i.e., make them sound more male. We believe that studying these properties will allow NLP to address both social factors and pragmatic aspects of language. We also release an application suite that can be used to evaluate the invariance of transformation applications.","tags":["NLP","Language Invariant Properties","Meaning"],"title":"Language Invariant Properties in Natural Language Processing","type":"publication"},{"authors":null,"categories":["NLP","computational social science"],"content":"Over the last decade, discontent in democracy, mistrust in institutions, and the rise of populist parties have strained European societies. Underlying these tensions are often increasing inequalities in Western countries, which fuel the discontent of individuals. The Covid pandemic further exacerbated these problems, as anti-Covid measures taken by governments differently impacted societal groups.\nThe MENTALISM project, funded by Fondazione Cariplo under grant agreement 2022-1480, combines modern social media analysis with traditional survey data to track inequality across Italy through the lens of the pandemic.\nOur ground-breaking mixed-methods approach uses machine learning and text analysis to trace online grievances in a vast corpus of social media data. We combine these methods with survey protocols and econometric analysis to validate the findings and provide actionable policy advice. MENTALISM combines the advantages of social media data (high-frequency, individual-level information) with the strength of socio-economic surveys (representativeness). Our novel interdisciplinary approach will critically evaluate the value of social media monitoring for policy feedback. Moreover, it will establish protocols for policymakers to better respond to growing grievances brought on by inequality at various steps in the process.\nThis interdisciplinary project is led by Profs. Carlo Schwarz (economics), and Dirk Hovy (NLP).\n","date":1649808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649808000,"objectID":"f1efa90206391b8dcd0df63edbc66767","permalink":"https://dirkhovy.com/project/mentalism/","publishdate":"2022-04-13T00:00:00Z","relpermalink":"/project/mentalism/","section":"project","summary":"Measuring, Tracking, and Analyzing Inequality using Social Media","tags":["demographic","inequality","economics","social media","NLP"],"title":"MENTALISM","type":"project"},{"authors":["Giuseppe Attanasio","Debora Nozza","Eliana Pastor","Dirk Hovy"],"categories":[],"content":"","date":1649721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649721600,"objectID":"1bc8b1ca2c825938f3fb71def878b8a1","permalink":"https://dirkhovy.com/publication/2022-interpretability-transformer-mysogyny-detection/","publishdate":"2022-04-12T14:48:20+01:00","relpermalink":"/publication/2022-interpretability-transformer-mysogyny-detection/","section":"publication","summary":"Transformer-based Natural Language Processing models have become the standard for hate speech detection. However, the unconscious use of these techniques for such a critical task comes with negative consequences. Various works have demonstrated that hate speech classifiers are biased. These findings have prompted efforts to explain classifiers, mainly using attribution methods. In this paper, **we provide the first benchmark study of interpretability approaches for hate speech detection**. We cover four post-hoc token attribution approaches to explain the predictions of Transformer-based misogyny classifiers in English and Italian. Further, we compare generated attributions to attention analysis.  We find that only two algorithms provide faithful explanations aligned with human expectations. Gradient-based methods and attention, however, show inconsistent outputs, making their value for explanations questionable for hate speech detection tasks.","tags":["Hate Speech","BERT","NLP"],"title":"Benchmarking Post-Hoc Interpretability Approaches for Transformer-based Misogyny Detection","type":"publication"},{"authors":["Debora Nozza","Federico Bianchi","Anne Lauscher","Dirk Hovy"],"categories":[],"content":"","date":1649721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649721600,"objectID":"9088977c974224d138af8fd8ed78b98e","permalink":"https://dirkhovy.com/publication/2022-honest-hurtful-language-model-lgbtqia+/","publishdate":"2022-04-12T14:48:20+01:00","relpermalink":"/publication/2022-honest-hurtful-language-model-lgbtqia+/","section":"publication","summary":"Current language technology is ubiquitous and directly influences individuals' lives worldwide. Given the recent trend in AI on training and constantly releasing new and powerful large language models (LLMs), there is a need to assess their biases and potential concrete consequences. While some studies have highlighted the shortcomings of these models, there is only little on the negative impact of LLMs on LGBTQIA+ individuals. In this paper, we investigated a state-of-the-art template-based approach for measuring the harmfulness of English LLMs sentence completion when the subjects belong to the LGBTQIA+ community. Our findings show that, on average, **the most likely LLM-generated completion is an identity attack 13% of the time**. Our results raise serious concerns about the applicability of these models in production environments.","tags":["Hate Speech","BERT","NLP"],"title":"Measuring Harmful Sentence Completion in Language Models for LGBTQIA+ Individuals","type":"publication"},{"authors":["Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1649721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649721600,"objectID":"caa2e3beea8b00d14fdcf83df519c588","permalink":"https://dirkhovy.com/publication/2022-pipelines-social-bias-testing-language-models/","publishdate":"2022-04-12T14:48:20+01:00","relpermalink":"/publication/2022-pipelines-social-bias-testing-language-models/","section":"publication","summary":"The maturity level of language models is now at a stage in which many companies rely on them to solve various tasks. However, while research has shown how biased and harmful these models are, **systematic ways of integrating social bias tests into development pipelines are still lacking. This short paper suggests how to use these verification techniques in development pipelines.** We take inspiration from software testing and suggest addressing social bias evaluation as software testing. We hope to open a discussion on the best methodologies to handle social bias testing in language models.","tags":["Hate Speech","BERT","NLP"],"title":"Pipelines for Social Bias Testing of Large Language Models","type":"publication"},{"authors":["Paul Röttger","Bertie Vidgen","Dirk Hovy","Janet B. Pierrehumbert"],"categories":[],"content":"","date":1649721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649721600,"objectID":"805f462ec62d4458e8694ccd8b6293f5","permalink":"https://dirkhovy.com/publication/2022-two-contrasting-data-annotation-paradigms-subjective-nlp-tasks/","publishdate":"2022-04-12T14:48:20+01:00","relpermalink":"/publication/2022-two-contrasting-data-annotation-paradigms-subjective-nlp-tasks/","section":"publication","summary":"Labelled data is the foundation of most natural language processing tasks. However, labelling data is difficult and there often are diverse valid beliefs about what the correct data labels should be. So far, dataset creators have acknowledged annotator subjectivity, but rarely actively managed it in the annotation process. This has led to partly-subjective datasets that fail to serve a clear downstream use. To address this issue, we propose two contrasting paradigms for data annotation. The descriptive paradigm encourages annotator subjectivity, whereas the prescriptive paradigm discourages it. Descriptive annotation allows for the surveying and modelling of different beliefs, whereas prescriptive annotation enables the training of models that consistently apply one belief. We discuss benefits and challenges in implementing both paradigms, and argue that dataset creators should explicitly aim for one or the other to facilitate the intended use of their dataset. Lastly, we conduct an annotation experiment using hate speech data that illustrates the contrast between the two paradigms.","tags":["Annotation","NLP","dataset"],"title":"Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks","type":"publication"},{"authors":["Federico Bianchi","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1649721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649721600,"objectID":"c798f81abd0bcd706c51aa0ea04a2d12","permalink":"https://dirkhovy.com/publication/2022-xlmemo-multilingual-emotion-prediction/","publishdate":"2022-04-12T14:48:20+01:00","relpermalink":"/publication/2022-xlmemo-multilingual-emotion-prediction/","section":"publication","summary":"Detecting emotion in text allows social and computational scientists to study how people behave and react to online events. However, developing these tools for different languages requires data that is not always available. This paper collects the available emotion detection datasets across 19 languages. We train a multilingual emotion prediction model for social media data, XLM-EMO. The model shows competitive performance in a zero-shot setting, suggesting it is helpful in the context of low-resource languages. We release our model to the community so that interested researchers can directly use it.","tags":["Sentiment Analysis","Emotion Detection","Italian","BERT","NLP","dataset","multilingual"],"title":"XLM-EMO: Multilingual Emotion Prediction in Social Media Text","type":"publication"},{"authors":["Giuseppe Attanasio","Debora Nozza","Dirk Hovy","Elena Baralis"],"categories":[],"content":"","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"b9f7adfa2c36e4d8da97d41a76dcdbf8","permalink":"https://dirkhovy.com/publication/2022-entropy-attention-regularization-bias/","publishdate":"2022-03-17T14:48:20+01:00","relpermalink":"/publication/2022-entropy-attention-regularization-bias/","section":"publication","summary":"Natural Language Processing (NLP) models risk overfitting to specific terms in the training data, thereby reducing their performance, fairness, and generalizability. E.g., neural hate speech detection models are strongly influenced by identity terms like gay, or women, resulting in false positives, severe unintended bias, and lower performance. Most mitigation techniques use lists of identity terms or samples from the target domain during training. However, this approach requires a-priori knowledge and introduces further bias if important terms are neglected. Instead, we propose a knowledge-free Entropy-based Attention Regularization (EAR) to discourage overfitting to training-specific terms. An additional objective function penalizes tokens with low self-attention entropy. We fine-tune BERT via EAR: the resulting model matches or exceeds state-of-the-art performance for hate speech classification and bias metrics on three benchmark corpora in English and Italian. EAR also reveals overfitting terms, i.e., terms most likely to induce bias, to help identify their effect on the model, task, and predictions.","tags":["Hate Speech","Bias","Entropy","Attention","Regularization","NLP"],"title":"Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists","type":"publication"},{"authors":["Emily Dinan","Gavin Abercrombie","A. Stevie Bergman","Shannon Spruit","Dirk Hovy","Y-Lan Boureau","Verena Rieser"],"categories":[],"content":"","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"75ad76dd011e594c70e4a27a81805308","permalink":"https://dirkhovy.com/publication/2022-safetykit-first-aid-measuring-safety-open-domain-conversational-systems/","publishdate":"2022-03-17T14:48:20+01:00","relpermalink":"/publication/2022-safetykit-first-aid-measuring-safety-open-domain-conversational-systems/","section":"publication","summary":"The social impact of natural language processing and its applications has received increasing attention.  In this position paper, we focus on the problem of safety for end-to-end conversational AI. We survey the problem landscape therein, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects. We then empirically assess the extent to which current tools can measure these effects and current systems display them. We release these tools as part of a ``first aid kit'' (SAFETYKIT) to quickly assess apparent safety concerns. Our results show that, while current tools are able to provide an estimate of the relative safety of systems in various settings, they still have several shortcomings. We suggest several future directions and discuss ethical considerations.","tags":["dialog","Bias","conversational AI","NLG","NLP"],"title":"SAFETYKIT: First Aid for Measuring Safety in Open-domain Conversational Systems","type":"publication"},{"authors":["Dirk Hovy"],"categories":[],"content":"","date":1642291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642291200,"objectID":"eb70cdde35ea1df981863c7b83b5fa20","permalink":"https://dirkhovy.com/publication/2022_nlpss2/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2022_nlpss2/","section":"publication","summary":"Text contains a wealth of information about about a wide variety of sociocultural constructs. Automated prediction methods can infer these quantities (sentiment analysis is probably the most well-known application). However, there is virtually no limit to the kinds of things we can predict from text: power, trust, misogyny, are all signaled in language. These algorithms easily scale to corpus sizes infeasible for manual analysis. Prediction algorithms have become steadily more powerful, especially with the advent of neural network methods. However, applying these techniques usually requires profound programming knowledge and machine learning expertise. As a result, many social scientists do not apply them. This Element provides the working social scientist with an overview of the most common methods for text classification, an intuition of their applicability, and Python code to execute them. It covers both the ethical foundations of such work as well as the emerging potential of neural network methods.","tags":["text analysis","social science","NLP","Python","classification"],"title":"Text Analysis in Python for Social Scientists – Prediction and Classification","type":"publication"},{"authors":["Alexandra N Uma","Tommaso Fornaciari","Dirk Hovy","Silviu Paun","Barbara Plank","Massimo Poesio"],"categories":[],"content":"","date":1640563200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640563200,"objectID":"89043ca549ca8b57f7d851ddb9c709fd","permalink":"https://dirkhovy.com/publication/2021-learning_from_disagreement_survey/","publishdate":"2021-12-27T14:48:20+01:00","relpermalink":"/publication/2021-learning_from_disagreement_survey/","section":"publication","summary":"Many tasks in Natural Language Processing (NLP) and Computer Vision (CV) offer evidence that humans disagree, from objective tasks such as part-of-speech tagging to more subjective tasks such as classifying an image or deciding whether a proposition follows from certain premises. While most learning in artificial intelligence (AI) still relies on the assumption that a single (gold) interpretation exists for each item, a growing body of research aims to develop learning methods that do not rely on this assumption. In this survey, we review the evidence for disagreements on NLP and CV tasks, focusing on tasks for which substantial datasets containing this information have been created. We discuss the most popular approaches to training models from datasets containing multiple judgments potentially in disagreement. We systematically compare these different approaches by training them with each of the available datasets, considering several ways to evaluate the resulting models. Finally, we discuss the results in depth, focusing on four key research questions, and assess how the type of evaluation and the characteristics of a dataset determine the answers to these questions. Our results suggest, first of all, that even if we abandon the assumption of a gold standard, it is still essential to reach a consensus on how to evaluate models. This is because the relative performance of the various training methods is critically affected by the chosen form of evaluation. Secondly, we observed a strong dataset effect. With substantial datasets, providing many judgments by high-quality coders for each item, training directly with soft labels achieved better results  than training from aggregated or even gold labels. This result holds for both hard and soft evaluation. But when the above conditions do not hold, leveraging both gold and soft labels generally achieved the best results in the hard evaluation. All datasets and models employed in this paper are freely available as supplementary materials.","tags":["annotation","NLP","disagreement","agreement"],"title":"Learning from Disagreement: A Survey","type":"publication"},{"authors":null,"categories":null,"content":"","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"https://dirkhovy.com/news/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/news/","section":"","summary":"List of news.\n","tags":[],"title":"News","type":"page"},{"authors":["Dirk Hovy","Shrimai Prabhumoye"],"categories":[],"content":"","date":1628208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628208000,"objectID":"2c3bf2de81d5732843e3bf56900eee2d","permalink":"https://dirkhovy.com/publication/2021-five-sources-bias/","publishdate":"2021-05-06T01:41:26+01:00","relpermalink":"/publication/2021-five-sources-bias/","section":"publication","summary":"Recently, there has been an increased interest in demographically grounded bias in natural language processing (NLP) applications. Much of the recent work has focused on describing bias and providing an overview of bias in a larger context. Here, we provide a simple, actionable summary of this recent work. We outline five sources where bias can occur in NLP systems: (1) the data, (2) the annotation process, (3) the input representations, (4) the models, and finally (5) the research design (or how we conceptualize our research). We explore each of the bias sources in detail in this article, including examples and links to related work, as well as potential counter-measures.","tags":["Position Paper","Issues","NLP","bias"],"title":"Five sources of bias in natural language processing","type":"publication"},{"authors":["Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1628208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628208000,"objectID":"ae8849cc748767803b8f7f12282a9f1e","permalink":"https://dirkhovy.com/publication/2021-gap-between-understanding-adoption/","publishdate":"2021-05-06T01:41:26+01:00","relpermalink":"/publication/2021-gap-between-understanding-adoption/","section":"publication","summary":"There are some issues with current research trends in NLP that can hamper the free development of scientific research. We identify five of particular concern: 1) the early adoption of methods without sufficient understanding or analysis; 2) the preference for computational methods regardless of risks associated with their limitations; 3) the resulting bias in the papers we publish; 4) the impossibility of re-running some experiments due to their cost; 5) the dangers of unexplainable methods.  If these issues are not addressed, we risk a loss of reproducibility, reputability, and subsequently public trust in our field. In this position paper, we outline each of these points and suggest ways forward.","tags":["Position Paper","Issues","NLP"],"title":"On the Gap between Adoption and Understanding in NLP","type":"publication"},{"authors":["Federico Bianchi","Silvia Terragni","Dirk Hovy"],"categories":[],"content":"","date":1628208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628208000,"objectID":"e3b6d4f859c0f40521fc0ad7439aa5b6","permalink":"https://dirkhovy.com/publication/2021-contextualized-improve-topic-models-coherence/","publishdate":"2021-05-06T01:41:26+01:00","relpermalink":"/publication/2021-contextualized-improve-topic-models-coherence/","section":"publication","summary":"Topic models extract groups of words from documents, whose interpretation as a topic hopefully allows for a better understanding of the data. However, the resulting word groups are often not coherent, making them harder to interpret. Recently, neural topic models have shown improvements in overall coherence. Concurrently, contextual embeddings have advanced the state of the art of neural models in general. In this paper, we combine contextualized BERT representations with neural topic models. We find that our approach produces more meaningful and coherent topics than traditional bag-of-word topic models and recent neural models. Our results indicate that future improvements in language models will translate into better topic models.","tags":["Topic Modeling","Coherence","NLP"],"title":"Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence","type":"publication"},{"authors":["Tommaso Fornaciari","Dirk Hovy","Elin Naurin","Julia Runeson","Robert Thomson","Pankaj Adhikari"],"categories":[],"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"c7b4b48cb786e0a2763d7f93ab0ed3f5","permalink":"https://dirkhovy.com/publication/2021-aclfindings-mimac/","publishdate":"2021-05-06T01:41:26+01:00","relpermalink":"/publication/2021-aclfindings-mimac/","section":"publication","summary":"In an election campaign, political parties pledge to implement various projects--should they be elected. But do they follow through? To track election pledges from parties' election manifestos, we need to distinguish between pledges and general statements. In this paper, we use election manifestos of Swedish and Indian political parties to learn neural models that distinguish actual pledges from generic political positions. Since pledges might vary by election year and party, we implement a Multi-Task Learning (MTL) setup, predicting election year and manifesto's party as auxiliary tasks. Pledges can also span several sentences, so we use hierarchical models that incorporate contextual information. Lastly, we evaluate the models in a Zero-Shot Learning (ZSL) framework across countries and languages. Our results indicate that year and party have predictive power even in ZSL, while context introduces some noise. We finally discuss the linguistic features of pledges.","tags":["Election pledges","Zero-Shot Learning","NLP"],"title":"'We will Reduce Taxes' - Identifying Election Pledges with Language Models","type":"publication"},{"authors":["Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1622937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622937600,"objectID":"3c6a04000acf7b38009176972f9bf596","permalink":"https://dirkhovy.com/publication/2021-honest-hurtful-language-model/","publishdate":"2021-03-29T14:48:20+01:00","relpermalink":"/publication/2021-honest-hurtful-language-model/","section":"publication","summary":"Language models have revolutionized the field of NLP. However, language models capture and proliferate hurtful stereotypes, especially in text generation. Our results show that **4.3% of the time, language models complete a sentence with a hurtful word**. These cases are not random, but follow language and gender-specific patterns. We propose a score to measure hurtful sentence completions in language models (HONEST). It uses a systematic template- and lexicon-based bias evaluation methodology for six languages. Our findings suggest that these models replicate and amplify deep-seated societal stereotypes about gender roles. Sentence completions refer to sexual promiscuity when the target is female in 9% of the time, and in 4% to homosexuality when the target is male.  The results raise questions about the use of these models in production settings.","tags":["Hate Speech","BERT","NLP"],"title":"HONEST: Measuring Hurtful Sentence Completion in Language Models","type":"publication"},{"authors":["Dirk Hovy","Diyi Yang"],"categories":[],"content":"","date":1622937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622937600,"objectID":"9ebb2f8b0e03f6f8b03537d2944bf15e","permalink":"https://dirkhovy.com/publication/2021-importance-modeling-social-factors-language/","publishdate":"2021-05-06T14:48:20+01:00","relpermalink":"/publication/2021-importance-modeling-social-factors-language/","section":"publication","summary":"Natural language processing (NLP) applications are now more powerful and ubiquitous than ever before. With rapidly developing (neural) models and ever-more available data, current NLP models have access to more information than any human speaker during their life. Still, it would be hard to argue that NLP models have reached human-level capacity. In this position paper, we argue that the reason for the current limitations is a focus on information content while ignoring language's social factors. We show that current NLP systems systematically break down when faced with interpreting the social factors of language. This limits applications to a subset of information-related tasks and prevents NLP from reaching human-level performance. At the same time, systems that incorporate even a minimum of social factors already show remarkable improvements. We formalize a taxonomy of seven social factors based on linguistic theory and exemplify current failures and emerging successes for each of them. We suggest that the NLP community address social factors to get closer to the goal of human-like language understanding. ","tags":["social factors","computational linguistics","NLP"],"title":"The Importance of Modeling Social Factors of Language: Theory and Practice","type":"publication"},{"authors":["Federico Bianchi","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"ede87cdeecd57ecdb6e7b020668ace0c","permalink":"https://dirkhovy.com/publication/2021-feelit-italian-sentiment-emotion/","publishdate":"2021-03-28T14:48:20+01:00","relpermalink":"/publication/2021-feelit-italian-sentiment-emotion/","section":"publication","summary":"Sentiment analysis is a common task to understand people's reactions online. Still, we often need more nuanced information: is the post negative because the user is angry or because they are sad? An abundance of approaches has been introduced for tackling both tasks. However, at least for Italian, they all treat only one of the tasks at a time. We introduce FEEL-IT, a novel benchmark corpus of Italian Twitter posts annotated with four basic emotions: **anger**, **fear**, **joy**, **sadness**. By collapsing them, we can also do sentiment analysis. We evaluate our corpus on benchmark datasets for both emotion and sentiment classification,  obtaining competitive results. We release an [open-source Python library](https://github.com/MilaNLProc/feel-it), so researchers can use a model trained on FEEL-IT for inferring both sentiments and emotions from Italian text.","tags":["Sentiment Analysis","Emotion Detection","Italian","BERT","NLP","dataset"],"title":"FEEL-IT: Emotion and Sentiment Classification for the Italian Language","type":"publication"},{"authors":["Tommaso Fornaciari","Federico Bianchi","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"3bc06910533e6771816b1c186a6e9ade","permalink":"https://dirkhovy.com/publication/2021-wassa-emotion-multitask/","publishdate":"2021-03-27T14:48:20+01:00","relpermalink":"/publication/2021-wassa-emotion-multitask/","section":"publication","summary":"The paper describes the MilaNLP team’s submission (Bocconi University, Milan) in the WASSA 2021 Shared Task on Empathy Detection and Emotion Classification. We focus on Track 2 - Emotion Classification - which consists of predicting the emotion of reactions to English news stories at the essay-level. We test different models based on multi-task and multi-input frameworks. The goal was to better exploit all the correlated information given in the data set. We find, though, that empathy as an auxiliary task in multi-task learning and demographic attributes as additional input provide worse performance with respect to single-task learning. While the result is competitive in terms of the competition, our results suggest that emotion and empathy are not related tasks - at least for the purpose of prediction.","tags":["Emotion Detection","BERT","NLP"],"title":"MilaNLP @ WASSA: Does BERT Feel Sad When You Cry?","type":"publication"},{"authors":["Tommaso Fornaciari","Alexandra Uma","Silviu Paun","Barbara Plank","Dirk Hovy and Massimo Poesio"],"categories":[],"content":"","date":1620172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620172800,"objectID":"23b4a371f95c37c5b13f4d6d76389ec6","permalink":"https://dirkhovy.com/publication/2021-naacl-softlabels/","publishdate":"2021-05-06T01:41:26+01:00","relpermalink":"/publication/2021-naacl-softlabels/","section":"publication","summary":"Supervised learning assumes that a ground truth label exists. However, the reliability of this ground truth depends on human annotators, who often disagree. Prior work has shown that this disagreement can be helpful in training models. We propose a novel method to incorporate this disagreement as information: in addition to the standard error computation, we use soft labels (i.e., probability distributions over the annotator labels) as an auxiliary task in a multi-task neural network. We measure the divergence between the predictions and the target soft labels with several loss-functions and evaluate the models on various NLP tasks. We find that the soft-label prediction auxiliary task reduces the penalty for errors on ambiguous entities and thereby mitigates overfitting. It significantly improves performance across tasks beyond the standard approach and prior work.","tags":["Soft-labels","Agreement","NLP"],"title":"Beyond Black \u0026 White: Leveraging Annotator Disagreement via Soft-Label Multi-Task Learning","type":"publication"},{"authors":["Sotiris Lamprinidis","Federico Bianchi","Daniel Hardt","Dirk Hovy"],"categories":[],"content":"","date":1618531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618531200,"objectID":"97f586c2e6f028d5128baf1d6a1aaa97","permalink":"https://dirkhovy.com/publication/2021-universal-joy/","publishdate":"2021-03-27T14:48:20+01:00","relpermalink":"/publication/2021-universal-joy/","section":"publication","summary":"While emotions are universal aspects of human psychology, they are expressed differently across different languages and cultures. We introduce a new data set of over 530k anonymized public Facebook posts across 18 languages, labeled with five different emotions. Using multilingual BERT embeddings, we show that emotions can be reliably inferred both within and across languages. Zero-shot learning produces promising results for low-resource languages. Following established theories of basic emotions, we provide a detailed analysis of the possibilities and limits of cross-lingual emotion classification. We find that structural and typological similarity between languages facilitates cross-lingual learning, as well as linguistic diversity of training data. Our results suggest that there are commonalities underlying the expression of emotion in different languages. We publicly release the anonymized data for future research.","tags":["Emotion Detection","BERT","NLP","data set"],"title":"Universal Joy A Data Set and Results for Classifying Emotions Across Languages","type":"publication"},{"authors":["Tommaso Fornaciari","Federico Bianchi","Dirk Hovy","Massimo Poesio"],"categories":[],"content":"","date":1617926400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617926400,"objectID":"3a875d0db3d135d98a7b5d26b50805ed","permalink":"https://dirkhovy.com/publication/2021_eacl_decour/","publishdate":"2021-04-09T01:41:26+01:00","relpermalink":"/publication/2021_eacl_decour/","section":"publication","summary":"Spotting a lie is challenging but has an enormous potential impact on security as well as private and public safety. Several NLP methods have been proposed to classify texts as truthful or deceptive. In most cases, however, the target texts’ preceding context is not considered. This is a severe limitation, as any communication takes place in context, not in a vacuum, and context can help to detect deception. We study a corpus of Italian dialogues containing deceptive statements and implement deep neural models that incorporate various linguistic contexts. We establish a new state-of-the-art identifying deception and find that not all context is equally useful to the task. Only the texts closest to the target, if from the same speaker (rather than questions by an interlocutor), boost performance. We also find that the semantic information in language models such as BERT contributes to the performance. However, BERT alone does not capture the implicit knowledge of deception cues: its contribution is conditional on the concurrent use of attention to learn cues from BERT’s representations.","tags":["deception detection","dataset","NLP"],"title":"BERTective: Language Models and Contextual Information for Deception Detection","type":"publication"},{"authors":["Federico Bianchi","Silvia Terragni","Dirk Hovy","Debora Nozza","Elisabetta Fersini"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"b4e481bdc36e151c5f7c537366aa81d6","permalink":"https://dirkhovy.com/publication/2021-crosslingual-topic-model/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/2021-crosslingual-topic-model/","section":"publication","summary":"We introduce a novel topic modeling method that can make use of contextulized embeddings (e.g., BERT) to do zero-shot cross-lingual topic modeling.","tags":["NLP","Topic Modeling","BERT","Language Models"],"title":"Cross-lingual Contextualized Topic Models with Zero-shot Learning","type":"publication"},{"authors":["Dirk Hovy"],"categories":[],"content":"","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608076800,"objectID":"5cb6c78d7dfa74acb0b3dc3d0145145c","permalink":"https://dirkhovy.com/publication/2020_nlpss/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020_nlpss/","section":"publication","summary":"Text is everywhere, and it is a fantastic resource for social scientists. However, because it is so abundant, and because language is so variable, it is often difficult to extract the information we want. There is a whole subfield of AI concerned with text analysis (natural language processing). Many of the basic analysis methods developed are now readily available as Python implementations. This Element will teach you when to use which method, the mathematical background of how it works, and the Python code to implement it.","tags":["text analysis","social science","NLP","Python"],"title":"Text Analysis in Python for Social Scientists – Discovery and Exploration","type":"publication"},{"authors":["Dirk Hovy","Federico Bianchi","Tommaso Fornaciari"],"categories":[],"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"38a575da835464063eb667eb335f436f","permalink":"https://dirkhovy.com/publication/2020_mt/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020_mt/","section":"publication","summary":"The main goal of machine translation has been to convey the correct content. Stylistic considerations have been at best secondary. We show that as a consequence, the output of three commercial machine translation systems (Bing, DeepL, Google) make demographically diverse samples from five languages “sound” older and more male than the original. Our findings suggest that translation models reflect demographic bias in the training data. This opens up interesting new research avenues in machine translation to take stylistic considerations into account.","tags":["bias","ethics","machine translation","NLP"],"title":"“You Sound Just Like Your Father” Commercial Machine Translation Systems Include Stylistic Biases","type":"publication"},{"authors":["Deven Santosh Shah","H. Andrew Schwartz","Dirk Hovy"],"categories":[],"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"15d5ca711d194a2336fb3c44dc0ea869","permalink":"https://dirkhovy.com/publication/2020_bias/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020_bias/","section":"publication","summary":"An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.","tags":["bias","ethics","NLP"],"title":"Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview","type":"publication"},{"authors":["Dirk Hovy","Afshin Rahimi","Timothy Baldwin","Julian Brooke"],"categories":[],"content":"","date":1584835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584835200,"objectID":"196496b369b51faaabbe3f66aa224c90","permalink":"https://dirkhovy.com/publication/2020_eutwitter/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020_eutwitter/","section":"publication","summary":"Geotagged Twitter data allows us to investigate correlations of geographic language variation, both at an interlingual and intralingual level. Based on data-driven studies of such relationships, this paper investigates regional variation of language usage on Twitter across Europe and compares it to traditional research of regional variation. This paper presents a novel method to process large amounts of data and to capture gradual differences in language variation. Visualizing the results by deterministically translating linguistic features into color hues presents a novel view of language variation across Europe, as it is reflected on Twitter. The technique is easy to apply to large amounts of data and provides a fast visual reference that can serve as input for further qualitative studies. The general applicability is demonstrated on a number of studies both across and within national languages. This paper also discusses the unique challenges of large-scale analysis and visualization, and the complementary nature of traditional qualitative and data-driven quantitative methods, and argues for their possible synthesis.","tags":["computational sociolinguistics","sociolinguistics","NLP","representation learning","embeddings"],"title":"Visualizing Regional Language Variation Across Europe on Twitter","type":"publication"},{"authors":["Farzana Rashid","Tommaso Fornaciari","Dirk Hovy","Eduardo Blanco","Fernando Vega-Redondo"],"categories":[],"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"a7aa9d88e9614128120dc2a841ac10ab","permalink":"https://dirkhovy.com/publication/2020_helpful/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020_helpful/","section":"publication","summary":"When interacting with each other, we motivate, advise, inform, show love or power towards our peers. However, the way we interact may also hold some indication on how successful we are, as people often try to help each other to achieve their goals. We study the chat interactions of thousands of aspiring entrepreneurs who discuss and develop business models. We manually annotate a set of about 5,500 chat interactions with four dimensions of interaction styles (motivation, cooperation, equality, advice). We find that these styles can be reliably predicted, and that the communication styles can be used to predict a number of indices of business success. Our findings indicate that successful communicators are also successful in other domains.","tags":["conversation","style","communication","NLP"],"title":"Helpful or Hierarchical? Predicting the Communicative Strategies of Chat Participants, and their Impact on Success","type":"publication"},{"authors":["Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"39527c2d2966939ebd36a97e84e5382f","permalink":"https://dirkhovy.com/publication/2020-bertlang-language-specific-bert/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020-bertlang-language-specific-bert/","section":"publication","summary":"Recently, Natural Language Processing (NLP) has witnessed an impressive progress in many areas, due to the advent of novel, pretrained contextual representation models. In particular, Devlin et al. (2019) proposed a model, called BERT (Bidirectional Encoder Representations from Transformers), which enables researchers to obtain state-of-the art performance on numerous NLP tasks by fine-tuning the representations on their data set and task, without the need for developing and training highly-specific architectures. The authors also released multilingual BERT (mBERT), a model trained on a corpus of 104 languages, which can serve as a universal language model. This model obtained impressive results on a zero-shot cross-lingual natural inference task. Driven by the potential of BERT models, the NLP community has started to investigate and generate an abundant number of BERT models that are trained on a particular language, and tested on a specific data domain and task. This allows us to evaluate the true potential of mBERT as a universal language model, by comparing it to the performance of these more specific models. This paper presents the current state of the art in language-specific BERT models, providing an overall picture with respect to different dimensions (i.e. architectures, data domains, and tasks). Our aim is to provide an immediate and straightforward overview of the commonalities and differences between Language-Specific (language-specific) BERT models and mBERT. We also provide an interactive and constantly updated website that can be used to explore the information we have collected, at [https://bertlang.unibocconi.it](https://bertlang.unibocconi.it/).","tags":["multilingual","BERT","representation learning","NLP"],"title":"What the [MASK]? Making Sense of Language-Specific BERT Models","type":"publication"},{"authors":null,"categories":["demographic"],"content":"Dirk Hovy, scientific director of DMI and Professor of computer science, has won an ERC starting grant of 1.5mln euros. His project INTEGRATOR, funded under grant agreement 949944, introduces demographic factors into language processing systems, which will improve algorithmic performance, avoid racism, sexism, and ageism, and open up new applications. What if I wrote that “winning an ERC Grant, Dirk Hovy got a sick result?”. Those familiar with the use of “sick” as a synonym for “great” or “awesome” among teenagers would think that Bocconi Knowledge hired a very young writer (or someone posing as such). The rest would think I went crazy. Current artificial intelligence-based language systems wouldn’t have a clue. “Natural language processing (NLP) technologies,” Prof. Hovy says, “fail to account for demographics both in understanding language and in generating it. And this failure prevents us from reaching human-like performance. It limits possible future applications and it introduces systematic bias against underrepresented demographic groups”.\n🗞️🗞️ Related articles featured in Corriere Innovazione and Bocconi News.\n","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"d6b57eefc5eca031cd0bb3edb943a34f","permalink":"https://dirkhovy.com/project/integrator/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/integrator/","section":"project","summary":"Incorporating Demographic Factors into Natural Language Processing Models","tags":["demographic","NLP"],"title":"INTEGRATOR","type":"project"},{"authors":null,"categories":["computational social science","political science","nlp"],"content":"In this inter-disciplinary project, Dirk Hovy and Tommaso Fornaciari team up with an international team of political scientists (led bt the University of Gothenburg) to develop mixed methods for analyzing political parties’ promises to voters during election campaigns. For democracy to function effectively, political parties must offer clear choices to voters during election campaigns. However, as parties’ communication with voters has become increasingly fragmented and targeted, it is much harder for citizens to keep track of what parties are promising. This threatens the quality of democratic representation. It also challenges established research methods for studying parties’ campaign promises. This project will develop new methods for studying parties’ promises in modern election campaigns. The project will integrate existing qualitative methods in political science and develop new research tools based on NLP. These AI-powered tools will enable researchers to examine parties’ campaign promises in large amounts of text and speech. The resulting research will be of significant benefit to citizens, who will receive greater clarity on the choices that parties are offering. These existing and new methods are highly relevant to research on text and speech in a wide range of social science fields. Until now, progress in this field has been stifled by limited dialogue among the proponents of different qualitative and quantitative methods. The project includes established experts on parties’ campaign promises, new media, qualitative and quantitative methods for analyzing political texts, and machine learning and natural language processing. The project is funded by the Swedish Riksbankens Jubileumsfond for 12M SEK.\n","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"cc64e6761fb9bc89dcd828508f7b467b","permalink":"https://dirkhovy.com/project/mimac/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/mimac/","section":"project","summary":"Mixed methods for analyzing political parties’ promises to voters during election campaigns","tags":["computational social science","political science","nlp"],"title":"MiMac","type":"project"},{"authors":null,"categories":["political science","nlp","social media"],"content":"Echo chambers and online abuse are two significant problems affecting the health of conversations on social media. This interdisciplinary, multi-institutional project (led by George Washington University) helps Twitter tackle these issues by developing metrics and algorithms to measure various uncivil behaviors. Given the concerns about growing polarization and the spread of misinformation, our first two metrics, mutual recognition and diversity of perspectives, will help Twitter diagnose issues that arise when users isolate themselves from those who hold differing opinions. Mutual recognition measures whether and to what extent people on opposing sides of an issue acknowledge and engage with rival claims. When recognition occurs, a public sphere is established. When there is no recognition, echo chambers result. Diversity of perspectives measures the range of claims made on the platform, how likely users are to encounter (as opposed to engaging with) divergent and unfamiliar claims, and how polarized the debate is.\nOur second two metrics, incivility, and intolerance, will help Twitter identify and address abuse and targeted harassment. Incivility measures the presence of anti-normative intensity in conversation, including the use of profanity and vulgarity. However, recognizing that such anti-normative communication sometimes serves justifiable\u0026ndash;and in some cases, even beneficial\u0026ndash;ends, we distinguish this concept from intolerance. Targeted attacks on individuals or groups, particularly when carried out based on gender, sexuality, race, ethnicity, religion, or ability, threaten the fundamental democratic principles of equality and freedom.\nTo classify these measures at scale, we draw upon existing work in various computational fields, notably natural language processing and network analysis, but take this work further in addressing the metrics outlined here. Moreover, beyond merely detecting and measuring mutual recognition, diversity of perspectives, incivility, and intolerance, we propose to study the effects these four phenomena have on users. In doing so, we offer a theoretically and empirically driven approach that will help Twitter diagnose the conversation\u0026rsquo;s relative health on its platform.\n","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"b687a82907bfa3278ec0305ce0470f43","permalink":"https://dirkhovy.com/project/twitterhealth/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/twitterhealth/","section":"project","summary":"Devising Metrics for Assessing Echo Chambers, Incivility, and Intolerance on Twitter","tags":["social media","political science","nlp"],"title":"Twitter Healthy Conversations","type":"project"},{"authors":["Alexandra Uma","Tommaso Fornaciari","Dirk Hovy","Silviu Paun","Barbara Plank","Massimo Poesio"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"a5fe34b8d82f43aca4cded8dbebd251c","permalink":"https://dirkhovy.com/publication/2020_aaai_softlabels/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020_aaai_softlabels/","section":"publication","summary":"Recently, Peterson et al. provided evidence of the benefits of using probabilistic soft labels generated from crowd annotations for training a computer vision model, showing that using such labels maximizes performance of the models over unseen data. In this paper, we generalize these results by showing that training with soft labels is an effective method for using crowd annotations in several other AI tasks besides the one studied by Peterson et al., and also when their performance is compared with that of state-of-the-art methods for learning from crowdsourced data. ","tags":["annotation","disagreement","loss function","NLP"],"title":"A Case for Soft Loss Functions","type":"publication"},{"authors":["Tommaso Fornaciari","Dirk Hovy"],"categories":[],"content":"","date":1572739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572739200,"objectID":"e6f7d976c82c2e5990707d0efc2d07b8","permalink":"https://dirkhovy.com/publication/2019_m2v/","publishdate":"2019-10-31T01:35:54+01:00","relpermalink":"/publication/2019_m2v/","section":"publication","summary":"Prior research has shown that geolocation can be substantially improved by including user network information. While effective, it suffers from the curse of dimensionality, since networks are usually represented as sparse adjacency matrices of connections, which grow exponentially with the number of users. In order to incorporate this information, we therefore need to limit the network size, in turn limiting performance and risking sample bias. In this paper, we address these limitations by instead using dense network representations. We explore two methods to learn continuous node representations from either 1) the network structure with node2vec (Grover and Leskovec, 2016), or 2) textual user mentions via doc2vec (Le and Mikolov, 2014). We combine both methods with input from social media posts in an attention-based convolutional neural network and evaluate the contribution of each component on geolocation performance. Our method enables us to incorporate arbitrarily large networks in a fixed-length vector, without limiting the network size. Our models achieve competitive results with similar state-of-the-art methods, but with much fewer model parameters, while being applicable to networks of virtually any size. ","tags":["geolocation","representation learning","NLP"],"title":"Dense Node Representation for Geolocation","type":"publication"},{"authors":["Tommaso Fornaciari","Dirk Hovy"],"categories":[],"content":"","date":1572739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572739200,"objectID":"c99ae1a9dbc181af0fec07ee706ff45e","permalink":"https://dirkhovy.com/publication/2019_geo_mtl/","publishdate":"2019-10-31T01:25:36+01:00","relpermalink":"/publication/2019_geo_mtl/","section":"publication","summary":"Geolocation, predicting the location of a post based on text and other information, has a huge potential for several social media applications. Typically, the problem is modeled as either multi-class classification or regression. In the first case, the classes are geographic areas previously identified; in the second, the models directly predict geographic coordinates. The former requires discretization of the coordinates, but yields better performance. The latter is potentially more precise and true to the nature of the problem, but often results in worse performance. We propose to combine the two approaches in an attention-based multitask convolutional neural network that jointly predicts both discrete locations and continuous geographic coordinates. We evaluate the multi-task (MTL) model against single-task models and prior work. We find that MTL significantly improves performance, reporting large gains on one data set, but also note that the correlation between labels and coordinates has a marked impact on the effectiveness of including a regression task.","tags":["geolocation","multitask learning","NLP"],"title":"Geolocation with Attention-Based Multitask Learning Models","type":"publication"},{"authors":["Hanh Nguyen","Dirk Hovy"],"categories":[],"content":"","date":1572739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572739200,"objectID":"da268d55d2d3daa3188db963df72f794","permalink":"https://dirkhovy.com/publication/2019_siri/","publishdate":"2019-10-31T01:35:54+01:00","relpermalink":"/publication/2019_siri/","section":"publication","summary":"User reviews provide a significant source of information for companies to understand their market and audience. In order to discover broad trends in this source, researchers have typically used topic models such as Latent Dirichlet Allocation (LDA). However, while there are metrics to choose the “best” number of topics, it is not clear whether the resulting topics can also provide in-depth, actionable product analysis. Our paper examines this issue by analyzing user reviews from the Best Buy US website for smart speakers. Using coherence scores to choose topics, we test whether the results help us to understand user interests and concerns. We find that while coherence scores are a good starting point to identify a number of topics, it still requires manual adaptation based on domain knowledge to provide market insights. We show that the resulting dimensions capture brand performance and differences, and differentiate the market into two distinct groups with different properties.","tags":["NLP","smart speakers","topic modeling"],"title":"Hey Siri. Ok Google. Alexa: A topic modeling of user reviews for smart speakers","type":"publication"},{"authors":["Tommaso Fornaciari","Dirk Hovy"],"categories":[],"content":"","date":1572739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572739200,"objectID":"f03e8b5dae24f99c3b8d42cc770514c9","permalink":"https://dirkhovy.com/publication/2019_p2c/","publishdate":"2019-10-31T01:38:23+01:00","relpermalink":"/publication/2019_p2c/","section":"publication","summary":" Geolocating social media posts relies on the assumption that language carries sufficient geographic information. However, locations are usually given as continuous latitude/longitude tuples, so we first need to define discrete geographic regions that can serve as labels. Most studies use some form of clustering to discretize the continuous coordinates (Han et al., 2016). However, the resulting regions do not always correspond to existing linguistic areas. Consequently, accuracy at 100 miles tends to be good, but degrades for finer-grained distinctions, when different linguistic regions get lumped together. We describe a new algorithm, Point-to-City (P2C), an iterative k-d tree-based method for clustering geographic coordinates and associating them with towns. We create three sets of labels at different levels of granularity, and compare performance of a state-of-the-art geolocation model trained and tested with P2C labels to one with regular k-d tree labels. Even though P2C results in substantially more labels than the baseline, model accuracy increases significantly over using traditional labels at the fine-grained level, while staying comparable at 100 miles. The results suggest that identifying meaningful linguistic areas is crucial for improving geolocation at a fine-grained level.","tags":["geolocation","NLP","clustering"],"title":"Identifying Linguistic Areas for Geolocation","type":"publication"},{"authors":["Aparna Garimella","Carmen Banea","Dirk Hovy","Rada Mihalcea"],"categories":[],"content":"","date":1562112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562112000,"objectID":"5dec16fd019afc36d15e76cab7ab6ea4","permalink":"https://dirkhovy.com/publication/2019-gender-bias-part-of-speech-tagging-dependency-parsing/","publishdate":"2019-10-31T01:35:54+01:00","relpermalink":"/publication/2019-gender-bias-part-of-speech-tagging-dependency-parsing/","section":"publication","summary":"Several linguistic studies have shown the prevalence of various lexical and grammatical patterns in texts authored by a person of a particular gender, but models for part-of-speech tagging and dependency parsing have still not adapted to account for these differences. To address this, we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articles’ authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women. Further analyses reveal numerous part-of-speech tags and syntactic relations whose prediction performances benefit from the prevalence of a specific gender in the training data. The results underscore the importance of accounting for gendered differences in syntactic tasks, and outline future venues for developing more accurate taggers and parsers. We release our data to the research community.","tags":["pos tagging","parsing","NLP","bias"],"title":"Women’s Syntactic Resilience and Men’s Grammatical Luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"https://dirkhovy.com/cv/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/cv/","section":"","summary":"A little more about me and how to get in touch","tags":null,"title":"About / Contact","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://dirkhovy.com/contact/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"A little more about me and how to get in touch","tags":null,"title":"Contact","type":"widget_page"},{"authors":["Fernando Vega-Redondo","Paolo Pin","Diego Ubfal","Cristiana Benedetti-Fasil","Charles Brummitt","Gaia Rubera","Dirk Hovy","Tommaso Fornaciari"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"12bbc46c9ef5b1283e70d7fd9cdc0c89","permalink":"https://dirkhovy.com/publication/2019_adansonia/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2019_adansonia/","section":"publication","summary":"Can large-scale peer interaction foster entrepreneurship and innovation? We conducted an RCT involving almost 5,000 entrepreneurs from 49 African countries. All were enrolled in an online business course, and the treatment involved random assignment to either face-to-face or virtual (Internet-mediated) interaction. We find positive treatment effects on both the submission of business plans and their quality, provided interaction displays some intermediate diversity. Network effects are also significant on both outcomes, although diversity plays a different role for each. This shows that effective peer interaction can be feasibly implemented quite broadly but must also be designed carefully, in view of the pursued objectives.","tags":["social science","economics","text analysis"],"title":"Peer networks and entrepreneurship: A Pan-African RCT","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d7d529cae69ca866f12e955616a55bfb","permalink":"https://dirkhovy.com/items/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/items/","section":"","summary":"See some of the projects I have worked on","tags":null,"title":"Projects","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://dirkhovy.com/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"See some of the projects I have worked on","tags":null,"title":"Projects","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"65de3680a280f6bf29dc34fe1adad5a6","permalink":"https://dirkhovy.com/talks/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/talks/","section":"","summary":"Upcoming and recent talks","tags":null,"title":"Talks","type":"widget_page"},{"authors":["Dirk Hovy","Tommaso Fornaciari"],"categories":[],"content":"","date":1541203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541203200,"objectID":"ff3dfca9f7c85f2d365ce66a6da7f88f","permalink":"https://dirkhovy.com/publication/2018_emnlp_retro/","publishdate":"2019-10-31T01:41:26+01:00","relpermalink":"/publication/2018_emnlp_retro/","section":"publication","summary":"","tags":[],"title":"Increasing In-Class Similarity by Retrofitting Embeddings with Demographic Information","type":"publication"},{"authors":["Dirk Hovy","Christoph Purschke"],"categories":[],"content":"","date":1540166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540166400,"objectID":"66a0f211e4d88095c64e9e6679ad64a7","permalink":"https://dirkhovy.com/publication/2018-capturing-regional-variation-distributed-representations-geographic-retrofitting/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018-capturing-regional-variation-distributed-representations-geographic-retrofitting/","section":"publication","summary":"Dialects are one of the main drivers of language variation, a major challenge for natural language processing tools. In most languages, dialects exist along a continuum, and are commonly discretized by combining the extent of several preselected linguistic variables. However, the selection of these variables is theory-driven and itself insensitive to change. We use Doc2Vec on a corpus of 16.8M anonymous online posts in the German-speaking area to learn continuous document representations of cities. These representations capture continuous regional linguistic distinctions, and can serve as input to downstream NLP tasks sensitive to regional variation. By incorporating geographic information via retrofitting and agglomerative clustering with structure, we recover dialect areas at various levels of granularity. Evaluating these clusters against an existing dialect map, we achieve a match of up to 0.77 V-score (harmonic mean of cluster completeness and homogeneity). Our results show that representation learning with retrofitting offers a robust general method to automatically expose dialectal differences and regional variation at a finer granularity than was previously possible.","tags":["computational sociolinguistics","sociolinguistics","NLP","representation learning","embeddings","retrofitting"],"title":"Capturing Regional Variation with Distributed Place Representations and Geographic Retrofitting","type":"publication"},{"authors":["Silviu Paun","Bob Carpenter","Jon Chamberlain","Dirk Hovy","Udo Kruschwitz","Massimo Poesio"],"categories":[],"content":"","date":1540166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540166400,"objectID":"ac97468b9625b50fc42dc47858c6d8d2","permalink":"https://dirkhovy.com/publication/2018-comparing-bayesian-models-annotation/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018-comparing-bayesian-models-annotation/","section":"publication","summary":"The analysis of crowdsourced annotations in natural language processing is concerned with identifying (1) gold standard labels, (2) annotator accuracies and biases, and (3) item difficulties and error patterns. Traditionally, majority voting was used for 1, and coefficients of agreement for 2 and 3. Lately, model-based analysis of corpus annotations have proven better at all three tasks. But there has been relatively little work comparing them on the same datasets. This paper aims to fill this gap by analyzing six models of annotation, covering different approaches to annotator ability, item difficulty, and parameter pooling (tying) across annotators and items. We evaluate these models along four aspects: comparison to gold labels, predictive accuracy for new annotations, annotator characterization, and item difficulty, using four datasets with varying degrees of noise in the form of random (spammy) annotators. We conclude with guidelines for model selection, application, and implementation.","tags":["NLP","annotation","generative models","disagreement"],"title":"Comparing Bayesian Models of Annotation","type":"publication"},{"authors":["Sotiris Lamprinidis","Daniel Hardt","Dirk Hovy"],"categories":[],"content":"","date":1540166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540166400,"objectID":"376dee532427df70e4cf017de36dccec","permalink":"https://dirkhovy.com/publication/2018-predicting-news-headline-popularity-syntactic-semantic-knowledge-multitask-learning/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018-predicting-news-headline-popularity-syntactic-semantic-knowledge-multitask-learning/","section":"publication","summary":"Newspapers need to attract readers with headlines, anticipating their readers’ preferences. These preferences rely on topical, structural, and lexical factors. We model each of these factors in a multi-task GRU network to predict headline popularity. We find that pre-trained word embeddings provide significant improvements over untrained embeddings, as do the combination of two auxiliary tasks, news-section prediction and part-of-speech tagging. However, we also find that performance is very similar to that of a simple Logistic Regression model over character n-grams. Feature analysis reveals structural patterns of headline popularity, including the use of forward-looking deictic expressions and second person pronouns.","tags":["NLP","multitask learning","text classification"],"title":"Predicting News Headline Popularity with Syntactic and Semantic Knowledge Using Multi-Task Learning","type":"publication"},{"authors":null,"categories":null,"content":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"https://dirkhovy.com/license/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/license/","section":"","summary":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"},{"authors":["Dirk Hovy"],"categories":[],"content":"","date":1529625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529625600,"objectID":"f18513a3f10ae12b8977d1caf7da095f","permalink":"https://dirkhovy.com/publication/2018-social-neural-network/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018-social-neural-network/","section":"publication","summary":"Over the years, natural language processing has increasingly focused on tasks that can be solved by statistical models, but ignored the social aspects of language. These limitations are in large part due to historically available data and the limitations of the models, but have narrowed our focus and biased the tools demographically. However, with the increased availability of data sets including socio-demographic information and more expressive (neural) models, we have the opportunity to address both issues. I argue that this combination can broaden the focus of NLP to solve a whole new range of tasks, enable us to generate novel linguistic insights, and provide fairer tools for everyone.","tags":["NLP","computational sociolinguistics","retrofitting","representation learning"],"title":"The Social and the Neural Network: How to Make Natural Language Processing about People again","type":"publication"},{"authors":["Dirk Hovy"],"categories":null,"content":"If you have been to ACL in Vancouver or followed the news on Twitter, you know that it was the biggest conference of its kind. And EMNLP, held in Copenhagen in September, could again claim the same for itself, too, with more than 1200 participants and more long paper submissions than ACL. Given the recent interest in all things NLP, this development is not too surprising, and if current trends hold, we should expect further growth and more record attendances to come on a regular basis.\nPersonally, I think that is a good thing: there are still plenty of open questions in NLP, and the field as a whole can only benefit if more people devote their thoughts to the questions in our field. However, it will (have to) affect the way we hold conferences.\nWhile we are still a long way away from conference sizes as seen in medicine and economics, with up to 10,000 participants, we will likely soon regularly reach attendance of 2000 and more participants (as is already happening in the ML community). Even at this level, it is clear that our conference model needs to be open to growth.\nAs far as I can tell from my involvement in EMNLP, this growth will affect (at least) three aspects of conferences: reviewing, organization, and structure of the actual conference.\nThere has been a lively debate about the state of reviewing in the community (something I like a lot about NLP as a field: people are always willing to tinker with the status quo). Without weighing in on the arxiv debate (which deserves its own discussion), I think it is becoming clear that reviewing is a both a bottleneck and a control mechanism. It is getting ever harder to find reviewers for all submissions, and the quality of the reviews varies a lot. If we reach 2000, 3000, or even 5000 submissions (remember that there will always be way more submissions than papers), we will need enormous PCs to guarantee three reviews. Some people have entertained the idea of open reviewing, but I believe there is a danger that it becomes a popularity contest rather than a fair quality assessment. So far, reviewing is voluntary, but thankless, despite attempts at reviewing prizes. One incentive could be the requirement to review if you submit: since most papers have more than one author, this could go a long way to reducing the reviewer problem. It would not address quality, but it is hard to see how to tackle this better.\nEven if we solve the reviewer problem, we are still left with the decision how to accept papers: right now, conferences aim for 20-25% accepted papers per area. To me, this is the crucial measure to control the ultimate conference size. If we keep the current ratio and submissions keep growing, so will conference sizes. The alternative is to set a size limit instead: the top N papers (by score, meta-review, and random tie break) across all areas get in, the rest is rejected. The problem with this approach is of course that it will drop acceptance rates precipitously, and make it so much harder for good work to get published, but it would allow us to have an upper bound on the size.\nAs for organization, I do enjoy the personal touch that the involvement of community members as general, local, publication, and other chairs brings to conferences. However, from my own experience I can say how hard it is to combine it with your day job as researcher, and once we pass the 2000 mark, it will become almost prohibitive. Given how tight a schedule many researchers already have, this does not sound like a feasible way forward. Certain positions should always be held by researchers, of course (program and are chairs, for example), but it should be possible to outsource some of the other positions.\nA relatively straightforward solution to this problem would be another full-time position in the ACL exec, to support the people who are already there, and to professionalize certain responsibilities currently held by researchers (for example local, handbook, or publicity chair). The increase in salary costs for ACL would most likely be offset by the increased participant numbers.\nThis would help reduce variability: none of us are trained conference organizers, and since it is always somebody new picking it up as they go, outcomes vary quite a bit. The permanent members of ACL provide guidance and continuity, but while they are doing an outstanding job, they too feel the brunt of increasing conference sizes (probably even more than others). An additional position would help address this. Fewer organizers would help streamline communication.\nLastly, larger attendance numbers will change the actual structure of the conferences as we know them. We might have to envision a completely new model, where conferences become more of a discussion forum to exchange ideas than a presentation medium.\nIncreasingly, the parallel track model is reaching its limits (although parallel poster sessions seem to work well), and we will either have to introduce even more parallel sessions (unpopular, since attendees will have more conflicts of presentations scheduled at the same time), extend the conference duration (also unpopular, especially for members with family and small kids), or shorten talks. Personally, I am for a 5min talk limit: as it is, most talks can not convey all of the information contained in the paper anyway, so there is little reason for them to be so long. The best a talk can do is serve as appetizer for the paper, which you then want to read in your time. That, however, can be accomplished in 5min just as well as in 12 or 15. I think the exchange in QA sessions is great and should be kept as much as possible, but I am not sure it will be feasible. A better exchange is the direct chat during poster sessions, so increasing poster acceptances is an obvious solution (although maybe not an easy one). Personally, I increasingly like the focused topicality and exchange of workshops, but I am not sure it will be possible to scale them (even at an average workshop size of 50 participants, we would have to have dozens of workshops, which again raises the time vs. parallelity problem, not to mention space issues).\nEither way, the growing field will present us with new challenges and affect the way we do conferences. However, I am confident that we will find a way as a community, and am more curious than concerned. The only thing that is for certain is that conferences as we know them will become a thing of the past.\n","date":1505779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505779200,"objectID":"a05f602eb1f8b53e5b08f68f67220dbc","permalink":"https://dirkhovy.com/post/2017_09_19_some_thoughts_on_the_future_of_nlp_conferences/","publishdate":"2017-09-19T00:00:00Z","relpermalink":"/post/2017_09_19_some_thoughts_on_the_future_of_nlp_conferences/","section":"post","summary":"If you have been to ACL in Vancouver or followed the news on Twitter, you know that it was the biggest conference of its kind. And EMNLP, held in Copenhagen in September, could again claim the same for itself, too, with more than 1200 participants and more long paper submissions than ACL.","tags":null,"title":"Some Thoughts on the Future of NLP Conferences","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"It’s All about the He said, She said―A Quantitative Analysis of the Three Presidential Debates\nThe question what constitutes an acceptable sentence is a matter of taste, and would elicit very different answers from a moral philosopher, a linguist, and a logician. In natural language processing (NLP), the answer is much simpler (or simplistic), and quantifiable: any sentence that could be generated with some probability from a language model.\nAs the US presidential debates have drawn to a close, much has been said about acceptable and unacceptable language. While NLP is woefully ill-equipped to make moral decisions on what the candidates said, it is pretty useful to analyze how much was said, and how unusual it is. So I spent an afternoon analyzing the transcripts of the three debates, and quantified the findings.\nI downloaded the three transcripts, separated out the answers of the two candidates, split them into sentences, and analyzed them with a language model. Without going into to much technical detail: a language model is a statistical model which has been induced from a large collection of text. To use the model, we give it a sentence and ask “How likely is it to generate this sentence?” The model then returns a probability between 0 and 1. 0 means that the model would never produce this sentence, and 1 that it always would. In practice, neither of them really occur, but numbers are somewhere in between.\nThe exact numbers depend on what and how much text you used to train the model, how many words in sequence you look at, and how similar your training data was to the texts you analyze. I used a 5-gram SRILM trained on a corpus of 2,584,929 English review sentences. No, this might not be the best model one could use, and if I used it in an application, I would certainly train on something closer to the debates. However, I used the same model for all three debates and both candidates, so independent of the absolute values we get, we can compare the two politicians quantitatively.\nSo what do we learn?\nFirst of all, Donald Trump says more (1950 sentences, compared to Clinton’s 1136), but he uses fewer words: the median Trump sentence has 11 words, a Clinton sentence 16. The graph below shows the relative distribution of sentence lengths for each candidate (I accounted for the fact that they uttered different amounts of sentences).\nBecause the bars are sometimes a little hard to see in front of each other, I also overlaid them with a smoothed curve (kernel density estimator). The dotted lines show the respective median length in words.\nWe can see that Trump utters more short sentences (under 15 words), and few longer sentences. Clinton, on the other hand, has a lot more of her sentences in the 15-30 word range.\nWhat about the language model? Let’s first look at the likelihood of the sentences. Some explanation: since the probabilities get very small and hard to distinguish, the likelihood of the sentence is typically given as logarithm of the probability. That makes it a larger, but negative number. The closer the number is to 0, the more likely a sentence is under the model.\nWe again see some noticeable differences: Trump’s sentences are usually more likely than Clinton’s. This is both an effect of the words the two use, but also of the sentence length (longer sentences become less and less likely), and we have already seen that there are noticeable differences in sentence length.\nSo let’s normalize each sentence likelihood by the sentence length. That gives us the average log probability per word (note that the x-axis scale is much smaller than before).\nEven here, on a per-word-basis, we see that the model is more likely to produce Trump sentences rather than Clinton sentences (you can actually use language models to generate sentences, often to great comical effect, but there isn’t enough training data for each candidate to really come up with much. I tried).\nSo what do the different sentences look like? Well, the two highest scoring sentences (measured by logprob/word) for each candidate are “Because I was a senator with a Republican president .” (Clinton) and “Horribly wounded .” (Trump). The most “average” sentences are “But let ’ s not assume that trade is the only challenge we have in the economy .” (Clinton) and “When we have $ 20 trillion in debt , and our country ’ s a mess , you know , it ’ s one thing to have $ 20 trillion in debt and our roads are good and our bridges are good and everything ’ s in great shape , our airports .” (Trump). Both of these buck the length-trend. The least likely sentences of each candidate, however, do follow what we have seen before: “Donald thinks belittling women makes him bigger .” (Clinton) vs. “Trump Foundation , small foundation .” (Trump).\nSo independent of what the candidates are talking about, the way how they talk can help us separate them to some extent. In fact, if we use only the number of words and logprob as features, we can train a logistic regression classifier that distinguishes the two candidates with an accuracy of over 65% (10-fold cross-validation). That’s only slightly better than the majority class (about 63% accuracy) and again not good enough to build a system, but interesting given that we have not even looked at what the candidates are saying.\nDoes this tell us anything about the likely outcome in November? No. But it shows that the differences between the candidates’ rhetoric styles go beyond what they say in a quantifiable way: sentence length and predictability.\n","date":1477094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477094400,"objectID":"65c7030c8512f4e23f2ee39c5b2897aa","permalink":"https://dirkhovy.com/post/2016_10_22_its_all_about_the_he_said_she_saida_quantitative_analysis_of_the_three_presidential_debates/","publishdate":"2016-10-22T00:00:00Z","relpermalink":"/post/2016_10_22_its_all_about_the_he_said_she_saida_quantitative_analysis_of_the_three_presidential_debates/","section":"post","summary":"It’s All about the He said, She said―A Quantitative Analysis of the Three Presidential Debates\nThe question what constitutes an acceptable sentence is a matter of taste, and would elicit very different answers from a moral philosopher, a linguist, and a logician.","tags":null,"title":"It’s All About the He Said, She Said―A Quantitative Analysis of the Three Presidential Debates","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"In a recent article in the New Yorker, James Surowiecki outlined how, back in the 1960s, professional athletes considered strength training akin to cheating: either you were good at sports, or you weren’t―training had nothing to do with it. Practice was seen as just a way to stay in shape, not to get better. Today, this notion sounds quaint, naive, and a little bit stupid. We expect professional athletes (and any remotely serious amateurs) to have a rigorous training regimen, including fitness, nutrition, and rest schedules.\nWhen it comes to scientists, however, we still think along the same lines as the athletes in the last century. Da Vinci, Einstein, Curie: We like to think that these people had an innate “gift”, a knack for science, that they were just brilliant and needed no training. Yes, they were extremely smart, but nothing could be further from the truth. Da Vinci and Tesla had sophisticated sleep schedules to maximize efficiency, Einstein arranged his personal life around his science (with no regard for the people around him), and Curie literally worked herself to death.\nThe notion of inherent brilliance, however, does not only pertain to the all-time greats. Scientists are generally portrayed as geniuses, who possess a preternatural insight and operate on a different plane from mere mortals. This is an overcome and elitist notion, and to perpetuate that stereotype is not only disrespectful to all the hard-working researchers, but also damaging to science.\nEvery great academic I know has indeed an unusually good understanding of their subject matter, but mostly, they do because they work a substantial amount. And the more accomplished they are, the more they work. None of them could get by on talent alone, neither to get where they are, nor to maintain that level.\nThere are of course no well-known training regimen for scientists (What is the equivalent of endurance training for researchers? How should one eat and rest to achieve maximum performance?)\nHowever, many researchers I know exercise regularly, both to maintain their health, and as counterbalance to their academic routine. And while not many academics eat an athlete’s diet, many of them follow scrupulous caffeination rituals.\nMore importantly, though, the best researchers are constantly finding ways to identify and improve their weaknesses. And the only way to do so is by investing time. Lots of time.\nA job at a prestigious university these days comes with the implicit understanding (from both sides) that you put in 80+ hours a week, not necessarily that you are brilliant. Work-life balance be damned.\nThis approach has some serious side effects, with alcoholism and burn-out unusually common among academics. Yet we still try to make it look easy on the outside, slave to the genius fallacy. We hope to convince people of our brilliance, while simultaneously fighting back the impostor syndrome, and wondering how the others do it so effortlessly. Truth is: they don’t.\nThis is even more infuriating since academia is already set up as a series of escalating training rounds, and would benefit from acknowledging that. The genius complex is holding us all back, devalues hard work, and makes it difficult for young researchers to accept their limits, to acknowledge that their accomplished colleagues got to where they are by years of hard work and scrupulous training, rather than by mere natural talent.\nSports and music have abandoned the genius notion in favor of dedicated training and hard work, and consequently, performance has improved across the board over the last few decades. And while the overall quality of science has improved by the same mechanism, we still cling to an overcome notion that brings more harm than good. It’s time we abandon it as well.\n","date":1467763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467763200,"objectID":"73f6de4760b1e5d920f63b336d6a1187","permalink":"https://dirkhovy.com/post/2016_07_06_sciences_genius_complex/","publishdate":"2016-07-06T00:00:00Z","relpermalink":"/post/2016_07_06_sciences_genius_complex/","section":"post","summary":"In a recent article in the New Yorker, James Surowiecki outlined how, back in the 1960s, professional athletes considered strength training akin to cheating: either you were good at sports, or you weren’t―training had nothing to do with it.","tags":null,"title":"Science’s genius complex","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"As mentioned before, I sometimes use my academic knowledge of natural language processing for purposes other than research.\nA friend recently told me about an entertaining game where you gerundivize words in movie titles (i.e., you add -ing at the end) to completely change the meaning. Some of my PG-13 favorites include “Jurassic Parking”, “Ironing Man” and “2001: Spacing Oddysey” (you can get equally entertaining, yet NSFW result with other titles, but I leave that as an exercise to the reader).\nBeing the spoilsport I am, I decided that it would be fun to see how much NLP could help me with that. It certainly won’t be able to decide whether an altered title is funny or not (that’s how lame AI still really is), but it would at least help me generate all possible versions.\nI downloaded a list of the 1000 best movies ever (at least according to The New York Times) and then took each title, went through it word by word, and checked (against the Brown corpus), whether adding ’-ing’ to the end resulted in an English word. If so, I printed it out.\nThe only tricky part was to deal with the spelling alterations for gerunds: -e is always removed ( “take” becomes “tak-ing”), consonants are usually doubled ( “put” becomes “put-t-ing”, but “model” becomes “model-ing”). For the latter case, I actually generate both the duplicated and a non-duplicated version (the rules for the game are not quite clear on what to do here). That’s how I got “Beverly Hills Coping”, which I think sounds much funnier than “Beverly Hills Copping”.\nI didn’t check for grammaticality of the entire title, which results in nonsense such as “Alice Doesn’t Living Here Anymore”, while other results are just minor changes in meaning ( “Dial M for Murder” vs. “Dialing M for Murder”). Some of the results are pretty entertaining, though: “The Counting of Monte Cristo”, “Lasting Tango in Paris”, “Gosford Parking”, “Gone with the Winding”, “Lone Staring” (creep!), “Odd Man Outing”, “Oliver Twisting”, “Totaling Recall”, or “Body Heating”. You can download the script here and play around with it to get the full list, or modify it with your own titles.\nAnd that’s it, I wasted another perfectly good hour using NLP for my personal entertainment.\n","date":1442534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442534400,"objectID":"c9d0385bb7d49f14638124d2d14fdf55","permalink":"https://dirkhovy.com/post/2015_09_18_fun_with_movie_titles/","publishdate":"2015-09-18T00:00:00Z","relpermalink":"/post/2015_09_18_fun_with_movie_titles/","section":"post","summary":"As mentioned before, I sometimes use my academic knowledge of natural language processing for purposes other than research.\nA friend recently told me about an entertaining game where you gerundivize words in movie titles (i.","tags":null,"title":"Fun with Movie Titles","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Recently, I was interviewed by two students for a study on the business application of natural language processing technique called sentiment analysis. Sentiment analysis takes as input a text (which can be anything from a sentence, a tweet, or a paragraph, up to an entire document), and tries to predict the general attitude expressed therein: usually divided into positive, negative, or neutral.\nFor many businesses, this is an appealing application, since it promises to detect how people think about the company’s products and services, and because it can potentially be used to evaluate stock options.\nHowever, potential and reality differ, and as far as I see it, there are currently three problems that limit the general applicability of sentiment analysis, and their commercial use:\nThe labels: The labels are fairly coarse (positive, negative, neutral), while there is still an ongoing debate in psychology on how many basic emotions there are (see here). More fine-grained labels (Facebook let’s you label your status with more than 100 “emotions”) might provide better leverage, but the question is: what would they be? Another problem is the relation between text and labels: we recently had a paper accepted which shows that a common approach to labeling (by using ratings) is not strongly correlated with the text, i.e., models (and humans) can’t guess correctly how many stars somebody gave, only based on the review text. This is largely what we expect of our statistical approaches, though. Which brings us to the second problem:\nThe models The models are usually trained on a particular domain (say, movie reviews), where they learn that certain features are indicative, say for movies the word ’hilarious’. However, when applied to another domain (say, restaurant reviews), this word does not at all indicate positive sentiment (a “hilarious” meal might not be what we hope for).\nIn technical terms, models overfit the training data. For a negative result on this, see here. Models need to be better regularized, i.e., de-biased from the training data, in order not to put too much faith in spurious features. Which finally brings us to the third problem:\nThe features The problem of most approaches is the reliance on individual words, rather than on global sentiment and a deeper understanding of the text. Many models still rely on predefined word lists, or dictionaries, but individual words do not do the problem justice. Things like negation, sarcasm, or metaphors can completely distort the sense of a phrase, even though the individual words seem unambiguous. Even seemingly clear positive or negative words can often express both sentiments when seen in context, cf. “sincere” in “sincere answer” vs. “sincere condolences”, or “cold” in “cold look” vs. “cold beer” (see Flekova et al.). This doesn’t even begin to cover the problem that different age and gender groups express positive or negative sentiment very differently, yet that the models treat all text as coming from the same demographics.\nIn sum, our approaches are currently too simplistic to capture the complexity of entire texts, thus making results brittle. The over-reliance on individual words and the lack of model regularization exacerbate this problem.\nThis is not to say that sentiment analysis does not work at all, but all of this limits the commercial use of sentiment analysis to fairly clearly denominated domains (see also the assessment of Larson and Watson).\nTo improve make sentiment analysis viable for a wider range of contexts, though, we have to start improving all of the three areas above.\n","date":1442534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442534400,"objectID":"019be95366813c313f700cd8a46a4829","permalink":"https://dirkhovy.com/post/2015_09_18_how_usable_is_sentiment_analysis/","publishdate":"2015-09-18T00:00:00Z","relpermalink":"/post/2015_09_18_how_usable_is_sentiment_analysis/","section":"post","summary":"Recently, I was interviewed by two students for a study on the business application of natural language processing technique called sentiment analysis. Sentiment analysis takes as input a text (which can be anything from a sentence, a tweet, or a paragraph, up to an entire document), and tries to predict the general attitude expressed therein: usually divided into positive, negative, or neutral.","tags":null,"title":"How usable is sentiment analysis?","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"I love natural language processing, I really do. I think it has the potential to make the world a little bit better, and like all things worth exploring, it also has the potential to do evil. But it can be tiring wielding all this awesome technology for such serious causes, and sometimes, a man just wants to have a little fun with his subject. After all, why not get a laugh out of all the time invested?\nTurns out, you can have a lot of fun with NLP, and it usually only takes a few lines of code and some data. An internet age ago (i.e., last year or so), the Doge meme took the Web by storm, and after seeing it enough, I realized that it followed a certain pattern, and that much of the humor derived from the ungrammatical use of intensifiers with certain word types (I’m a lot of fun at parties, I swear). Essentially, the pattern is\n“Wow, such ADJECTIVE! Much NOUN! Very VERB!”\nAll I had to do now was to get all nouns, verbs, and adjectives out of an annotated corpus (I used the Brown corpus, which comes with the NLTK library), and then randomly pick one of each category to fill the slots. Oh, yeah, and I converted all verbs to their infinitive (i.e,. ’jumped’ and ’jumping’ become ’jump’).\nThe results range from the mundane and stupid to the insightful and funny. My favorites are the jaded look on counter culture in “Wow, such underground! Much intentions! Very smell!” and the strangely place-appropriate “Wow, such scandinavian! Much concrete! Very constitute!”\nAnd that’s it. The entire script is 6 lines of Python code. You can download the script here and play around with it. Enjoy!\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"6cfea92e1cfb82676b44a5e239eda46b","permalink":"https://dirkhovy.com/post/2015_09_01_wow_such_meme_much_nlp_very_generate/","publishdate":"2015-09-01T00:00:00Z","relpermalink":"/post/2015_09_01_wow_such_meme_much_nlp_very_generate/","section":"post","summary":"I love natural language processing, I really do. I think it has the potential to make the world a little bit better, and like all things worth exploring, it also has the potential to do evil.","tags":null,"title":"Wow: Such Meme, Much NLP, Very Generate!","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"A number of comedies hinge on the premise of a young and an old person switching bodies. When a 45-year-old business woman says “’sup dudes?”, we find this funny (at least some of us), because it goes against our expectations of how people speak. We do have fairly clear ideas of how 45-year-old business women speak, and how teenage guys do, and that these two ways are not the same. To us, this is such a common and intuitive fact about language that breaking it intentionally can have comedic value.\nFor the models we use in natural language processing (NLP), however, this fact is not at all clear. To them, all language is the same, because we have not taught them about the difference. When I say “taught”, I don’t mean that we sat them down and explained how language works, of course. We train a model by presenting it with a bunch of input sentences, and with the correct output analyses we expect for them. If the machine has seen enough of these input and output pairs, it can learn a function that maps from an input sentence to the output analysis.\nThe problem is that almost all of these training pairs came from newspaper articles from the 80s. And that most of these articles were produced by (and for) a specific demographic, which is, broadly speaking, old, white, and male.\nWe would expect 60-year-old men to have difficulties understanding “the kids these days”, and so it’s no surprise that our models have exactly the same difficulties. When we give them input sentences from today’s teenagers (e.g., Twitter), they produce incorrect analyses. Of course, tweets are written very differently from newspaper articles, and so for a while now, the field has investigated the influence of the genre on performance. However, genre is not the whole picture: if we feed the models sentences from older people, they do a lot better than on sentences from younger people, even when the genre is the same for both groups.\nAgain, this is not too surprising, since language changes with every generation. What is surprising, however, is the depth and magnitude of this change. Younger people do not just use different words than older people. If it was that simple, we could just have the machine learn a number of new words. It turns out, however, that the differences go deeper: younger people even put their words together in ways very different from older people.\nIn order to test this, we ignored the actual words and looked instead at pairs of the words’ parts of speech (noun, verb, adjective, etc.) So “Dan cooks” “Mary writes” or “Frank measures” all become “NOUN VERB”. We found that in both German and English, the pairs from the older group were much more similar to the training data than the pairs of the younger group were. In other words: younger people use word combinations that are unlike anything our models have seen before. Older people don’t. Consequently, our models are much better at predicting part of speech sequences for the older group. We tested this for both German and English, with the same results.\nPairs of parts of speech are one thing, but linguistically speaking, they are still a fairly shallow phenomenon.\nWe also looked at the deep syntactic structure of grammatical functions (subject, verb, object, etc.), where words do not have to be adjacent, but can be on opposite ends of the sentence.\nThese analysis were interesting in two ways: from a linguistic perspective, and from an NLP perspective.\nLinguists have suspected for a long time that syntax changes with age. However, since syntax is very complex, this was hard to prove: we can put words together in a great number of ways, and you have to observe lots and lots of examples to see even the most common ones. Even then, it is hard to pin down the exact differences, if you don’t know what constructions you are looking for. We got around both problems by analyzing millions of sentences from people whose age we know. Among those, we selected only the most frequent syntactic constructions and compared them. That way, we did not have to specify beforehand which constructions to look for. The pattern analyses was of course less than perfect (remember, our models are biased), but by analyzing large enough numbers and by focusing on frequent constructions, we were able to get enough reliable observations to find significant differences. We expect the differences to be even more pronounced if the analyses were better.\nThe result of all this is that even the word-order (syntax) of young people is radically different from the older group. So different, in fact, that seeing a certain construction can give the machine a good clue as to how old the person is. Just as it would us humans.\nThis does of course not mean that one group uses a syntactic construction and the other group doesn’t. It just means that one group uses a construction statistically significantly more often than the other group.\nAnd the differences don’t just extend to age: we found similar differences again between men and women. What’s even more startling is the fact that these patterns occur in up to 12 different indo-european languages.\nThe other way in which these findings were interesting, namely for NLP, was that it showed that our models do pick up on demographic differences, albeit in a bad way. There is, however, nothing inherently ageist to the model algorithms: they are not consciously aware of these differences. They simply transform input sentences into output analyses. However, due to their training, they pick up on the language characteristics of the training data. And when the models get new inputs, they expect the language to be the same as before. This shows how brittle our models are, and how susceptible to the language characteristics (the bias) in the training data.\nIn fact, we found that our models not only did consistently worse on data from young people (in both German and English), but that they also performed worse and worse the more markers of African-American vernacular English (AAVE) were in a text. (They did not, however, perform worse on different genders―at least.)\nSo you got a bunch of bad analyses, you could say―so what!\nIndeed, if it was just for academic purposes, this would be annoying, but on the whole inconsequential. However, NLP models are increasingly used as go-to tools for unstructured data analysis, both in business and political analysis. If all of these models expect language to come from old white men, and then perform poorly on texts from other demographic groups, we risk systematically ignoring or, even worse, disadvantaging these groups.\nLuckily, there are ways to prevent this problem. For one, we can simply train our models on data from more and more demographic groups. In a recent paper, I showed that if we encode age and gender in the models, we get better performance, even under very controlled settings. This means that there is enough signal in the language of different demographic groups that our models can learn to differentiate, and to produce better analyses on a variety of tasks and languages.\nThis requires, though, that we have enough samples from all demographic groups, and their correct analyses. Both assumptions are unrealistic (for now), because collecting the data and producing the correct analyses takes a lot of time and effort. What’s more, there are dozens of demographic variables: age, gender, education, ethnicity, class, income, etc., and we are only starting to see which ones impact our models.\nIf we want to address the problem in earnest, we can’t afford to encode each of these variables explicitly. However, we can also just tell our models to expect demographic differences, and figure out the rest themselves.\nIn the future, we need to find ways to automatically detect all kinds of variations, and to reduce the impact of them on training our models. We need to teach our models that language varies along demographic lines, but that all of these variations are valid.\nNot only will we improve the quality of our models, we will also produce fairer analyses that benefit everyone the same.\nThe papers I described can be found here, here, here, and here.\n","date":1436486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436486400,"objectID":"de4497a179a25a28d9f39e2192d6ac0f","permalink":"https://dirkhovy.com/post/2015_07_10_are_our_models_ageist/","publishdate":"2015-07-10T00:00:00Z","relpermalink":"/post/2015_07_10_are_our_models_ageist/","section":"post","summary":"A number of comedies hinge on the premise of a young and an old person switching bodies. When a 45-year-old business woman says “’sup dudes?”, we find this funny (at least some of us), because it goes against our expectations of how people speak.","tags":null,"title":"Are our models ageist?","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Here, I’ll try to explain another paper I have worked on in generally understandable terms. This time, it’s about learning whose opinion we can trust.\nSay you are thinking of watching “Interstellar”. You have seen mixed reviews and want to poll your friends for an opinion. So you ask 6 people. If five say “don’t bother” and one “yay”, it’s pretty clear. This is called “majority voting”.\nHowever, more often than not, you will get a tie, i.e., three people say “don’t bother” and three “yay”. This gets worse the more answer options there are: imagine asking six people whether to see “Interstellar”, “The Hobbit”, “Fury”, or “Unbroken”.\nOne way to break ties is by flipping a coin (or rolling a die, if you have more than two answer options). However, this has a 50% or higher chance of picking the wrong answer.\nIf you knew, however, that one of your friends simply likes all movies and always says yes, and another one has the same taste as you and said no, you would be able to weigh their answers differently. Instead of flipping a coin to break ties, you’d use a weighted average to get the best answer.\nIn Natural Language Processing, we often ask people for their opinion. Usually, it’s about the part of speech (noun, verb, adjective, etc) of words, or whether a sentence is positive, negative, or neutral. This is called annotation. The annotated text is then used to train statistical models. If the annotation is wrong, the models won’t work as well.\nWe assume that most annotators are generally trustworthy, but that some annotators get it wrong. Either because they did not pay attention to the explanation, or because they don’t care about the task and just want to get paid. If we could down-weigh bad annotators, we would get better annotations and thus better statistical models.\nUnfortunately, we usually don’t know the annotators, and thus we don’t know how much to weigh each annotator’s answer. If we did, we could just compute a weighted average over the annotators and get the most likely correct answer.\nIf we already knew the correct answers, we could count how often each annotator gave the correct answer, and use that fraction as weight.\nBut we don’t know the correct answer, and we don’t know the weights, so we are stuck in a circular problem.\nThe way to address this circular problem is by using an algorithm called Expectation Maximization (EM). It works in two steps that are repeated until we reach a satisfying answer.\nInitially, we give each annotator some random weight. In the first step, we then calculate the most likely answers based on the weights. Now we can compute how many answers each annotator got right, and assign them a weight based on that fraction. This is the second step.\nWith the new weights, we re-calculate how many answers each annotator gets right, and again update the weights. And again, and again. At some point, the weights don’t change much any more from round to round, and we are done. We now have weights and can compute the most likely final answers.\nWe also use an additional technique, called Variational Bayes EM, that essentially tells the model that people either do a good job or they don’t care, but nobody cares a little. This is called a “prior belief”, or just “prior”. Technically, this works by adding pseudo-counts, i.e., when computing how many answers each annotator got right and wrong, we add a small number (we used 0.5) to both. The reason why this works is complex, but it essentially relativizes the influence of the counts a bit, unless they are pretty strong. In the end, it prevents the model from giving too low weights to actually good annotators and improves performance.\nUsing the final weights for each annotator, we can compute a likelihood for each answer under the model (i.e., given that particular set of weights, how likely is a particular answer). The product of all answer likelihoods gives us a measure for how good the model is. Ideally, we would like to have a model with high likelihood.\nSince we started out with random weights, there is a chance that a bad annotator ends up with a high weight. It’s a small chance, because the training process tends to correct that, but it exists. To eliminate that chance, we run the training several times, every time with different starting weights. Once a training run finishes, we measure the overall likelihood of the model. We then pick the final set of weights that resulted in the highest overall likelihood.\nWe implemented all this in a model and called it MACE, which stands for Multi-Annotator Competence Estimation, because a) that describes what it does and b) we thought it sounded funny to say “Learning whom to trust with MACE” (yes, this is how scientists work).\nWhen we tested MACE on data sets where we already knew the correct answer, we found that MACE correctly finds more than 90% of the answers, while majority voting (with coin flipping to break ties) does much worse.\nIn real life, we of course don’t know the correct answers, but we found in several annotation projects that the MACE answers produce better statistical NLP models than when using majority voting annotations. We also found that annotators who get a low weight usually also produce bad work, while the ones with high weights produce good annotations.\nSince we have probabilities for each answer, we can also choose to focus on the ones with high probabilities. If we do that, we see that the accuracy for those answers is even higher than for all. This is interesting for the case where we have some more annotations than we need, but would like to know that the ones we choose are of especially high quality.\nWhen asking people to annotate, we can also smuggle test questions in there where we know the correct answer. These are called control items (because we can control how good the annotators are). That way, we can sort out bad apples even more accurately. If we use even just a few control items in MACE, accuracy goes up even further.\nWhen I gave a talk about MACE, one of the listeners asked what would happen if my annotators were a bunch of monkeys: would MACE still find the “experts”? The answer is no, but it’s a good question, and we actually did test how many “good” annotators the model needs to find good answers. We simulated 10 annotators and varied the number of good ones: those would get 95% of the answers correct (this is roughly the percentage of the best annotators in real life). The rest of the simulated annotators would pick an answer at random or always choose the same value. We found that even with just 3 or four good annotators, MACE was much better in recovering the correct answer than majority voting. Luckily, in real life, it is pretty unlikely to have such a bad crowd of annotators. Just don’t use monkeys.\nWhether we have control items or not, we can use MACE to get better answers for our annotation projects, and learn in the process which annotators are doing a good job.\nThe paper I explained here is this one, and MACE can be downloaded here.\n","date":1420934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420934400,"objectID":"0bc685f0e30d84fd25aa427d43bed596","permalink":"https://dirkhovy.com/post/2015_01_11_what_i_do_learning_whom_to_trust/","publishdate":"2015-01-11T00:00:00Z","relpermalink":"/post/2015_01_11_what_i_do_learning_whom_to_trust/","section":"post","summary":"Here, I’ll try to explain another paper I have worked on in generally understandable terms. This time, it’s about learning whose opinion we can trust.\nSay you are thinking of watching “Interstellar”.","tags":null,"title":"What I do: Learning whom to trust","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"As much as I love languages, one of the things that frustrated me in linguistics was the seeming arbitrariness of theories. There was no way of knowing which one was better than another. That did not stop people from arguing about exactly that, but there was no way of proving it.\nOne of the things that most drew me to natural language processing was the possibility to measure and quantify how good a model (and thereby its underlying linguistic theory) was. I was overjoyed. Unfortunately, nothing is that easy.\nIt turns out that the closer you look, the more difficulties there are. However, there are also solutions. One of them is significance testing. It’s very powerful, but very easy to misunderstand.\nWhile it is easy to compare two models A and B on the same data set and decide which one is better, this says very little about which model is better in general. Model B might be better on this particular data set, but bad on all others (this is called overfitting). We can get a better picture if we compare the two models on more data sets and average over them. Most likely, however, the difference between two good models will be small.\nSo even if we used several data sets, there is still a chance that the difference between A and B is just due to some unaccounted peculiarities, or pure coincidence. This chance gets smaller with more data, but it does not disappear. Can we quantify that chance? This is what significance tests are for.\nIn general, significance tests estimate the probability that the claim that the difference between the models is not coincidence is false. I.e., how likely am I wrong when I say “the difference is not due to chance”. This probability is the p-value. A p-value of 0.01 thus means: even though we have shown that the difference between the models is not coincidence, there is a 0.01=1% chance that we were wrong. If our significance test value is lower than this 0.01, then we can say that the difference is “statistically significant at p=0.01”.\nNaturally, the lower the p-value, the better. The important point is that significance is binary: either your result is significant at a certain p-value or it isn’t. This is why this list of descriptions for failed significance tests is rather hilarious.\nOk, great. So does that mean if I see a significant result at a small p-value in a paper, the model is good? Unfortunately, no. Because there are a lot of things that can influence the p-value. Here are some.\nThe most obvious is the test we use. Some tests only work if your data is normally distributed, i.e., if you plot the data, it looks like a bell shape. This is almost never the case in language. Most data looks like a Zipf curve, i.e., it has a steep decline and then a long tail. Any test that makes the normal-distribution assumption is thus bound to give a wrong result.\nA good significance test to compare two models is bootstrap sampling: pick a random sample from the data (instances can be repeated) and compare the two models on that. Do this 10.000 times or so. Count how often B is better than A and divide that by 10.000. That’s your p-value. If the result is small, A is probably a better model.\nIt does not matter how your data is distributed, this gives us a good estimate.\nOk, so are we done now that we have a good test? Again, no. There are more factors, and even if we pick a certain p-value threshold and report significance, we could be wrong.\nSay my models analyze sentences. Maybe I need to restrict my analyses to short sentences (say, less than 20 words) for computational reasons. If A does better than B on this sample, I still have no idea whether it will also be better on longer sentences. My significant result is thus only valid for sentences shorter than 20 words. Unless I say this explicitly, my significant result is misleading. If I wanted to deceive people into thinking my model is great, I could look at different lengths and choose to just report the one that gives me a significant result.\nAnother issue is the measure I use to compare the models. When analyzing the performance of two models on sentences, I can look at how many sentences each gets right, or at how many words. Or I can just look at verbs. Or rather than the correct items, I can look at the error rate of a certain category. Or a whole number of other measures. All of these can be interesting, but if I get a significant result for one measure, it does not mean I get a significant result for all the others. If I was an unscrupulous researcher, I could test all measure and then just report the ones that look best.\nTypically, the larger the data and the bigger the difference, the easier to get a low p-value. Somewhat counterintuitively, this does not mean that increasing the sample size will give a significant result. Maybe I just add more examples where A and B are the same, or more where the weaker model is stronger, and so the differences wash out.\nUltimately, all that a positive significance test can tell us is that the difference between models for this particular data set, under the given conditions, for the given measure is significant at a certain level. That’s a lot of qualifications.\nThe best we can do under these circumstances is to use several data sets, several measures, a clear description of what conditions we used, and an appropriate significance test with a low p-value.\nThat way, when we say A is significantly better than B, we can be more sure that others will be able to replicate that. It’s not much. But it’s much better than guessing.\nThe paper I am talking about here is this one. If you got interested, please see the references for a number of other good papers on the subject.\n","date":1420848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420848000,"objectID":"109619ff770ba89905cb070ea446c38d","permalink":"https://dirkhovy.com/post/2015_01_10_what_i_do_significance_testing/","publishdate":"2015-01-10T00:00:00Z","relpermalink":"/post/2015_01_10_what_i_do_significance_testing/","section":"post","summary":"As much as I love languages, one of the things that frustrated me in linguistics was the seeming arbitrariness of theories. There was no way of knowing which one was better than another.","tags":null,"title":"What I do: Significance Testing","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"After almost 5 years, I am finally done with grad school! I just started a postdoc, so this is probably a good time to look back. Two friends recently asked me what my “grad school story” was. What had I learned during my PhD, apart from the obvious technical and academic skills? What were the things I wish I’d known before I started. It got me thinking: what would I tell myself if I got to go back in time? Here is what I came up with:\nTake breaks\nWhen I started grad school, I believed exhaustion, all-nighters, and 14h-days were hallmarks of a good grad student. Well, turns out they are not! I worked 12-14h every day, 8h on weekends. After 3 months, I was tired all the time and got sick on a biweekly basis (flu, stomach bugs, etc.). After 6 months, I was burned out, deeply unhappy, constantly sick, and seriously considered quitting. Worst of all: my productivity had constantly decreased. It was time to rethink my believes.\nGrudgingly, I learned to accept those limitations. I concentrated productive work (coding, writing) in my peak hours, and used the rest for “busy work” (reading, setting up experiments). Good time management is one of the key skills to learn in your PhD, and one of those they never teach you. It is simply impossible to produce quality work without taking a break every now and then. I have heard estimates that you can only be really productive for 6 hours each day.\nThe most important part of that were the breaks! I exercised, walked, had lunch with friends, read the newspaper. I was still thinking about my work. But getting some distance from it helped me see errors I overlooked when working constantly. Cutting back on my hours not only made me happier and healthier, it also made me more productive.\nIt also helped me to set myself an end time. I had some of my most productive times when I was dependent on a shuttle service and could only work until 5pm. I made every minute count, and went home in the evening without regrets. I got a lot done. Working 14 hours straight did not accomplish half as much―and felt a lot worse.\nKnow your advisor\nWhen I started out in grad school, I thought of my advisor as this superhuman being who knows everything. Apparently, I am not alone. This honeymoon period can last a while. Inevitably, though, everyone reaches a point where they disagree with their advisor. It can be a bit of a shock to learn that advisors are only human, too.\nAt the end of the day, though, it is good to remember that an advisor is the person who keeps you in business. They speak up for you in quals and screenings, vouch for you academically, introduce you to the right people, and help pay your tuition, travel expenses, and conference fees. They are busy people, and it is not their job to hold your hand, nor help you with the daily nitty-gritty. They have, however, spent a lot of time in the field and can help you find the right direction. It is up to you what you make of it, though. I know some people who have been discouraged by their advisor to pursue a project, only to find a paper on it at the next conference.\nIt helps to know what their strengths are and benefit from them, and find somebody else for the things they cannot teach you. The latter are often hands-on solutions and technical issues. Most of their hands-on experience is several years old and might be outdated, especially in a fast-paced field like computer science. That’s what fellow grad students are for….\nIt is your job to keep your advisor happy. Do the project work, help with classes, and listen to their counseling. But decide for yourself what applies to you. Part of your PhD is becoming your own researcher.\nTalk to people\nEven though it often felt like it, it was important for me to realize that I was not alone in the PhD! I was surrounded by other grad students and researchers, either directly or in my general community. When I started, I was lacking many of the computer science skills my peers had. I had the choice to either envy them or learn from them. The latter worked much better. I have learned more from water cooler talks and by asking colleagues than I have from most classes. I also learned a ton from collaborating on papers, and it’s less work for everyone. Internships and visits are a another great way to meet other people and get exposed to new ideas. I went to IBM and CMU, both for 3 months, and came back invigorated and full of new ideas and impressions.\nLearning how to talk to people also means giving good presentations. We need to share our ideas to get plenty of feedback. It helped me to find out how others perceived my research and to check whether that’s what I wanted to convey. If they didn’t get it, I reminded myself that it was probably my fault for not explaining it well enough: the audience is always right. This is especially true when talking to non-scientist friends: if I could explain it to them, I knew I had gotten to the core of the problem (this is sometimes also called the elevator pitch: can you explain your work to someone in the time you spent together on an elevator?). It’s difficult, but it helped me to think outside the box: there is always something in your work that relates to people’s everyday experience (even if it is remote). I think it also helps with writing papers―if you can explain what your work is about in a few simple sentences, people will be more willing to read your paper. Even scientists like a simple explanation better than a convoluted one.\nThe more specialized my work got, the more important I found it to keep an open mind in general. I found that somebody who works on something completely different can often offer an objective view or an alternative approach to the problem. I made it a point to go to talks outside my area, read papers on related topics and general science. What others do can be as interesting as your own work (but don’t fall into the trap thinking what you do is less interesting than everybody else’s work). Also, it helped me overcome the misconception that being opinionated is equivalent to being smart. It’s an easy mistake to make, but it’s still wrong. And yes, I did it, and I’m not proud.\nLast but not least, keeping an open mind helped me to learn other things as well. Even though I felt challenged with all the demands of my research, I found that over time, my mind got used to challenges. It made it easier to pick up some new non-scientific skills along the way (I learned dancing, cooking, and how to ride a motorcycle), and I’m glad I did (again: it helps to take a break sometimes).\nIt is impossible to be a good researcher when you never leave your room.\nGet a hammer\nIn fact, get a whole toolbox! Early on, I was told to find an approach, algorithm, data set, resource, or other method that I liked. For me, this was the EM algorithm: I love how you can solve a circular problem (if I knew X, I could solve Y, and vice versa) by just starting out somewhere and then refining your model step by step. It’s similar to how children learn about the world, and it can help with a range of problems.\nOnce I had that, I started looking for problems I could solve with it. I applied it to problems you cannot solve with it. That helped me understand why it works for some and not others. I learned a lot both about the problem and my hammer. It also expanded my technical expertise and helped me produce results more efficiently (and thus write more papers).\nIt’s important not to get too hung up on one thing, though! Not everything is a nail, and nobody likes a zealous one-trick pony. While it sometimes seems that academia rewards single-mindedness, it often leads those people down a path of no return when the paradigm shifts or their technique becomes obsolete. I learned to accept the limitations and explored alternatives.\nI tried to put as many things in my toolbox as possible, and to learn when to use them. This is an immensely fun part of the PhD, and I don’t even think I’m done yet.\nEnjoy!\nThis is probably the most important point. When I was so fed up with the program that I considered quitting, I paused and thought about why I put myself through this. Why did I do a PhD? And for whom? I realized that I was not in it for my advisor, for my family, or society as a whole, I wasn’t doing this for others―I was doing this only for myself. Because it is what I always wanted to do! If I didn’t become the next superstar in my field, so what? I was in it because I loved it. Not every second of it, for sure, but as a whole: that was enough to make those difficult times pale to insignificance in the grand scheme of things. Around that time, I went to a talk by Tom Mitchell, on how to predict what people had read by looking at their brain images, and I remember walking out thinking “There are so many more cool things I haven’t even started on, I can’t possibly quit now” (this is another reason why it is good to keep an open mind and check out other fields).\nWhen you’re in a PhD program, you are doing something very few people get the chance to do: you are at the cutting edge of research and work with interesting people on cool problems every day. Everybody gets down once in a while, and pretty much everybody considered quitting at some point. It’s good to remember what you’re excited about. And that you have every right to be excited!\nSo that’s it. This is what got me through my PhD. If I had to do it all over again, this is what I would focus on.\nThere are of course other good documents out there on how to make it through grad school, one of the better ones is this one by Hanna Wallach and Mark Dredze. Check it out.\n","date":1376870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376870400,"objectID":"a05b32de8c30791b128c3b6d220cbbb8","permalink":"https://dirkhovy.com/post/2013_08_19_how_to_be_a_good_grad_student/","publishdate":"2013-08-19T00:00:00Z","relpermalink":"/post/2013_08_19_how_to_be_a_good_grad_student/","section":"post","summary":"After almost 5 years, I am finally done with grad school! I just started a postdoc, so this is probably a good time to look back. Two friends recently asked me what my “grad school story” was.","tags":null,"title":"How to be a Good Grad Student","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Our software package MACE (Multi-Annotator Competence Estimation) is out! It provides competence estimates of the individual annotators and the most likely answer to each item. All you need to provide is a CSV file with one item per line.\nIn tests, MACE’s trust estimates correlated highly with the annotators’ true competence, and it achieved accuracies of over 0.9 on several data sets. Additionally, MACE can take annotated control items into account, and provides thresholding to exclude low-confidence answers. Feel free to check it out. Comments welcome!\n","date":1365120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1365120000,"objectID":"d9ce7e0fd7f70636ffbc34547ba370ca","permalink":"https://dirkhovy.com/post/2013_04_05_mace_available_for_download/","publishdate":"2013-04-05T00:00:00Z","relpermalink":"/post/2013_04_05_mace_available_for_download/","section":"post","summary":"Our software package MACE (Multi-Annotator Competence Estimation) is out! It provides competence estimates of the individual annotators and the most likely answer to each item. All you need to provide is a CSV file with one item per line.","tags":null,"title":"MACE available for download","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"I have noticed that some of my friends (mostly Germans) use a fake name on social networking sites. This started a few years ago, when it became clear that a) the security of these sites isn’t exactly Fort Knox and b) their business model includes selling your data. I assume therefore that the fake names are meant to protect your private information. While I understand the sentiment, I think this is futile, and just makes it harder for your friends to find you. Here is why.\nThe basic problem might be anthropomorphizing companies. If we assume that social networking companies use the same approach to searching for our information as you and me, a false name could throw them off. (It would be tempting at this point to speculate about the age-old belief that knowing somebody’s name gives you power over them, but that’s beside the point here)\nHowever, these companies don’t use humans to search for your data―they use machine learning. And for that, a fake name is just one little piece of data. One of many…\nSay you just opened an account and put down a nickname. Can you ensure that all your friends will address you with that name, mention you with that name, and that you will sign all messages with it? Are all your stated relatives using the same moniker? If you ever found a long-lost friend on the site and wanted to contact, can you avoid to sent a message saying “Hey long-lost friend, this is really Dirk Hovy, I am using a nickname, but I would like to re-connect.”?\nIf you answered “no” to any of these, all you managed is to make it a little harder, but not impossible, to get your real name. You more or less openly provided a decryption key that voids all your attempts at keeping your name safe. Just because you put something into a private message does not mean it is invisible. It’s just data, after all.\nEven if you managed to keep all of your communications under control: are you sure your account is not linked to any other sites that contain your name? Did you not sign up with this account when you bought something, have you not liked something with it, or linked it to some other account that contains your true name? If you have done any of the above, it will be the easiest thing in the world to find your true name and link it to your data. It is all a matter of connecting the dots. There are whole industries and research branches devoted to it, and the more dots there are, the easier it gets.\nI’m not trying to sound Orwellian, and I don’t mean to imply that those companies are evil by their nature. But their―more or less publicly―stated objective is that in exchange for letting you use their service, they get your data and sell it for profit. They are not in it for philanthropic reasons. They have bills to pay. You implicitly bought into that model when you signed up. You might have even explicitly agreed to it, provided you read all 25 pages of the end user agreement and were able to decipher the legalese. One can object to that model, but one cannot ignore the fact that it is reality.\nThe most secure option is obviously to not use any social networking sites, or the internet, for that matter. While this is 100% safe, it is also not very realistic.\nSo in the absence of that option, it is probably better to be more aware of what we put out there, and how easily it can be found. And if it is out there, it will be found and used. Don’t try to hide from a person if a machine is looking for you.\nUsing a nickname just makes it hard for your friends to find you.\n","date":1353456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1353456000,"objectID":"9be6fcfa7554b89db6b1142b3243d2b2","permalink":"https://dirkhovy.com/post/2012_11_21_fake_social_network_names_wont_protect_your_privacy/","publishdate":"2012-11-21T00:00:00Z","relpermalink":"/post/2012_11_21_fake_social_network_names_wont_protect_your_privacy/","section":"post","summary":"I have noticed that some of my friends (mostly Germans) use a fake name on social networking sites. This started a few years ago, when it became clear that a) the security of these sites isn’t exactly Fort Knox and b) their business model includes selling your data.","tags":null,"title":"Fake social network names won’t protect your privacy","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Writing your papers in LaTeX is great and you should definitely do it. It makes everything better (with the possible exception of grammar), but you have to trust it with the formatting. This is where it gets tricky. Most papers have a page limit, and while LaTex makes sure everything lines up perfectly, it does not care about how many pages it takes. Trimming the paper to a certain page limit thus becomes a familiar headache before every deadline. Luckily, you don’t have to rewrite the whole paper to make the limit. Here are some simple tricks I found helpful to save a lot of space.\nDon Metzler showed me a great and easy technique to trim your paper considerably:\nfind all paragraphs that have three or fewer words on the last line\nshorten those paragraphs so that the last words advance into the previous line\nYou can leave paragraphs with more than three words on the last line alone, so instead of rewriting everything a bit, you can focus on a few paragraphs.\nThis only eliminates one line per paragraph, but due to the way LaTex spaces out paragraphs over the page, this actually shortens the overall paper quite a bit. Treat three or four paragraphs that way and you might cut your paper by half a page.\nSo, how do you shorten those paragraphs? A good way is to get rid of redundant or “empty” expressions. One that I found myself using way too often is “especially in the case of”, as in “This is annoying, especially in the case of long paragraphs”. The expression is perfectly grammatical, but we can convey the same meaning by just using “especially for”, as in “This is annoying, especially for long paragraphs”. “Especially” already singles out a special case, so we don’t have to say it again. We don’t lose any information, but save three words, and―what’s more important in LaTeX―three white spaces. LaTex spaces out words evenly across each line, mainly by varying the size of spaces (it also varies character spacing, but to a lesser degree). So having fewer characters and white spaces shortens the line, which in turn shortens the paragraph, which in turn shortens the page, which in turn allows you to keep your page limit.\nOther phrases that can be shortened: verb plus nominalization, if there is a proper verb for it. I find myself using lots of these constructions. Instead of saying “we used this for our evaluation”, just make it “we evaluated this”.\nThe Chicago manual of Style also identifies these candidates:\n“due to the fact that” = “because”\n“in connection with” = “of”, “about”, or “for”\n“at this (point in) time” = “now”\nThe best way to save space, however, is to delete useless phrases. Many papers include a paragraph which starts with “The remainder of this paper is structured as follows:…”. I automatically skip ahead if I see this. In a 8-page paper, you do not need an overview: I can get that by just flipping through. After all, that’s what section titles are for. And do sentences like “We first introduce the problem in Section 1” or “Section 5 concludes the paper” really add anything to my understanding? Do they need to tell me that the section titled “Evaluation” will “present the evaluation of the experiments”?\nLeaving this overview-paragraph out saves a lot of space, and does not take anything away from the content.\nOf course it’s good to pay attention to these things while writing, and express yourself as clearly and succinctly as possible. But a few of these cases will creep in anyways. And when it is time to trim the paper, they are a good starting point.\nIf you have more tips or suggestions, please share! Let’s make meeting page limits in LaTex less scary.\n","date":1348531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1348531200,"objectID":"7b633a5ac09d930c5ce876095b792d3e","permalink":"https://dirkhovy.com/post/2012_09_25_trimming_papers/","publishdate":"2012-09-25T00:00:00Z","relpermalink":"/post/2012_09_25_trimming_papers/","section":"post","summary":"Writing your papers in LaTeX is great and you should definitely do it. It makes everything better (with the possible exception of grammar), but you have to trust it with the formatting.","tags":null,"title":"Trimming Papers","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"I have talked before about how important it is for scientists to express themselves well, and the most important aspect of that is to give good talks. I am far from being a good speaker, but I am a little obsessed with learning what makes one.\nSo I recently went to a workshop on presentation, and came away with some good tips:\nuse dark background. It is much easier on the eyes of your audience, broadens your screen estate, and prevents you from casting weird shadows when you stand in front of it (some people dislike it, though, because it’s so dark)\nshape your talk like a glass: start broad and then narrow to the details (the cup of the glass), stay on them for a while (the stem), and end broadly (the foot)\nmaximize the axis space of graphs to fill as much of the screen as possible. Push the legend and title into the graph area, in blank spaces\ndo not use a laser pointer. If you want to point something out, circle it on the slide\nOne of the best ways to get better is to watch good presentations and note what they do. Here are a few presentations I particularly enjoyed, and what I think makes them interesting:\nDick C. Hardt on “Identity 2.0”. I have no idea what “Identity 2.0” is, and I don’t think it caught on, but the rapid-fire presentation style is fascinating and easy to prepare. Though hard to pull off…\nGuy Kawasaki’s talk for entrepreneurs uses minimal slides, and a lot of great lines. Some of what he says is even relevant for presentations, but mostly, it is fun to watch and easy to follow.\nChip Kidd talks about book covers, but he drives home an important point: show or tell, but not both―your audience is not stupid. “And they deserve better.”\nThe previous talks are about big ideas, and thus a bit abstract. Hans Rosling shows how you can take hard data and make its presentation palatable and fun. This takes a lot of work in preparation, but it shows you that you don’t always need the same old boring graphs.\nSimilarly, David McCandless shows how information can be conveyed in interesting and appealing ways. Maybe not always achievable for the average scientist, but worth thinking about, and looking at.\nWhat comes through for me in all the good talks is this: keep it simple. Use pictures more than words. Your slides should be secondary to your talk. They do not need to be interpretable without you. That’s what a paper or a handout is for.\nI recently tried cutting text as much as possible in my proposal talk, and got very positive feedback about the slides. It is harder for scientific presentations than for general talks, since you want to convey a lot of detail and nuances, but it helps to focus the attention. I plan to reduce to the max.\n","date":1347580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1347580800,"objectID":"1ba1c5dd97e4cf19a85ca32a5e063a93","permalink":"https://dirkhovy.com/post/2012_09_14_the_art_of_good_presentations/","publishdate":"2012-09-14T00:00:00Z","relpermalink":"/post/2012_09_14_the_art_of_good_presentations/","section":"post","summary":"I have talked before about how important it is for scientists to express themselves well, and the most important aspect of that is to give good talks. I am far from being a good speaker, but I am a little obsessed with learning what makes one.","tags":null,"title":"The Art of Good Presentations","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Together with my roommate, I found a great way to prepare chicken. It cooks quickly, stays moist, and is almost impossible to mess up. I made variations of it four times during the last week. Here goes:\nTake chicken breast, pat dry and cut into small strips.\nPut strips in a ziplock bag and add salt and a few table spoons of corn or tapioca starch.\nHeat a pan, add oil.\nShake chicken strip in a strainer to get rid of excess starch.\nFry the chicken in pan.\nYou can stop here and eat the delicious, juicy chicken. The starch creates a thin layer of insulation between meat and pan, so that the chicken cooks more evenly and doesn’t dry out. You can add other spices to the starch, if you are so inclined. Allspice is pretty awesome.\nOr you can go in to make an orange chicken that beats the crap out of anything you get at a Chinese fast-food restaurant:\nMix the juice from 3 limes with the same amount of orange juice and some fermented chili sauce.\nAdd to the cooked chicken strips.\nReduce until strips are just coated with a thin film.\nEnjoy!\n","date":1334448000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1334448000,"objectID":"269899a6066c85f3eba92915b5f22e2f","permalink":"https://dirkhovy.com/post/2012_04_15_orange_chicken/","publishdate":"2012-04-15T00:00:00Z","relpermalink":"/post/2012_04_15_orange_chicken/","section":"post","summary":"Together with my roommate, I found a great way to prepare chicken. It cooks quickly, stays moist, and is almost impossible to mess up. I made variations of it four times during the last week.","tags":null,"title":"Orange Chicken","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"While writing on my thesis and various papers, I found that there sometimes is a disconnect between my perception and what others make of the same data. I started thinking about why that is and how it could be solved. I found a simple, yet effective solution: have other people tell you their version of the story. Here is why.\nOne of the most important aspects of research is communicating your ideas. It does not help the world if you are brilliant but cannot convey your thoughts. It is also one of the most difficult tasks. What you want and what your average reader wants differs slightly, and while you know your needs, in the end, it is the needs of your readers you have to cover in order to convey your idea.\nBy the time you are ready to publish, you have spent a lot of time setting up experiments, tweaking parameters, searching related work, and collecting data points. You have devoted a sizeable part of your life to this, you know all the details, and you are very attached to the outcome. You want the world to know how much work it was, and to be able to understand it in all its complexity.\nThe awful truth is: most people do not care about the details of how you reached your final results. At all. They want a take-home message they can readily understand themselves and relate to others. And they should get one!\nDwelling on the details might make your paper very reproducible, but it is also a surefire way to drive away your readers. They will soon lose interest and skip the details, trying to find what they are looking for. Or stop reading altoghether. If this happens, all your work was basically in vain. They won’t get your idea, and they won’t tell others about it.\nSo how can you meet your readers needs?\nA solution that worked surprisingly well for me was to simply ask them. Tell your friends/colleagues the general problem, give them a few data points, and ask them what they think the paper looks like (obviously, don’t give them your version yet). You’d be surprised how much the stories can differ.\nYour friends are unburdened by the details, and still able to see the forest instead of the trees. If they ask you for more information, supply it. You will learn which parts only you saw (because you spent so much time on it), and you can go back and make them clear(er).\nPay attention to how they would present your findings. What do they emphasize, what do they leave out, what is the story they spin? If they reach another conclusion, maybe you need to give them more information, or you have to re-evaluate yours. Don’t reject their outline thinking they did not understand it. If they don’t, neither will your reviewers!\nIf you do it with enough people, you will find things that pop up again and again, and the holes that need to be filled.\nThis solution is obviously not foolproof. You have to be able to let go of some parts you really liked, and you have to be able to draw attention to some important your helpers might have skipped. It can not guarantee you an accepted paper, but it will help you to make it more readable, and convey your idea better. Also, it’s a good way to let your friends know what you’re working on.\n","date":1332979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1332979200,"objectID":"1818e5629e785462646a00143689702c","permalink":"https://dirkhovy.com/post/2012_03_29_in_other_words/","publishdate":"2012-03-29T00:00:00Z","relpermalink":"/post/2012_03_29_in_other_words/","section":"post","summary":"While writing on my thesis and various papers, I found that there sometimes is a disconnect between my perception and what others make of the same data. I started thinking about why that is and how it could be solved.","tags":null,"title":"In Other Words","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"German researchers have drafted a position paper in which they demand science be decelerated in order to improve its quality. Their points are (Die Zeit article 4/14/2011):\nworldwide reduction of publications to allow scientists to survey the field and ensure quality\nresearch needs a basic funding, yet cannot be economically evaluated like a company\nfunding should be based on content, not projected success\nauthors should only appear on papers if they contributed to it\nscientists have to write their own grant proposals, no agencies should do that or even correct the scientists\nexperiments need to be more transparent and reproducible\ngood science is only possible with long-term grants\nWhile I agree with most of the ideas (I do think that a base funding would be a Very Good Thing for a couple of less flashy disciplines, and I do agree that science should be about substance first), I take issue with the latent notion that science is too fast, too competitive, and that presentation is overrated.\nScience is all about ideas, even half-baked ideas, and, more importantly, sharing them. No major work was created by one person out of thin air, but resulted from building on what other people have done before, however small it was. If those other people had waited to publish it until they thought it was complete, it might have never seen the light of day. Or, more likely, it would have, but published by somebody else, who was not as hesitant. Of course you should wait until you are reasonably sure your results are sound, but there is a point where it turns into procrastination. If you do not publish, nobody knows you are brilliant (they also won’t know if you are clueless…)\nPart of a scientist’s skill set is to navigate and assess the body of work in his or her field. There are increasingly more tools to help you achieve that. Scientists know which journals are hard to get into, and which ones will print anything as long as it has a title. Researchers will assess work also based on where it is published. Both quality and quantity matter. Someone who has had only one paper in 10 years, but in Nature or Science, is not much better than someone who has cranked out four papers a year in obscure journals over the same time span. Granted, the first guy has substance, but who tells me he could do it again? With the other one I know at least what he was up to, and that his ideas were bad. Luckily, most people will lie somewhere in the midlle. So the flood of publications is actually a boon rather than a bane.\nBy artificially restricting the number of publications, you do not necessarily improve quality (transparency and fairness of acceptance criteria is an issue to itself), but take away a lot of breadth and information.\nAnd, yes, science is about presentation: if your idea is too complicated to explain it, chances are it is not worth explaining anyways. Some people maintain that you should be able to explain your whole research idea during an elevator ride. A lot of the great ideas are exceedingly simple, and a lot of good papers are good because they explain their point well. A brilliant mind that cannot communicate its brilliance is no use to the academic world, least themselves. The fact that the occasional showman gets a grant although his ideas are not very deep should not stop us from rewarding good presentations!\nYou might not like it, but I am sure that fast, competitive, and presentable science improves our general knowledge and understanding of the world. Artificial boundaries and regulations do not. The times when researchers could sit in their study and worry about one thing for years are gone. Now, you have to go out and present it, for money, for visibility, and ultimately also for the advancement of science.\n","date":1318723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1318723200,"objectID":"3e016f88a2f77bc79279fb5111d1a039","permalink":"https://dirkhovy.com/post/2011_10_16_science_and_showmanship/","publishdate":"2011-10-16T00:00:00Z","relpermalink":"/post/2011_10_16_science_and_showmanship/","section":"post","summary":"German researchers have drafted a position paper in which they demand science be decelerated in order to improve its quality. Their points are (Die Zeit article 4/14/2011):\nworldwide reduction of publications to allow scientists to survey the field and ensure quality","tags":null,"title":"Science and Showmanship","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"One thing I wish I was, apart from brilliant, is to be fascinated by boring things.\nThink about it: it would have so many advantages. Like that linear algebra class you had in high school when you could barely stay awake, and now you try to remember how to invert a matrix. Or the list of all the resources that everybody on you project agrees would be really useful to have, but nobody wants to actually sit down and compile it, because the thought alone makes half your brain fall asleep.\nIf you were excited by all of that, you could get a lot of good work done. On the downside, you might also become the go-to guy for everyone with a boring task. Hey, you can’t have everything! At least you wouldn’t be bored…\n","date":1303776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1303776000,"objectID":"a4da8312813c630b1bdca64af3864191","permalink":"https://dirkhovy.com/post/2011_04_26_one_wish/","publishdate":"2011-04-26T00:00:00Z","relpermalink":"/post/2011_04_26_one_wish/","section":"post","summary":"One thing I wish I was, apart from brilliant, is to be fascinated by boring things.\nThink about it: it would have so many advantages. Like that linear algebra class you had in high school when you could barely stay awake, and now you try to remember how to invert a matrix.","tags":null,"title":"One wish","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"After some deliberation, I decided to write my future posts in English only, to speed up my blogging freqeuency.\nTranslation took up too much time, and in some cases prevented me from posting at all. I will catch up on these posts now.\nSince my German readers have excellent English skills, this solution leaves nobody out.\nYou can expect more posts in the future.\n","date":1302825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1302825600,"objectID":"1532b1daefcefd410f41d11011692f5a","permalink":"https://dirkhovy.com/post/2011_04_15_language_change/","publishdate":"2011-04-15T00:00:00Z","relpermalink":"/post/2011_04_15_language_change/","section":"post","summary":"After some deliberation, I decided to write my future posts in English only, to speed up my blogging freqeuency.\nTranslation took up too much time, and in some cases prevented me from posting at all.","tags":null,"title":"Language change","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"My grandmother could never throw anything away. Occasionally, my mom and her sisters would clean out the pantry, and my cousins, siblings, and I would stand by and bet on the oldest item. A ten year old ketchup bottle? A pack of custard powder several years over its due date? Or maybe something that had to be bought with post-war food stamps?\nMy Grandmother had a very different approach to food than we do. She raised six kids on a budget, during and after the war. If something grew moldy, she would cut out the soiled parts and declare the rest perfectly edible, and, in fact, eat it. I don’t think she ever got sick. She told us that dirt made you healthy, and my mother related to me that as kids they believed one pound was the acceptable amount of dirt per year.\nMy grandmother had learned cooking professionally, and when I say professionally, I mean efficient, not fancy. For our family dinners, she cooked for an army, and her meatloafs and patties are legendary. My mom’s were good, but these were heavenly, probably because my grandma believed that more fat makes anything better. She was a round woman with rosy cheeks, and in my memory, she always wore a flowery dress and a grey wig. She would roll down hills with us kids and could pop out her dentals, which we thought was the coolest thing ever. If we were grumpy, she would give us “laughing pills”, what other people called Mentos.\nHer two worst memories were the night they bombed the neighboring city, when the horses screamed in their stables ( “Have you ever heard horses scream”, she would whisper with a shudder), and the Polish soldier who stole her strawberries. When she grew old, she was cared for by a Polish nurse, and I think Poland was able to redeem itself in her opinion. After the death of my grandfather, she got very sad and only wanted to be reunited with him.\nShe died during the night, with one eye open and a surprised look on her face.\nI often think of her when I cook, and what she would have done. I collect and filter the grease whenever I fry bacon. I buy cheap cuts of meat, like shoulder or chicken hearts. I think fat makes everything better. When I cook, I cook for an army.\n","date":1290211200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1290211200,"objectID":"9a4b3e72fe00430c3dc1c4ecce69a2e5","permalink":"https://dirkhovy.com/post/2010_11_20_remembering_the_dead_/","publishdate":"2010-11-20T00:00:00Z","relpermalink":"/post/2010_11_20_remembering_the_dead_/","section":"post","summary":"My grandmother could never throw anything away. Occasionally, my mom and her sisters would clean out the pantry, and my cousins, siblings, and I would stand by and bet on the oldest item.","tags":null,"title":"Remembering the Dead, 1","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Like millions before me, I arrived in New York with a sense of wonder. I had been reading on the train ride into Penn station, so my first glance of the city was when I stepped out onto seventh street. It was a clear midwinter afternoon, and the low sun illuminated the tips of the skyscrapers and filled the streets with a soft light. I was immediately captivated. I had been meaning to come here for a long time, and finally I had made it.\nUnless millions before me, however, I had not come from distant shores to build a living here. I was only visiting for an afternoon from New Jersey.\nMy first action was to find a Starbucks, something I imagined to be a little easier in New York. Eventually, I succeeded, got a coffee, and left through the backdoor into some sort of mall. Uniformed pages showed people around, a group of women was taking pictures of the ceiling. I started to wonder…\nOnly when stepping out onto fifth street and glancing up the facade, I realized that I had just unknowingly visited the Empire State Building. They should put up signs…\nNew York is very different from LA. There are no Empire State Buildings, for a start. Also, new York is reigned by pedestrians. As soon as the cars slow down, they start crossing the street, no matter whether it’s red. If you do that in LA, you’ll get fined for jaywalking. Here, you only get fined for not walking.\nNobody asked how I was doing or wished me a good day, and I adapted quickly to the environment. I rolled my eyes at people slowing down, I snarled at people stopping to watch the shop windows. I’m sure New Yorkers have their bad reputation because of visiting Angelinos who enjoy being rude for a day.\nOk, not true, I did neither of the above. Without looking at anyone, I just walked at a quick pace up the street, headed for Central Park before it gets dark. I saw Macy’s windows and the Rockefeller Center christmas tree. I stopped at a cathedral that stood in stark and comical contrast to the high risers around it, seeking some rest from the bustling streets, but it was just as busy inside as outside. I strolled through the beginning of Central Park and got a bad Espresso and hot chocolate at a hip cafe. Eventually, I swam anonymously through the crowds down Broadway, washed into Penn station, and boarded the next train back to New Jersey. A state that is much nicer than it’s bad reputation. I’m almost sure it’s due to visiting Angelinos…\n","date":1260835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1260835200,"objectID":"4ac0831db7780eafd497cf5eabc8d2d9","permalink":"https://dirkhovy.com/post/2009_12_15_new_york_i_love_you_but_youre_bringing_me_down/","publishdate":"2009-12-15T00:00:00Z","relpermalink":"/post/2009_12_15_new_york_i_love_you_but_youre_bringing_me_down/","section":"post","summary":"Like millions before me, I arrived in New York with a sense of wonder. I had been reading on the train ride into Penn station, so my first glance of the city was when I stepped out onto seventh street.","tags":null,"title":"New York I love you, but you’re bringing me down","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Sometimes, you see things only from a distance. Birthdays, for example (whoever had their birthday lately knows that I need a little longer). When the Wall fell, I was eight. At that time it seemed nothing special. I only remember that everyone was very excited and watched a lot of TV. This was rare (the watching television), and therefore had to mark something special. I was told that there had been a border in Germany, which was now gone. That did not impress me much. When we went on holiday in France, there was a border, too, and that was always a lot of fun. Also the fact that they spoke German on the other side of the border I found little remarkable. I had an aunt in Austria, and there was a frontier, too, and on the other side they spoke German. With eight, geopolitics is still rather simple…\nOnly when I look back now, things seem more remarkable. And more complex. Germany and Europe are what they are, last but not least because of those days in the fall, when my family watched a lot of TV, and everything that ensued. And not, as some here would have you believe, because a senile ex-actor proclaimed “Tear down that wall” (even less because of a third rank star with fake chest hair humming silly little song about freedom. But then, nobody but him believes that anyways). And it is good the way it is. At least, from a distance, it does not look half as bad as one would have it at home.\nSometimes you only miss things from a distance. Things that you have not previously noticed, or found ridiculous. Many little things: long train rides through wooded hills, deli-meat-specialist saleswomen, autumn fires, bakeries, Feierabend beer, shop talk about football, the deep rooted belief that everything in this world can be solved efficiently in a very specific way.\nBut of course, mainly the loved ones you left behind, in that reunified country on the other side of the globe.\nAnd before you know it, you find youself sentimentally murmuring what Hoffmann von Fallersleben wrote down nearly 170 years, Einigkeit und Recht und Freiheit… Happy Birthday, Germany! Be well, and stay as you are. You are ok the way you are.\nLike I said, I always need a little longer for birthdays…\n","date":1259712000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1259712000,"objectID":"9c01f27edebe0b79a467900fd6bf176f","permalink":"https://dirkhovy.com/post/2009_12_02_belated_birthday_wishes/","publishdate":"2009-12-02T00:00:00Z","relpermalink":"/post/2009_12_02_belated_birthday_wishes/","section":"post","summary":"Sometimes, you see things only from a distance. Birthdays, for example (whoever had their birthday lately knows that I need a little longer). When the Wall fell, I was eight. At that time it seemed nothing special.","tags":null,"title":"Belated Birthday Wishes","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"For some time now, I have been a subscriber to the magazine “Cooks Illustrated”. A friend described it as “food porn”, but the focus is less on sensual pleasure than on scientific analysis (you know that a food magazine is serious if they print in two columns, and only in B/W).\nRecipes are varied ingredient by ingredient, tested and the outcome reported, until you get the best possible result. In addition, you get tricks and tips and kitchen tool reviews.\nMy absolute favorite by now is a recipe for ricotta. Super easy, fast, and very delicious! And a worthy replacement for the unobtainable Quark. Here’s my version (original in Cooks ilustrated Oct 2009):\nHeat a gallon of whole milk with a tablespoon salt to 185°F, or until surface slightly ripples. Take off the flame and add 1/3rd cup of lemon juice. Let stand for 5 minutes. If the consistency is not curdly enough, add another tablespoon of lemon juice. Repeat until there are no more changes in the consistency. Skim off the mass with a strainer and put it in a colander lined with kitchen towel. Put over a bowl and leave overnight in the fridge.\nThe next morning, you have fresh ricotta, somewhere between cream and cottage cheese. Tested in pasta and with honey for dessert.\nGuten Appetit!\n","date":1253750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1253750400,"objectID":"1a2bef29549749d69e66798edbedb293","permalink":"https://dirkhovy.com/post/2009_09_24_food_nerd/","publishdate":"2009-09-24T00:00:00Z","relpermalink":"/post/2009_09_24_food_nerd/","section":"post","summary":"For some time now, I have been a subscriber to the magazine “Cooks Illustrated”. A friend described it as “food porn”, but the focus is less on sensual pleasure than on scientific analysis (you know that a food magazine is serious if they print in two columns, and only in B/W).","tags":null,"title":"Food Nerd","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"And then, suddenly, it is summer. The days are only a little bit hotter, yet the nights are warm and mediterranean. If Angelenos sat outside, this is when they’d do it. Yet people are fleeing LA for the long weekend, clearing the freeways, leaving the city behind.\nFires rage on the hills encircling it. At night, you can see their orange glow on the slopes. By day, an unwavering pillar of smoke marks their position. It mingles with the smog of downtown and tints the sunsets pink and orange. It rains soot over the city and can be smelled as far as the coast. And it greets the people coming back into LA as they fly through it: You might leave for a weekend, but the city is still here. With its fires.\nAnd so is summer…\n","date":1252195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1252195200,"objectID":"b50fc3af473fcfc582b4c11e77992bc5","permalink":"https://dirkhovy.com/post/2009_09_06_summertime/","publishdate":"2009-09-06T00:00:00Z","relpermalink":"/post/2009_09_06_summertime/","section":"post","summary":"And then, suddenly, it is summer. The days are only a little bit hotter, yet the nights are warm and mediterranean. If Angelenos sat outside, this is when they’d do it.","tags":null,"title":"Summertime","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"There are two kinds of researchers: scientists and engineers. Faced with a problem, the scientist will say “How interesting” and proceed to abstract and classify it, develop experiments to reproduce it, and come up with a theory to understand it.\nFaced with a problem, the engineer will say “How can we solve this” and proceed to measure and discretize it, build a model, refine and rework it, until it solves the problem.\nThanks to science, our understanding of the problem has increased. Thanks to engineering, we have one problem less. Ideally, these two disciplines should work hand in hand. Scientists analyze the problem to help understanding it, with an eye on possible solutions. Then engineers use that knowledge to solve the problem more efficiently. And indeed, scientists often try to sound more engineering, and engineers more sciency. But that is mostly wishful thinking.\nIn reality, the two camps know little and think even less of one another. Scientists easily get absorbed and sidetracked by fascinating details, producing knowledge for the sake of knowing. Engineers get just as fascinated, yet with task specific details, tailoring their solutions so exactly to the problem at hand that they have to start almost from scratch when faced with a similar one.\n“What do I care why it works, as long as it does”, says the engineer. And more often than not, it involves some hack to get there.\n“What do I care how it works, as long as we learn something”, says the scientist. Yet sometimes, even that is not guaranteed. The main difference between the two is the nature of the outcome. Engineering sells better, science―not so much.\nLinguistics is clearly a science (I could not think of any product linguistics has fostered). Computer science, despite the name, is mostly engineering (unless it’s theoretical CS). Somewhere in the middle, there’s Computational Linguistics, and there, waving, is little me…\nIn this ambivalent field, one seems to have to choose a side. Being a linguist by training and nature, I am primed on sciences. Yet getting a PhD in CS often incurs being asked to solve engineering problems which have a linguistic component. It’s like trying to make me an engineer with a knack for language. It took me the better half of a year to realize that that is not who I am: I want to us the toolkit of CS to understand linguistic problems. A scientist with a knack for engineering, maybe. A fine distinction, yet an important one. At least for the person who makes it… But what does it matter, as long as we can bridge the gap between the two!\nThanks to engineering, this is the first post I wrote in English and then translated back into German. And thanks to science, I was able to know which parts I should correct. And why…\n","date":1250726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1250726400,"objectID":"8e77fea87e0fa1b1580dbc07fb67a37d","permalink":"https://dirkhovy.com/post/2009_08_20_science_vs_engineering/","publishdate":"2009-08-20T00:00:00Z","relpermalink":"/post/2009_08_20_science_vs_engineering/","section":"post","summary":"There are two kinds of researchers: scientists and engineers. Faced with a problem, the scientist will say “How interesting” and proceed to abstract and classify it, develop experiments to reproduce it, and come up with a theory to understand it.","tags":null,"title":"Science vs Engineering","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"I love eating! And I love cooking. Perhaps even more than eating. Whoever is surprised by this does not know me well. Cooking for me is far more exciting than eating the final product. Perhaps because it has no more secrets. The interesting part is to figure out if everything went smoothly, as I had hoped for. And rather than for me alone, I cook for others―the more the better. Eating is the most direct way to show someone you like them, and I haven’t yet met anyone who does not appreciate that.\nFood is―besides language―one of the most salient features of a culture. But more often than not, the most famous dish is not everyday food. When it comes to national cuisine, we all go back to stereotypes: as a German, of course, I love beer, miss bread with crust, and would die for bratwurst with sauerkraut.\nDarkly, people have prophesied before my arrival in LA that I will be a wabbleing lardass in no time, thanks to a diet of hamburgers, French fries and donuts. What else do Americans eat…?\nBut wait! Americans love good food. They celebrate it! There is a TV station which broadcasts nothing else, there are countless journals, websites and local groups, sharing insider tips, recipes and restaurants. And California is especially ideal for this. You get everything fresh: meat, fish, vegetables, fruit―the producers are only a few minutes drive away. Accordingly, there are Farmer’s Markets in each district, and the supermarkets carry everything your heart desires. And at any time.\nEach immigrant group has brought their own recipes, adjusted them to the local produce, and all peek into their neighbor’s pots. Americans are new to the international market of cooking traditions, but they have no inhibitions, they’ll try everything. And without the ballast of tradition, they pick from each recipe the best and continue from there on.\nCalifornian wine can easily keep up with Bordeauxs, but costs only half as much. And, it has to be said: American beer is excellent! I have found a lot of great beers, often by small local breweries, which are not exported. What you get in Germany is waht nobody here drinks. (And no, German beer is not automatically the best in the world. Purity law or not: some insipid brews I have chugged out of patriotism were no advertisement for the German brewing tradition).\nDowntown, there is restaurant with the beautiful name “Wurstküche”, and from Knack to Bratwurst and rattlesnake-rabbit links, they serve everything you can cram into guts.\nOnly the bread here still needs practice. No crust and fuzzy consistency―this can pass as “bread-like pastry” at the most. I’m doing my part to educate and provide home-baked goodies for my colleagues. Multigrain with spices, coriander with apricot and pistachio, or chocolate with cranberries―I have adjusted my palette to the local palate, spread the recipes and wait for it to bear fruit. The reactions are unanimously positive. The only setback: The crust was too cross, I was told. But there I am not willing to make compromises! As I said, we still practice …\nThe problem with German stereotypes, actually, is that although they are not representative, they all apply to me… Bread, sausage and beer? Bring it on!\nMy eaten Donuts, on the other hand, I can count on a few fingers, for the Hamburgers I need two hands. In fact, I have lost 10lbs within 3 months, simply by eating more consciously (and a little stress). Even in America there is salad…\n","date":1250035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1250035200,"objectID":"de6b5c40330512293c7aac44742ee8f0","permalink":"https://dirkhovy.com/post/2009_08_12_bratwurst_mit_sauerkraut/","publishdate":"2009-08-12T00:00:00Z","relpermalink":"/post/2009_08_12_bratwurst_mit_sauerkraut/","section":"post","summary":"I love eating! And I love cooking. Perhaps even more than eating. Whoever is surprised by this does not know me well. Cooking for me is far more exciting than eating the final product.","tags":null,"title":"Bratwurst mit Sauerkraut","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Apparently, I just live down the road from the bar that was the inspiration for Moe’s tavern in the Simpsons. I will check that out…\nCan I talk to Mr. Freely? First name I.P…\n","date":1246233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1246233600,"objectID":"f3595cea97b5e637977d4aa94428486d","permalink":"https://dirkhovy.com/post/2009_06_29_movie_world/","publishdate":"2009-06-29T00:00:00Z","relpermalink":"/post/2009_06_29_movie_world/","section":"post","summary":"Apparently, I just live down the road from the bar that was the inspiration for Moe’s tavern in the Simpsons. I will check that out…\nCan I talk to Mr. Freely?","tags":null,"title":"Movie World","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"When I arrived here, my attitude was the same as every European’s fresh off the boat―a feeling of calmly assumed cultural superiority. The same kind of feeling you have towards high school kids talking about poetry, or the new guy in your office droning on about workflow. Experience, time, let’s face it: History is on your side! Surely, coming from a continent that has such a diverse culture, such a cornucopia of wars, famines, great thinkers and glorious artists makes you a more sophisticated human being than these youngsters? I laughed at “historical buildings” that are barely 200 years old, I chuckled at the subject of American history.\nBut working in America is a humbling experience. People get up early and go to bed late. There is no sentimentality lost, work has to be done, no matter what. The only thing you are judged by is the impact of your work. And you realize: All your sophistication, culture and history buy you nothing! The people who came here more often than not did so because they wanted to leave their old lives behind. Together with the history, the culture, and the prejudices. Coming here was making a clean slate―your religious beliefs, your philosphical views were secondary to your ability to make a life. History was what you made for yourself. You can knowledgeably talk about medieval poetry, Romanticism and dialectic? Good for you! Now, concerning that deadline…\nAnd then, what kind of history would a German and a Chinese immigrant have to share? The first point in time they both could relate to was the time they arrived here. What each of them had thought of as historical facts was just an interesting story from another place and time to the other. Even if you did not want to leave the past behind, it was something you shared with a much smaller group, something private and reserved for special occasions. So while many Americans treasure their heritage and take interest in the countries of their ancestors, they do so in their spare time. History is something that happened in the past, but we are living now!\nAnd just in case it becomes history some day, we better do a good job in the meantime…\n","date":1240876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1240876800,"objectID":"72ed8cd89d230d88f9b382037d20a855","permalink":"https://dirkhovy.com/post/2009_04_28_insights_of_a_travelling_salesman/","publishdate":"2009-04-28T00:00:00Z","relpermalink":"/post/2009_04_28_insights_of_a_travelling_salesman/","section":"post","summary":"When I arrived here, my attitude was the same as every European’s fresh off the boat―a feeling of calmly assumed cultural superiority. The same kind of feeling you have towards high school kids talking about poetry, or the new guy in your office droning on about workflow.","tags":null,"title":"Insights of a travelling salesman","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Picture the late morning sun over LA, lazily shining through the open front door of a single storey house. As it crosses the threshold, it passes waves of Tango music, floating out into the Easter Sunday. As it hits the battered hardwood floor, legs move swiftly through the beam, wearing high heels and dancing shoes. On a table in the kitchen wait banana pancakes, tamales, fruit, and orange juice for the dancers.\nWhat a perfect way of celebrating Easter…\n","date":1239494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1239494400,"objectID":"972c184e6f81f4724aa560fe6faa8899","permalink":"https://dirkhovy.com/post/2009_04_12_picture_this/","publishdate":"2009-04-12T00:00:00Z","relpermalink":"/post/2009_04_12_picture_this/","section":"post","summary":"Picture the late morning sun over LA, lazily shining through the open front door of a single storey house. As it crosses the threshold, it passes waves of Tango music, floating out into the Easter Sunday.","tags":null,"title":"Picture this…","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"“You write so infrequently”, I hear quite often. “I have too much to do,” I then reply. That is true, but there is of course more. Everyone likes to hear good news, or at least exciting ones. And in recent weeks, there was not much of either of them. Not only the global economy, also my life showed signs of unhappy development. And the Californian sun was behind thick clouds.\nBack from Germany, I got really aware of how far away I am. Not only geographically, also mentally. My attempt to tell people here about Germany showed me how much I’ve taken for granted, how little things I questioned or had consciously perceived. How does the German insurance system work, what exactly does the Bundespräsident do, why are there Haupt and Real schools (and how do they translate), and where is the difference between the Bundesrat and Bundestag?\nAt the same time I am still a foreigner here: I know no American lullabies, was spared from high school hell, and so far I have never thought about my credit report. I felt like sitting between all chairs. I even thought my English was deteriorating.\nIn addition, my research inched forward slowly, I long puzzled over my schedule, and there were some things in my private life I had to set straight. Nothing great, but in sum unnerving. My morale was struck. To make matters worse, in February, I had an accident. No physical consequences, but the car was out, and that in LA is synonymous with disaster. The low point was reached.\nPerhaps a good thing, because from there on it went uphill. After a shock, you can see things more clearly: I have reorganized my week, redefined my targets, and concentrated on fewer things, but with more energy. And that did it. I am happier and more content than before, university and job are fun again, and the thing with the car was also taken care of. The insurance was helpful and friendly, many people have given me advice and practical help, and since yesterday I’m glad the owner of a bright red Nissan Versa. I am still a foreigner, but I am not the only one. And it can be quite charming, too. Just what the deal with Hauptschulen is escapes me still…\nSo, this is it! After every rain there’s sunshine, even and especially in California…\n","date":1235952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1235952000,"objectID":"1f286234d8e4c21f851660291656ee18","permalink":"https://dirkhovy.com/post/2009_03_02_after_rain_comes_sunshine/","publishdate":"2009-03-02T00:00:00Z","relpermalink":"/post/2009_03_02_after_rain_comes_sunshine/","section":"post","summary":"“You write so infrequently”, I hear quite often. “I have too much to do,” I then reply. That is true, but there is of course more. Everyone likes to hear good news, or at least exciting ones.","tags":null,"title":"After rain comes sunshine","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"One of the most frequently encountered prejudices against America in Germany is the superficiality: In America, nobody is really friendly, that is just superficial. Service in restaurants lasts only until the check is brought. Admittedly, the greetings in America are much more cordial than in Germany, and still the phrases are less comitting. Nobody is really interested in “how I am” (I started relating at length how I felt once and was met with blank stares). Is that necessarily worse, though? I had to un-train myself wishing random people a nice day when I was in Germany, just to avoid being eyed with suspicion.\nI don’t really know what people in Germany expect: If I meet someone in an elevator, I don’t want to share their most intimate thoughts, a “How is it going” is sufficient. It does not hurt to say something friendly, and it is always nice to hear it. If I enter a restaurant, I do not intend to malke friends for life, I just want to be served promptly and correctly. Maybe with a smile, why not?\nAnd though people look down on the American attitude, nobody is really fond of the “emotionally authentic” German service. Maybe waiters there are more authentic, yet if I have to wait 20min for some sourpuss to bring me the espresso I ordered twice, which then consistently does not turn up on the check, I have to say that I don’t give a damn about emotional depth and authenticity! After all, German waiters do not even have to worry about the expected tip being subtracted from (already minimum) wages, so it should be much easier for them to smile some times. The friendliness of American service personel might be partially due to the fear of losing one’s job, but what difference does the motivation for friendly service ultimately make for the customer? I do not need to questions someones psychological motivation if he treats me nicely. And just for the sake of completeness it should be mentioned here that Americans are indeed capable of genuine friendliness and helpfulness…\nSo as long as it only concerns everyday encounters and not interpersonal relations, I am all for a little bit more superficiality!\nHave a nice day!\n","date":1233360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1233360000,"objectID":"124694e3012208dbccec587ff65e2cde","permalink":"https://dirkhovy.com/post/2009_01_31_have_a_nice_vorurteil/","publishdate":"2009-01-31T00:00:00Z","relpermalink":"/post/2009_01_31_have_a_nice_vorurteil/","section":"post","summary":"One of the most frequently encountered prejudices against America in Germany is the superficiality: In America, nobody is really friendly, that is just superficial. Service in restaurants lasts only until the check is brought.","tags":null,"title":"Have a nice Vorurteil!","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Europeans often make fun of the American tendency to see Europe in five days ( “If it is Tuesday, this must be Paris”). Of course you cannot fully appreciate the complexity and nuances of a country in such short a time, but in the meantime I know why one would still want to do it. And Europeans usually have more than two weeks worth of holidays per year…\nIf you have only a restricted time, you try to cram as much into it as possible―if you like to travel, countries, if you like people, meetings.\nOver the last two weeks I have had a meeting marathon which sometime got me quite dizzy ( “If I meet X today, it must be Tuesday”), and still I did not manage to see everyone I wanted. A fortnight is far too short a time for all the wonderful people you meet over almost three decades…\nThis always leaves the feeling, though, to just scrape at the surface and not do everyone justice. You can not fully appreciate the complexity and nuances of a person in such short a time, and still you try. Because even a brief meeting is better than none. And you take home so much more than Facebook or Skype could ever tell you.\nTo those I met: Thanks for the time with you, it was great to see you again! And to those I did not manage to meet: Please don’t hold it against me, it was not on purpose. Just on a tight schedule…\nIn any case I would be stoked to see you in LA at one point. Maybe if you are on a US trip? In that case, why not make it a Tuesday?\n","date":1231027200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1231027200,"objectID":"9cd49e578656362b34ddfc6dcadd17a3","permalink":"https://dirkhovy.com/post/2009_01_04_see_europe_in_two_weeks/","publishdate":"2009-01-04T00:00:00Z","relpermalink":"/post/2009_01_04_see_europe_in_two_weeks/","section":"post","summary":"Europeans often make fun of the American tendency to see Europe in five days ( “If it is Tuesday, this must be Paris”). Of course you cannot fully appreciate the complexity and nuances of a country in such short a time, but in the meantime I know why one would still want to do it.","tags":null,"title":"See Europe in two weeks…","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Language is one of the things you always take with you, no matter where, when, or what your baggage restrictions are. Our phonological system is hard to fool (or, as Christoph says “phonology always works”). If you don’t believe it, try for one hour to exchange all Fs and Ks. Should you succeed, you are a genius. If not, you’ll have a lot of fun.\nThis leaves us with the realisation, though, that we will always be spotted a s foreigners: German final devoicing and the whole trouble with “th” and “wh” are dead giveaways, and my “vowels are not American”, as a friend pointed out.\nLanguage is not only grammar and vocabulary, but also pronunciation subtleties: American “sh “s have less friction than German ones, less rounding, and the “a “s in “aber” and “garden” are absolutely not the same. Over the past few months, I have been identified as South African, British, or, well: German, but nobody ever seriously considered me to be American.\nEven as a linguist you cannot beat your own system: The brain happily abstracts and throws everything into neat categories. Don’t bother it with details…\nI have tried to pick up a few Chinese phrases, but my Chinese friends have either smiled politely or sadly shaken their heads. Even when I thought that I had repeated everything I heard, I hadn’t, since Chinese not only uses sounds, but also tones, and if you are not trained, you frankly don’t hear them…\nIt is only slightly consoling that on the other side, foreigners never get a German “ch” right.\nIt gets even worse when we get to meaning: Subconsciously, one a builds up a fine grained taxonomy of meaning nuances: Langauge is like a well worn rapier, which can pinpoint a meaning and win an argument.\nOnly when you start argueing in another language you realize you are suddenly handling a club. Sure, you can hit at the general meaning area, and you can win an argument, provided you hit first and hard. Yet it has no elegance or style, and too often, one is left searching for the right words to express a thought.\nThere are words, though, that I would like to have in both languages: “random” is such a word. I know that it can be translated as “zufällig”, but that does not cut it in a sentence like “That comment was so random!” And why does English not have an equivalent for “doch “: “yes, it is” is clumsy, and does not guarantee that satisfaction to prove someone wrong with just one word (I was also told that “jein” should be introduced, being an indecisive mix of “yes” and “no”).\nOne of the biggest obstacles in learning Engish is the fact that over the years, it has acquired Scandinavian, Germanic and Romance influences and mixed it all up. There is irregular inflection, yet not consistently: goose-geese and foot-feet, yet not moose-meese or wood-weed. I try to advocate the innovative use of “one shoop, two sheep”, yet people seem reluctant to take it on.\nThe only way out of this seems to me founding my own language which incorporates all these wonderful concepts. As a result, nobody will understand what I am saying any more, but I guess that is the price you have to pay if you want to express yourself clearly…\n","date":1227744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1227744000,"objectID":"1f3fc15e9ece96fc55c2c0865c158412","permalink":"https://dirkhovy.com/post/2008_11_27_speak_in_tongues/","publishdate":"2008-11-27T00:00:00Z","relpermalink":"/post/2008_11_27_speak_in_tongues/","section":"post","summary":"Language is one of the things you always take with you, no matter where, when, or what your baggage restrictions are. Our phonological system is hard to fool (or, as Christoph says “phonology always works”).","tags":null,"title":"Speak in tongues","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Yesterday, we had an earthquake drill. At 10:00am, we were supposed to “drop, cover, and hold on” (does “duck and cover” sound familiar). Since I am all for this kind of prevention, I participated. Apparently, I was about the only person who did… After five rather dull minutes (no people playing wounded, no paramedic coming to check on me), a rather puzzled colleague inquired what I was doing and whether I was ok. Apart from the fact that the space under my desk is rather dark and claustrophobic, I was, and I would have been in case of a real earthquake. That is, unless the building collapsed. In that case, you should sit next to your desk and hope that the falling debris forms a cave around it.\nGiven that I work on the fourth floor of a 12 storey building, I am not convinced that would help much…\nIt might be better to be in an elevator, since those swing freely in a concrete shaft inside the building (outer walls are the most dangerous ones). Unless the cable snaps or a fire breaks out.\nI guess you just have to hope the architects did their best and you manage to stay away from the windows and outer walls when an earthquake hits. And if “drop, cover and hold on” helps―so be it.\nI’d still rather not try it…\n","date":1226620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1226620800,"objectID":"eea6e35e07aa9f21d24625f1d8e53499","permalink":"https://dirkhovy.com/post/2008_11_14_shake_it_baby/","publishdate":"2008-11-14T00:00:00Z","relpermalink":"/post/2008_11_14_shake_it_baby/","section":"post","summary":"Yesterday, we had an earthquake drill. At 10:00am, we were supposed to “drop, cover, and hold on” (does “duck and cover” sound familiar). Since I am all for this kind of prevention, I participated.","tags":null,"title":"Shake it, baby","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"I am happy to announce that the little spider living behind my left rearview mirror―despite a major car wash―continues to weave her net everyday.\nIn case you were worried…\n","date":1226102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1226102400,"objectID":"e37d50acfadf9a281a387bf5a068456b","permalink":"https://dirkhovy.com/post/2008_11_08_news_from_behind_the_mirrors_glass/","publishdate":"2008-11-08T00:00:00Z","relpermalink":"/post/2008_11_08_news_from_behind_the_mirrors_glass/","section":"post","summary":"I am happy to announce that the little spider living behind my left rearview mirror―despite a major car wash―continues to weave her net everyday.\nIn case you were worried…","tags":null,"title":"News from Behind the Mirror’s Glass","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"As a friend said: “I only believe when Fox announces Obama as president”. Sen. McCain just acknowledged Obama’s victory in a fair and moving speech―and Fox confirmed it…\nThat’s it: America has a new president!\nProbably not all will be well now, but hopefully many things a lot better. Thanks for voting, America. I am a happy alien…\n","date":1225756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225756800,"objectID":"85982405bb0b1a7ba447aea9b2d0841a","permalink":"https://dirkhovy.com/post/2008_11_04_its_over/","publishdate":"2008-11-04T00:00:00Z","relpermalink":"/post/2008_11_04_its_over/","section":"post","summary":"As a friend said: “I only believe when Fox announces Obama as president”. Sen. McCain just acknowledged Obama’s victory in a fair and moving speech―and Fox confirmed it…\nThat’s it: America has a new president!","tags":null,"title":"It’s over","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Since the first mentioning of my car here, it has not been washed. As LA is a very dusty city, however, so it was about time to change that. I thus welcomed the fact that a sorority of the local college held a car wash in my street to raise money for a school of blind children. Getting my car washed for a small fee for a good cause―that seemed ike a pretty good deal to me.\nProbably a bit too good to be true. For about two hours, I was the happy owner of a shiny car. Then, the long awaited rain set in and washed all the dirt out of the air―and onto my car.\nIn retalliation, I went and had my hair cut―that was also long overdue, yet it won’t be ruined by the next downpour…\nThat’ll show the wheather…\n","date":1225497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1225497600,"objectID":"fa042a1dd6ab39f4194903d15f78f2b7","permalink":"https://dirkhovy.com/post/2008_11_01_a_classic/","publishdate":"2008-11-01T00:00:00Z","relpermalink":"/post/2008_11_01_a_classic/","section":"post","summary":"Since the first mentioning of my car here, it has not been washed. As LA is a very dusty city, however, so it was about time to change that. I thus welcomed the fact that a sorority of the local college held a car wash in my street to raise money for a school of blind children.","tags":null,"title":"A classic","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Behind the left rear mirror of my car lives a little spider, which comes out every night and weaves her net between the door and the mirror. And every morning when I get into my car, I remove the net.\nIt is nothing personal from my side, and in secret, I even admire her persistency, but it has become some sort of ritual.\nMaybe there is something I can learn from it: Get out every morning and weave your web…\nOr probably I just have to start to wash my car properly.\n","date":1224892800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1224892800,"objectID":"a42bab0bce85d3c9caafead8060a09f2","permalink":"https://dirkhovy.com/post/2008_10_25_persistency/","publishdate":"2008-10-25T00:00:00Z","relpermalink":"/post/2008_10_25_persistency/","section":"post","summary":"Behind the left rear mirror of my car lives a little spider, which comes out every night and weaves her net between the door and the mirror. And every morning when I get into my car, I remove the net.","tags":null,"title":"Persistency","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"The last few weeks have been pretty intense (workload and stress level-wise). The next weeks will see more of that, but at least I am better prepared now.\nAlso, I found out that I can see the Hollywood sign from my office window.\nWell, that’s something…\n","date":1224201600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1224201600,"objectID":"d5732c4591131b5c9384b5120bf7c2f6","permalink":"https://dirkhovy.com/post/2008_10_17_at_least/","publishdate":"2008-10-17T00:00:00Z","relpermalink":"/post/2008_10_17_at_least/","section":"post","summary":"The last few weeks have been pretty intense (workload and stress level-wise). The next weeks will see more of that, but at least I am better prepared now.\nAlso, I found out that I can see the Hollywood sign from my office window.","tags":null,"title":"At least…","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Ok, so I am in LA: Everything is loud, big, and exciting. I have finally a room and all the accompanying bits and pieces, and life goes its way. Besides all that organizational matters I did at least not have to worry about getting to know the city. Which is an advantage. Not a very individual one, granted. We all know it. We all have been here. At least if we had a television…\nThe A Team, Baywatch, Beverly Hills 90210, and countless other series portray LA, even without stating that explicitly. Hollywood is not only a place, but a trademark and―to some―a way of life.\nMusicians from Cypress Hill over Presidents of the USA to Sheryl Crow or System of a Down sing about the city, telling tales about the hard life in South Central or the bars in Downtown, and A Tribe Called Quest in an older song bemoaned the loss of their wallet in El Segundo.\nYes, LA is exactly as we always imagined it to be. We have all been here, we know how it looks. Other than Bielefeld it exists, it has a place in our heads. That also means, however, that everyone has an exact picture about how I live. They differ somewhat, but an astounding number of them involve pools, stars, yet also thugs and shopping carts.\nMy reality is somewhat different: Sure, everything is as seen in the movies, all the places do exist. There are thugs, there are stars, and there are ghettos and glamour side by side. Reality, however, is less glamorous: I go to university in South Central, El Segundo is just a 15min bike ride away, Beverly Hills and I are separated by just a few numbers in our ZIP code, and Hollywood is a dingy quarter full of tourists, hookers, and souvenir shops. I live in two cities…\nUp close, the city loses much of its screen character and becomes something else: A tangle of streets and houses, of beach and highways. It is many small cities in one, all full of interesting, busy, and mostly nice people from all over the world. It is a myth that keeps re-inventing itself, an unsentimental giant with a disposition for drama. A contradiction in itself.\nNo, this LA is certainly not a pretty city, yet an exciting and―mostly―a friendly one.\nAnd currently my home.\n","date":1221696000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1221696000,"objectID":"ad6e565c95d26514918a97fbaf7dc687","permalink":"https://dirkhovy.com/post/2008_09_18_the_town_that_wasnt_there/","publishdate":"2008-09-18T00:00:00Z","relpermalink":"/post/2008_09_18_the_town_that_wasnt_there/","section":"post","summary":"Ok, so I am in LA: Everything is loud, big, and exciting. I have finally a room and all the accompanying bits and pieces, and life goes its way. Besides all that organizational matters I did at least not have to worry about getting to know the city.","tags":null,"title":"The town that wasn’t there","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Currently reading a book which states that you should not repeat yourself.\nTo make sure I got that they say it several times…\n","date":1220832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1220832000,"objectID":"3eaafbcdfefedc2a14827c5869cfc451","permalink":"https://dirkhovy.com/post/2008_09_08_the_art_of_selfcontradiction/","publishdate":"2008-09-08T00:00:00Z","relpermalink":"/post/2008_09_08_the_art_of_selfcontradiction/","section":"post","summary":"Currently reading a book which states that you should not repeat yourself.\nTo make sure I got that they say it several times…","tags":null,"title":"The Art of Self-Contradiction","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"“When I arrived, all I had were two bags full of stuff, and now I am the owner of…”\nWe all know the stories starting out like that. They are part of the topos America, just as the rich uncle and the dish washer turned millionaire.\nIn my case, however, the story is not that compelling yet―I have neither founded a global trading empire nor bought a villa with celebrity neighbours in Beverly Hills. In fact, I still do not even own a room yet.\nYet my possession has grown considerately since the notorious two bags.\nSince yesterday, I own a new iPhone and―just borrowed, though―an old car. What the car lacks in glamour is made up for by the phone: It is chic, shiny, easy to use out of the box―and devours battery like there is no tomorrow.\nThe car, in contrast, is rather energy efficient, an old Honda that does not need much.\nI hate to admit it, yet with both I am pretty much in line with the current L.A. trend: While a year ago the streets were full of cars that consumed more fuel on starting than a weekend trip through Europe did, fuel efficiency is now the new cool. And with the radical consequence that characterizes Americans and especially Californians, they have changed the outlook of their streets.\nI do not dare to tell people that they still pay half the price they would in Germany―if they set their minds on energy conscious living, who am I to stop them? My car will play its part, and my conscience can be at peace. Yet is my phone a green one?\nSo, having entered the world of the propertied with all the entailing moral consequences, all I lack now is a room to put all that stuff into. And a moral guideline to buy stuff…\n","date":1219536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1219536000,"objectID":"89bf4daa65506e9e35ca617a52ff3be3","permalink":"https://dirkhovy.com/post/2008_08_24_my_house_my_car_my/","publishdate":"2008-08-24T00:00:00Z","relpermalink":"/post/2008_08_24_my_house_my_car_my/","section":"post","summary":"“When I arrived, all I had were two bags full of stuff, and now I am the owner of…”\nWe all know the stories starting out like that. They are part of the topos America, just as the rich uncle and the dish washer turned millionaire.","tags":null,"title":"My house, my car, my…","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"One of the questions posed most frequently to me over the last few days was “How’s the weather?” Quite understandable if you are from a country that―due to changing metereological conditions―has something like weather.\nHere in L.A., however, the weatherforecast is about as interesting as election results from a totalitarian regime: You know beforehand what it’s going to be. In this case: 80°F plusminus 5, a little cooler in the mornings and evenings.\nThat may sound great, yet after a few days you get used to it. You also find out quickly that the clouds you see in the morning will have disappeared until noon.\nAs exciting as the city is otherwise, the weather is rather bland.\nAt least this has the advantage that you can spend more time worrying about other things than umbrellas and warm socks. For example forms. But that is another story. One you just have to weather…\n","date":1219363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1219363200,"objectID":"d396c29e763f95d7df3037b9453e4bd8","permalink":"https://dirkhovy.com/post/2008_08_22_if_a_bit_under_the_weather/","publishdate":"2008-08-22T00:00:00Z","relpermalink":"/post/2008_08_22_if_a_bit_under_the_weather/","section":"post","summary":"One of the questions posed most frequently to me over the last few days was “How’s the weather?” Quite understandable if you are from a country that―due to changing metereological conditions―has something like weather.","tags":null,"title":"If a bit under the weather…","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Well, I knew that das passieren würde, but when it strikes, you feel immer a little lost. After zwei oder three Tagen, your Gehirn does not know genau, which language to take. Es ist no longer German, aber it ist not yet Englisch. You concentrate on eine Sprache, but you keep switching back und vor.\nIt does nicht mal help if your host understands beide Sprachen, because you will not know, welchen Ausdruck man what zuordnen muss. I feel wie ein Aphasiker, der things zwar beschreiben can, yet is unable to recollect the Namen. It is schlimm genug, einen expression in the foreign language nicht zu wissen, yet I forgot them in either der beiden Sprachen!\nAt least this will sort sich out after a few days, aber until then I will re-enact the babylonian Sprachgewirr in meinem head…\n","date":1218844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1218844800,"objectID":"4088ce90204108bffba392c450b42f40","permalink":"https://dirkhovy.com/post/2008_08_16_babel/","publishdate":"2008-08-16T00:00:00Z","relpermalink":"/post/2008_08_16_babel/","section":"post","summary":"Well, I knew that das passieren würde, but when it strikes, you feel immer a little lost. After zwei oder three Tagen, your Gehirn does not know genau, which language to take.","tags":null,"title":"Babel","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"After a lot of toil and trouble, much waiting and even more forms, I have finally arrived in Los Angeles. Let’s start…\n","date":1218672000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1218672000,"objectID":"f4a9e314b4d35c85282f7fcc7d19de27","permalink":"https://dirkhovy.com/post/2008_08_14_arrived/","publishdate":"2008-08-14T00:00:00Z","relpermalink":"/post/2008_08_14_arrived/","section":"post","summary":"After a lot of toil and trouble, much waiting and even more forms, I have finally arrived in Los Angeles. Let’s start…","tags":null,"title":"Arrived","type":"post"},{"authors":["Dirk Hovy"],"categories":null,"content":"Two bags. That’s it. Two bags, max. 32kg each, more does the airline not allow. Two bags to take everything with you. Not only the stuff you need, but also everthing that separates travelling from living.\nIt’s strange to confine your former life to a certain weight and some baggage dimensions, but what can you do\u0026hellip;\n","date":1218672000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1218672000,"objectID":"4e541283b620558db3130b377376a809","permalink":"https://dirkhovy.com/post/2008_08_14_packed/","publishdate":"2008-08-14T00:00:00Z","relpermalink":"/post/2008_08_14_packed/","section":"post","summary":"Two bags. That’s it. Two bags, max. 32kg each, more does the airline not allow. Two bags to take everything with you. Not only the stuff you need, but also everthing that separates travelling from living.","tags":null,"title":"Packed","type":"post"}]